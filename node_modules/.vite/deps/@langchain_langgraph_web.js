import {
  AIMessagePromptTemplate,
  BaseChatPromptTemplate,
  BaseMessagePromptTemplate,
  BaseMessageStringPromptTemplate,
  ChatMessagePromptTemplate,
  ChatPromptTemplate,
  DictPromptTemplate,
  FewShotChatMessagePromptTemplate,
  FewShotPromptTemplate,
  HumanMessagePromptTemplate,
  ImagePromptTemplate,
  MessagesPlaceholder,
  SystemMessagePromptTemplate,
  messages_exports
} from "./chunk-ODZ5QXWL.js";
import {
  AIMessage,
  AIMessageChunk,
  AsyncCaller,
  AsyncLocalStorageProviderSingleton,
  BaseCallbackHandler,
  BasePromptTemplate,
  BaseStringPromptTemplate,
  BaseTracer,
  CallbackManager,
  ChatGenerationChunk,
  ChatPromptValue,
  DEFAULT_FORMATTER_MAPPING,
  DEFAULT_PARSER_MAPPING,
  GenerationChunk,
  Graph,
  HumanMessage,
  IterableReadableStream,
  LangChainTracer,
  PromptTemplate,
  RUN_KEY,
  Runnable,
  RunnableAssign,
  RunnableBinding,
  RunnableEach,
  RunnableLambda,
  RunnableMap,
  RunnableParallel,
  RunnablePick,
  RunnableRetry,
  RunnableSequence,
  RunnableToolLike,
  RunnableWithFallbacks,
  Serializable,
  StringPromptValue,
  ToolInputParsingException,
  ToolMessage,
  _coerceToDict,
  _coerceToRunnable,
  _configHasToolCallId,
  _isToolCall,
  addLangChainErrorFields,
  applyPatch,
  async_caller_exports,
  base_exports,
  base_exports2,
  callbackHandlerPrefersStreaming,
  checkValidTemplate,
  coerceMessageLikeToMessage,
  compare,
  concat,
  console_exports,
  convertToChunk,
  convertToOpenAIImageBlock,
  deepCompareStrict,
  ensureConfig,
  env_exports,
  extendInteropZodObject,
  external_exports,
  getBufferString,
  getCallbackManagerForConfig,
  getEnvironmentVariable,
  getInteropZodDefaultGetter,
  getInteropZodObjectShape,
  getSchemaDescription,
  get_lc_unique_name,
  interopParse,
  interopParseAsync,
  interopSafeParse,
  interopSafeParseAsync,
  interopZodObjectPartial,
  interopZodObjectPassthrough,
  interopZodObjectStrict,
  interopZodTransformInputSchema,
  interpolateFString,
  interpolateMustache,
  isAIMessage,
  isAIMessageChunk,
  isBase64ContentBlock,
  isBaseMessage,
  isBaseMessageChunk,
  isDirectToolOutput,
  isInteropZodObject,
  isInteropZodSchema,
  isShapelessZodSchema,
  isSimpleStringZodSchema,
  isToolMessage,
  isURLContentBlock,
  isZodArrayV4,
  isZodObjectV3,
  isZodObjectV4,
  isZodSchema,
  isZodSchemaV3,
  isZodSchemaV4,
  json_schema_exports,
  keyFromJson,
  log_stream_exports,
  manager_exports,
  mapKeys,
  mapStoredMessageToChatMessage,
  mergeConfigs,
  outputs_exports,
  parseCallbackConfigArg,
  parseFString,
  parseJsonMarkdown,
  parseMustache,
  parsePartialJson,
  parseTemplate,
  patchConfig,
  pickRunnableConfigKeys,
  promises_exports,
  prompt_values_exports,
  renderTemplate,
  serializable_exports,
  stream_exports,
  toJsonSchema,
  tracer_langchain_exports,
  validate,
  validatesOnlyStrings
} from "./chunk-VRKEZWG4.js";
import {
  __commonJS,
  __export,
  __publicField,
  __toESM
} from "./chunk-EWTE5DHJ.js";

// node_modules/base64-js/index.js
var require_base64_js = __commonJS({
  "node_modules/base64-js/index.js"(exports) {
    "use strict";
    exports.byteLength = byteLength;
    exports.toByteArray = toByteArray;
    exports.fromByteArray = fromByteArray;
    var lookup = [];
    var revLookup = [];
    var Arr = typeof Uint8Array !== "undefined" ? Uint8Array : Array;
    var code = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    for (i = 0, len = code.length; i < len; ++i) {
      lookup[i] = code[i];
      revLookup[code.charCodeAt(i)] = i;
    }
    var i;
    var len;
    revLookup["-".charCodeAt(0)] = 62;
    revLookup["_".charCodeAt(0)] = 63;
    function getLens(b64) {
      var len2 = b64.length;
      if (len2 % 4 > 0) {
        throw new Error("Invalid string. Length must be a multiple of 4");
      }
      var validLen = b64.indexOf("=");
      if (validLen === -1) validLen = len2;
      var placeHoldersLen = validLen === len2 ? 0 : 4 - validLen % 4;
      return [validLen, placeHoldersLen];
    }
    function byteLength(b64) {
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function _byteLength(b64, validLen, placeHoldersLen) {
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function toByteArray(b64) {
      var tmp;
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      var arr2 = new Arr(_byteLength(b64, validLen, placeHoldersLen));
      var curByte = 0;
      var len2 = placeHoldersLen > 0 ? validLen - 4 : validLen;
      var i2;
      for (i2 = 0; i2 < len2; i2 += 4) {
        tmp = revLookup[b64.charCodeAt(i2)] << 18 | revLookup[b64.charCodeAt(i2 + 1)] << 12 | revLookup[b64.charCodeAt(i2 + 2)] << 6 | revLookup[b64.charCodeAt(i2 + 3)];
        arr2[curByte++] = tmp >> 16 & 255;
        arr2[curByte++] = tmp >> 8 & 255;
        arr2[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 2) {
        tmp = revLookup[b64.charCodeAt(i2)] << 2 | revLookup[b64.charCodeAt(i2 + 1)] >> 4;
        arr2[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 1) {
        tmp = revLookup[b64.charCodeAt(i2)] << 10 | revLookup[b64.charCodeAt(i2 + 1)] << 4 | revLookup[b64.charCodeAt(i2 + 2)] >> 2;
        arr2[curByte++] = tmp >> 8 & 255;
        arr2[curByte++] = tmp & 255;
      }
      return arr2;
    }
    function tripletToBase64(num) {
      return lookup[num >> 18 & 63] + lookup[num >> 12 & 63] + lookup[num >> 6 & 63] + lookup[num & 63];
    }
    function encodeChunk(uint8, start, end) {
      var tmp;
      var output = [];
      for (var i2 = start; i2 < end; i2 += 3) {
        tmp = (uint8[i2] << 16 & 16711680) + (uint8[i2 + 1] << 8 & 65280) + (uint8[i2 + 2] & 255);
        output.push(tripletToBase64(tmp));
      }
      return output.join("");
    }
    function fromByteArray(uint8) {
      var tmp;
      var len2 = uint8.length;
      var extraBytes = len2 % 3;
      var parts = [];
      var maxChunkLength = 16383;
      for (var i2 = 0, len22 = len2 - extraBytes; i2 < len22; i2 += maxChunkLength) {
        parts.push(encodeChunk(uint8, i2, i2 + maxChunkLength > len22 ? len22 : i2 + maxChunkLength));
      }
      if (extraBytes === 1) {
        tmp = uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 2] + lookup[tmp << 4 & 63] + "=="
        );
      } else if (extraBytes === 2) {
        tmp = (uint8[len2 - 2] << 8) + uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 10] + lookup[tmp >> 4 & 63] + lookup[tmp << 2 & 63] + "="
        );
      }
      return parts.join("");
    }
  }
});

// node_modules/@langchain/langgraph/dist/errors.js
var BaseLangGraphError = class extends Error {
  constructor(message, fields) {
    let finalMessage = message ?? "";
    if (fields == null ? void 0 : fields.lc_error_code) {
      finalMessage = `${finalMessage}

Troubleshooting URL: https://langchain-ai.github.io/langgraphjs/troubleshooting/errors/${fields.lc_error_code}/
`;
    }
    super(finalMessage);
    Object.defineProperty(this, "lc_error_code", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.lc_error_code = fields == null ? void 0 : fields.lc_error_code;
  }
};
var GraphBubbleUp = class extends BaseLangGraphError {
  get is_bubble_up() {
    return true;
  }
};
var GraphRecursionError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphRecursionError";
  }
  static get unminifiable_name() {
    return "GraphRecursionError";
  }
};
var GraphValueError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphValueError";
  }
  static get unminifiable_name() {
    return "GraphValueError";
  }
};
var GraphInterrupt = class extends GraphBubbleUp {
  constructor(interrupts, fields) {
    super(JSON.stringify(interrupts, null, 2), fields);
    Object.defineProperty(this, "interrupts", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = "GraphInterrupt";
    this.interrupts = interrupts ?? [];
  }
  static get unminifiable_name() {
    return "GraphInterrupt";
  }
};
var NodeInterrupt = class extends GraphInterrupt {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(message, fields) {
    super([{ value: message }], fields);
    this.name = "NodeInterrupt";
  }
  static get unminifiable_name() {
    return "NodeInterrupt";
  }
};
var ParentCommand = class extends GraphBubbleUp {
  constructor(command) {
    super();
    Object.defineProperty(this, "command", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = "ParentCommand";
    this.command = command;
  }
  static get unminifiable_name() {
    return "ParentCommand";
  }
};
function isParentCommand(e) {
  return e !== void 0 && e.name === ParentCommand.unminifiable_name;
}
function isGraphBubbleUp(e) {
  return e !== void 0 && e.is_bubble_up === true;
}
function isGraphInterrupt(e) {
  return e !== void 0 && [
    GraphInterrupt.unminifiable_name,
    NodeInterrupt.unminifiable_name
  ].includes(e.name);
}
var EmptyInputError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyInputError";
  }
  static get unminifiable_name() {
    return "EmptyInputError";
  }
};
var EmptyChannelError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyChannelError";
  }
  static get unminifiable_name() {
    return "EmptyChannelError";
  }
};
var InvalidUpdateError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "InvalidUpdateError";
  }
  static get unminifiable_name() {
    return "InvalidUpdateError";
  }
};
var MultipleSubgraphsError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "MultipleSubgraphError";
  }
  static get unminifiable_name() {
    return "MultipleSubgraphError";
  }
};
var UnreachableNodeError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "UnreachableNodeError";
  }
  static get unminifiable_name() {
    return "UnreachableNodeError";
  }
};
var RemoteException = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "RemoteException";
  }
  static get unminifiable_name() {
    return "RemoteException";
  }
};
var getSubgraphsSeenSet = () => {
  if (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")] === void 0
  ) {
    globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")] = /* @__PURE__ */ new Set();
  }
  return globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")];
};

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/regex.js
var regex_default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/validate.js
function validate2(uuid) {
  return typeof uuid === "string" && regex_default.test(uuid);
}
var validate_default = validate2;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/parse.js
function parse(uuid) {
  if (!validate_default(uuid)) {
    throw TypeError("Invalid UUID");
  }
  var v;
  var arr2 = new Uint8Array(16);
  arr2[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;
  arr2[1] = v >>> 16 & 255;
  arr2[2] = v >>> 8 & 255;
  arr2[3] = v & 255;
  arr2[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;
  arr2[5] = v & 255;
  arr2[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;
  arr2[7] = v & 255;
  arr2[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;
  arr2[9] = v & 255;
  arr2[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 1099511627776 & 255;
  arr2[11] = v / 4294967296 & 255;
  arr2[12] = v >>> 24 & 255;
  arr2[13] = v >>> 16 & 255;
  arr2[14] = v >>> 8 & 255;
  arr2[15] = v & 255;
  return arr2;
}
var parse_default = parse;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/stringify.js
var byteToHex = [];
for (i = 0; i < 256; ++i) {
  byteToHex.push((i + 256).toString(16).slice(1));
}
var i;
function unsafeStringify(arr2, offset = 0) {
  return (byteToHex[arr2[offset + 0]] + byteToHex[arr2[offset + 1]] + byteToHex[arr2[offset + 2]] + byteToHex[arr2[offset + 3]] + "-" + byteToHex[arr2[offset + 4]] + byteToHex[arr2[offset + 5]] + "-" + byteToHex[arr2[offset + 6]] + byteToHex[arr2[offset + 7]] + "-" + byteToHex[arr2[offset + 8]] + byteToHex[arr2[offset + 9]] + "-" + byteToHex[arr2[offset + 10]] + byteToHex[arr2[offset + 11]] + byteToHex[arr2[offset + 12]] + byteToHex[arr2[offset + 13]] + byteToHex[arr2[offset + 14]] + byteToHex[arr2[offset + 15]]).toLowerCase();
}

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/rng.js
var getRandomValues;
var rnds8 = new Uint8Array(16);
function rng() {
  if (!getRandomValues) {
    getRandomValues = typeof crypto !== "undefined" && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);
    if (!getRandomValues) {
      throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");
    }
  }
  return getRandomValues(rnds8);
}

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v1.js
var _nodeId;
var _clockseq;
var _lastMSecs = 0;
var _lastNSecs = 0;
function v1(options, buf, offset) {
  var i = buf && offset || 0;
  var b = buf || new Array(16);
  options = options || {};
  var node = options.node;
  var clockseq = options.clockseq;
  if (!options._v6) {
    if (!node) {
      node = _nodeId;
    }
    if (clockseq == null) {
      clockseq = _clockseq;
    }
  }
  if (node == null || clockseq == null) {
    var seedBytes = options.random || (options.rng || rng)();
    if (node == null) {
      node = [seedBytes[0], seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];
      if (!_nodeId && !options._v6) {
        node[0] |= 1;
        _nodeId = node;
      }
    }
    if (clockseq == null) {
      clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 16383;
      if (_clockseq === void 0 && !options._v6) {
        _clockseq = clockseq;
      }
    }
  }
  var msecs = options.msecs !== void 0 ? options.msecs : Date.now();
  var nsecs = options.nsecs !== void 0 ? options.nsecs : _lastNSecs + 1;
  var dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 1e4;
  if (dt < 0 && options.clockseq === void 0) {
    clockseq = clockseq + 1 & 16383;
  }
  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === void 0) {
    nsecs = 0;
  }
  if (nsecs >= 1e4) {
    throw new Error("uuid.v1(): Can't create more than 10M uuids/sec");
  }
  _lastMSecs = msecs;
  _lastNSecs = nsecs;
  _clockseq = clockseq;
  msecs += 122192928e5;
  var tl = ((msecs & 268435455) * 1e4 + nsecs) % 4294967296;
  b[i++] = tl >>> 24 & 255;
  b[i++] = tl >>> 16 & 255;
  b[i++] = tl >>> 8 & 255;
  b[i++] = tl & 255;
  var tmh = msecs / 4294967296 * 1e4 & 268435455;
  b[i++] = tmh >>> 8 & 255;
  b[i++] = tmh & 255;
  b[i++] = tmh >>> 24 & 15 | 16;
  b[i++] = tmh >>> 16 & 255;
  b[i++] = clockseq >>> 8 | 128;
  b[i++] = clockseq & 255;
  for (var n2 = 0; n2 < 6; ++n2) {
    b[i + n2] = node[n2];
  }
  return buf || unsafeStringify(b);
}
var v1_default = v1;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v1ToV6.js
function v1ToV6(uuid) {
  var v1Bytes = typeof uuid === "string" ? parse_default(uuid) : uuid;
  var v6Bytes = _v1ToV6(v1Bytes);
  return typeof uuid === "string" ? unsafeStringify(v6Bytes) : v6Bytes;
}
function _v1ToV6(v1Bytes, randomize = false) {
  return Uint8Array.of((v1Bytes[6] & 15) << 4 | v1Bytes[7] >> 4 & 15, (v1Bytes[7] & 15) << 4 | (v1Bytes[4] & 240) >> 4, (v1Bytes[4] & 15) << 4 | (v1Bytes[5] & 240) >> 4, (v1Bytes[5] & 15) << 4 | (v1Bytes[0] & 240) >> 4, (v1Bytes[0] & 15) << 4 | (v1Bytes[1] & 240) >> 4, (v1Bytes[1] & 15) << 4 | (v1Bytes[2] & 240) >> 4, 96 | v1Bytes[2] & 15, v1Bytes[3], v1Bytes[8], v1Bytes[9], v1Bytes[10], v1Bytes[11], v1Bytes[12], v1Bytes[13], v1Bytes[14], v1Bytes[15]);
}

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v35.js
function stringToBytes(str) {
  str = unescape(encodeURIComponent(str));
  var bytes = [];
  for (var i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }
  return bytes;
}
var DNS = "6ba7b810-9dad-11d1-80b4-00c04fd430c8";
var URL = "6ba7b811-9dad-11d1-80b4-00c04fd430c8";
function v35(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    var _namespace;
    if (typeof value === "string") {
      value = stringToBytes(value);
    }
    if (typeof namespace === "string") {
      namespace = parse_default(namespace);
    }
    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {
      throw TypeError("Namespace must be array-like (16 iterable integer values, 0-255)");
    }
    var bytes = new Uint8Array(16 + value.length);
    bytes.set(namespace);
    bytes.set(value, namespace.length);
    bytes = hashfunc(bytes);
    bytes[6] = bytes[6] & 15 | version;
    bytes[8] = bytes[8] & 63 | 128;
    if (buf) {
      offset = offset || 0;
      for (var i = 0; i < 16; ++i) {
        buf[offset + i] = bytes[i];
      }
      return buf;
    }
    return unsafeStringify(bytes);
  }
  try {
    generateUUID.name = name;
  } catch (err) {
  }
  generateUUID.DNS = DNS;
  generateUUID.URL = URL;
  return generateUUID;
}

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/md5.js
function md5(bytes) {
  if (typeof bytes === "string") {
    var msg = unescape(encodeURIComponent(bytes));
    bytes = new Uint8Array(msg.length);
    for (var i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }
  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));
}
function md5ToHexEncodedArray(input) {
  var output = [];
  var length32 = input.length * 32;
  var hexTab = "0123456789abcdef";
  for (var i = 0; i < length32; i += 8) {
    var x = input[i >> 5] >>> i % 32 & 255;
    var hex = parseInt(hexTab.charAt(x >>> 4 & 15) + hexTab.charAt(x & 15), 16);
    output.push(hex);
  }
  return output;
}
function getOutputLength(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
function wordsToMd5(x, len) {
  x[len >> 5] |= 128 << len % 32;
  x[getOutputLength(len) - 1] = len;
  var a = 1732584193;
  var b = -271733879;
  var c = -1732584194;
  var d = 271733878;
  for (var i = 0; i < x.length; i += 16) {
    var olda = a;
    var oldb = b;
    var oldc = c;
    var oldd = d;
    a = md5ff(a, b, c, d, x[i], 7, -680876936);
    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg(b, c, d, a, x[i], 20, -373897302);
    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh(d, a, b, c, x[i], 11, -358537222);
    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii(a, b, c, d, x[i], 6, -198630844);
    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd(a, olda);
    b = safeAdd(b, oldb);
    c = safeAdd(c, oldc);
    d = safeAdd(d, oldd);
  }
  return [a, b, c, d];
}
function bytesToWords(input) {
  if (input.length === 0) {
    return [];
  }
  var length8 = input.length * 8;
  var output = new Uint32Array(getOutputLength(length8));
  for (var i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 255) << i % 32;
  }
  return output;
}
function safeAdd(x, y) {
  var lsw = (x & 65535) + (y & 65535);
  var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 65535;
}
function bitRotateLeft(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
function md5cmn(q, a, b, x, s, t) {
  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);
}
function md5ff(a, b, c, d, x, s, t) {
  return md5cmn(b & c | ~b & d, a, b, x, s, t);
}
function md5gg(a, b, c, d, x, s, t) {
  return md5cmn(b & d | c & ~d, a, b, x, s, t);
}
function md5hh(a, b, c, d, x, s, t) {
  return md5cmn(b ^ c ^ d, a, b, x, s, t);
}
function md5ii(a, b, c, d, x, s, t) {
  return md5cmn(c ^ (b | ~d), a, b, x, s, t);
}
var md5_default = md5;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v3.js
var v3 = v35("v3", 48, md5_default);

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/native.js
var randomUUID = typeof crypto !== "undefined" && crypto.randomUUID && crypto.randomUUID.bind(crypto);

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/sha1.js
function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;
    case 1:
      return x ^ y ^ z;
    case 2:
      return x & y ^ x & z ^ y & z;
    case 3:
      return x ^ y ^ z;
  }
}
function ROTL(x, n2) {
  return x << n2 | x >>> 32 - n2;
}
function sha1(bytes) {
  var K2 = [1518500249, 1859775393, 2400959708, 3395469782];
  var H = [1732584193, 4023233417, 2562383102, 271733878, 3285377520];
  if (typeof bytes === "string") {
    var msg = unescape(encodeURIComponent(bytes));
    bytes = [];
    for (var i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  } else if (!Array.isArray(bytes)) {
    bytes = Array.prototype.slice.call(bytes);
  }
  bytes.push(128);
  var l = bytes.length / 4 + 2;
  var N = Math.ceil(l / 16);
  var M = new Array(N);
  for (var _i = 0; _i < N; ++_i) {
    var arr2 = new Uint32Array(16);
    for (var j = 0; j < 16; ++j) {
      arr2[j] = bytes[_i * 64 + j * 4] << 24 | bytes[_i * 64 + j * 4 + 1] << 16 | bytes[_i * 64 + j * 4 + 2] << 8 | bytes[_i * 64 + j * 4 + 3];
    }
    M[_i] = arr2;
  }
  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 4294967295;
  for (var _i2 = 0; _i2 < N; ++_i2) {
    var W = new Uint32Array(80);
    for (var t = 0; t < 16; ++t) {
      W[t] = M[_i2][t];
    }
    for (var _t = 16; _t < 80; ++_t) {
      W[_t] = ROTL(W[_t - 3] ^ W[_t - 8] ^ W[_t - 14] ^ W[_t - 16], 1);
    }
    var a = H[0];
    var b = H[1];
    var c = H[2];
    var d = H[3];
    var e = H[4];
    for (var _t2 = 0; _t2 < 80; ++_t2) {
      var s = Math.floor(_t2 / 20);
      var T = ROTL(a, 5) + f(s, b, c, d) + e + K2[s] + W[_t2] >>> 0;
      e = d;
      d = c;
      c = ROTL(b, 30) >>> 0;
      b = a;
      a = T;
    }
    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }
  return [H[0] >> 24 & 255, H[0] >> 16 & 255, H[0] >> 8 & 255, H[0] & 255, H[1] >> 24 & 255, H[1] >> 16 & 255, H[1] >> 8 & 255, H[1] & 255, H[2] >> 24 & 255, H[2] >> 16 & 255, H[2] >> 8 & 255, H[2] & 255, H[3] >> 24 & 255, H[3] >> 16 & 255, H[3] >> 8 & 255, H[3] & 255, H[4] >> 24 & 255, H[4] >> 16 & 255, H[4] >> 8 & 255, H[4] & 255];
}
var sha1_default = sha1;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v5.js
var v5 = v35("v5", 80, sha1_default);
var v5_default = v5;

// node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/esm-browser/v6.js
function ownKeys(e, r) {
  var t = Object.keys(e);
  if (Object.getOwnPropertySymbols) {
    var o = Object.getOwnPropertySymbols(e);
    r && (o = o.filter(function(r2) {
      return Object.getOwnPropertyDescriptor(e, r2).enumerable;
    })), t.push.apply(t, o);
  }
  return t;
}
function _objectSpread(e) {
  for (var r = 1; r < arguments.length; r++) {
    var t = null != arguments[r] ? arguments[r] : {};
    r % 2 ? ownKeys(Object(t), true).forEach(function(r2) {
      _defineProperty(e, r2, t[r2]);
    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function(r2) {
      Object.defineProperty(e, r2, Object.getOwnPropertyDescriptor(t, r2));
    });
  }
  return e;
}
function _defineProperty(e, r, t) {
  return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: true, configurable: true, writable: true }) : e[r] = t, e;
}
function _toPropertyKey(t) {
  var i = _toPrimitive(t, "string");
  return "symbol" == typeof i ? i : i + "";
}
function _toPrimitive(t, r) {
  if ("object" != typeof t || !t) return t;
  var e = t[Symbol.toPrimitive];
  if (void 0 !== e) {
    var i = e.call(t, r || "default");
    if ("object" != typeof i) return i;
    throw new TypeError("@@toPrimitive must return a primitive value.");
  }
  return ("string" === r ? String : Number)(t);
}
function v6(options = {}, buf, offset = 0) {
  var bytes = v1_default(_objectSpread(_objectSpread({}, options), {}, {
    _v6: true
  }), new Uint8Array(16));
  bytes = v1ToV6(bytes);
  if (buf) {
    for (var i = 0; i < 16; i++) {
      buf[offset + i] = bytes[i];
    }
    return buf;
  }
  return unsafeStringify(bytes);
}

// node_modules/@langchain/langgraph-checkpoint/dist/id.js
function uuid6(clockseq) {
  return v6({ clockseq });
}
function uuid5(name, namespace) {
  const namespaceBytes = namespace.replace(/-/g, "").match(/.{2}/g).map((byte) => parseInt(byte, 16));
  return v5_default(name, new Uint8Array(namespaceBytes));
}

// node_modules/@langchain/langgraph-checkpoint/dist/serde/types.js
var TASKS = "__pregel_tasks";
var ERROR2 = "__error__";
var SCHEDULED = "__scheduled__";
var INTERRUPT = "__interrupt__";
var RESUME = "__resume__";

// node_modules/@langchain/core/dist/load/import_constants.js
var optionalImportEntrypoints = [];

// node_modules/@langchain/core/dist/load/import_map.js
var import_map_exports = {};
__export(import_map_exports, {
  agents: () => agents_exports,
  caches: () => base_exports3,
  callbacks__base: () => base_exports,
  callbacks__manager: () => manager_exports,
  callbacks__promises: () => promises_exports,
  chat_history: () => chat_history_exports,
  documents: () => documents_exports,
  embeddings: () => embeddings_exports,
  example_selectors: () => example_selectors_exports,
  language_models__base: () => base_exports4,
  language_models__chat_models: () => chat_models_exports,
  language_models__llms: () => llms_exports,
  load__serializable: () => serializable_exports,
  memory: () => memory_exports,
  messages: () => messages_exports,
  output_parsers: () => output_parsers_exports,
  outputs: () => outputs_exports,
  prompt_values: () => prompt_values_exports,
  prompts: () => prompts_exports,
  retrievers: () => retrievers_exports,
  runnables: () => runnables_exports,
  stores: () => stores_exports,
  tools: () => tools_exports,
  tracers__base: () => base_exports2,
  tracers__console: () => console_exports,
  tracers__initialize: () => initialize_exports,
  tracers__log_stream: () => log_stream_exports,
  tracers__run_collector: () => run_collector_exports,
  tracers__tracer_langchain: () => tracer_langchain_exports,
  tracers__tracer_langchain_v1: () => tracer_langchain_v1_exports,
  utils__async_caller: () => async_caller_exports,
  utils__chunk_array: () => chunk_array_exports,
  utils__env: () => env_exports,
  utils__function_calling: () => function_calling_exports,
  utils__hash: () => hash_exports,
  utils__json_patch: () => json_patch_exports,
  utils__json_schema: () => json_schema_exports,
  utils__math: () => math_exports,
  utils__stream: () => stream_exports,
  utils__testing: () => testing_exports,
  utils__tiktoken: () => tiktoken_exports,
  utils__types: () => types_exports,
  vectorstores: () => vectorstores_exports
});

// node_modules/@langchain/core/dist/agents.js
var agents_exports = {};

// node_modules/@langchain/core/dist/caches/base.js
var base_exports3 = {};
__export(base_exports3, {
  BaseCache: () => BaseCache,
  InMemoryCache: () => InMemoryCache,
  deserializeStoredGeneration: () => deserializeStoredGeneration,
  getCacheKey: () => getCacheKey,
  serializeGeneration: () => serializeGeneration
});

// node_modules/@langchain/core/dist/utils/hash.js
var hash_exports = {};
__export(hash_exports, {
  insecureHash: () => insecureHash,
  sha256: () => sha256
});

// node_modules/@langchain/core/dist/utils/js-sha1/hash.js
var root = typeof window === "object" ? window : {};
var HEX_CHARS = "0123456789abcdef".split("");
var EXTRA = [-2147483648, 8388608, 32768, 128];
var SHIFT = [24, 16, 8, 0];
var blocks = [];
function Sha1(sharedMemory) {
  if (sharedMemory) {
    blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    this.blocks = blocks;
  } else {
    this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
  }
  this.h0 = 1732584193;
  this.h1 = 4023233417;
  this.h2 = 2562383102;
  this.h3 = 271733878;
  this.h4 = 3285377520;
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
}
Sha1.prototype.update = function(message) {
  if (this.finalized) {
    return;
  }
  var notString = typeof message !== "string";
  if (notString && message.constructor === root.ArrayBuffer) {
    message = new Uint8Array(message);
  }
  var code, index = 0, i, length = message.length || 0, blocks3 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks3[0] = this.block;
      blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
    }
    if (notString) {
      for (i = this.start; index < length && i < 64; ++index) {
        blocks3[i >> 2] |= message[index] << SHIFT[i++ & 3];
      }
    } else {
      for (i = this.start; index < length && i < 64; ++index) {
        code = message.charCodeAt(index);
        if (code < 128) {
          blocks3[i >> 2] |= code << SHIFT[i++ & 3];
        } else if (code < 2048) {
          blocks3[i >> 2] |= (192 | code >> 6) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
        } else if (code < 55296 || code >= 57344) {
          blocks3[i >> 2] |= (224 | code >> 12) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code >> 6 & 63) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
        } else {
          code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
          blocks3[i >> 2] |= (240 | code >> 18) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code >> 12 & 63) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code >> 6 & 63) << SHIFT[i++ & 3];
          blocks3[i >> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
        }
      }
    }
    this.lastByteIndex = i;
    this.bytes += i - this.start;
    if (i >= 64) {
      this.block = blocks3[16];
      this.start = i - 64;
      this.hash();
      this.hashed = true;
    } else {
      this.start = i;
    }
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha1.prototype.finalize = function() {
  if (this.finalized) {
    return;
  }
  this.finalized = true;
  var blocks3 = this.blocks, i = this.lastByteIndex;
  blocks3[16] = this.block;
  blocks3[i >> 2] |= EXTRA[i & 3];
  this.block = blocks3[16];
  if (i >= 56) {
    if (!this.hashed) {
      this.hash();
    }
    blocks3[0] = this.block;
    blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
  }
  blocks3[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks3[15] = this.bytes << 3;
  this.hash();
};
Sha1.prototype.hash = function() {
  var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4;
  var f3, j, t, blocks3 = this.blocks;
  for (j = 16; j < 80; ++j) {
    t = blocks3[j - 3] ^ blocks3[j - 8] ^ blocks3[j - 14] ^ blocks3[j - 16];
    blocks3[j] = t << 1 | t >>> 31;
  }
  for (j = 0; j < 20; j += 5) {
    f3 = b & c | ~b & d;
    t = a << 5 | a >>> 27;
    e = t + f3 + e + 1518500249 + blocks3[j] << 0;
    b = b << 30 | b >>> 2;
    f3 = a & b | ~a & c;
    t = e << 5 | e >>> 27;
    d = t + f3 + d + 1518500249 + blocks3[j + 1] << 0;
    a = a << 30 | a >>> 2;
    f3 = e & a | ~e & b;
    t = d << 5 | d >>> 27;
    c = t + f3 + c + 1518500249 + blocks3[j + 2] << 0;
    e = e << 30 | e >>> 2;
    f3 = d & e | ~d & a;
    t = c << 5 | c >>> 27;
    b = t + f3 + b + 1518500249 + blocks3[j + 3] << 0;
    d = d << 30 | d >>> 2;
    f3 = c & d | ~c & e;
    t = b << 5 | b >>> 27;
    a = t + f3 + a + 1518500249 + blocks3[j + 4] << 0;
    c = c << 30 | c >>> 2;
  }
  for (; j < 40; j += 5) {
    f3 = b ^ c ^ d;
    t = a << 5 | a >>> 27;
    e = t + f3 + e + 1859775393 + blocks3[j] << 0;
    b = b << 30 | b >>> 2;
    f3 = a ^ b ^ c;
    t = e << 5 | e >>> 27;
    d = t + f3 + d + 1859775393 + blocks3[j + 1] << 0;
    a = a << 30 | a >>> 2;
    f3 = e ^ a ^ b;
    t = d << 5 | d >>> 27;
    c = t + f3 + c + 1859775393 + blocks3[j + 2] << 0;
    e = e << 30 | e >>> 2;
    f3 = d ^ e ^ a;
    t = c << 5 | c >>> 27;
    b = t + f3 + b + 1859775393 + blocks3[j + 3] << 0;
    d = d << 30 | d >>> 2;
    f3 = c ^ d ^ e;
    t = b << 5 | b >>> 27;
    a = t + f3 + a + 1859775393 + blocks3[j + 4] << 0;
    c = c << 30 | c >>> 2;
  }
  for (; j < 60; j += 5) {
    f3 = b & c | b & d | c & d;
    t = a << 5 | a >>> 27;
    e = t + f3 + e - 1894007588 + blocks3[j] << 0;
    b = b << 30 | b >>> 2;
    f3 = a & b | a & c | b & c;
    t = e << 5 | e >>> 27;
    d = t + f3 + d - 1894007588 + blocks3[j + 1] << 0;
    a = a << 30 | a >>> 2;
    f3 = e & a | e & b | a & b;
    t = d << 5 | d >>> 27;
    c = t + f3 + c - 1894007588 + blocks3[j + 2] << 0;
    e = e << 30 | e >>> 2;
    f3 = d & e | d & a | e & a;
    t = c << 5 | c >>> 27;
    b = t + f3 + b - 1894007588 + blocks3[j + 3] << 0;
    d = d << 30 | d >>> 2;
    f3 = c & d | c & e | d & e;
    t = b << 5 | b >>> 27;
    a = t + f3 + a - 1894007588 + blocks3[j + 4] << 0;
    c = c << 30 | c >>> 2;
  }
  for (; j < 80; j += 5) {
    f3 = b ^ c ^ d;
    t = a << 5 | a >>> 27;
    e = t + f3 + e - 899497514 + blocks3[j] << 0;
    b = b << 30 | b >>> 2;
    f3 = a ^ b ^ c;
    t = e << 5 | e >>> 27;
    d = t + f3 + d - 899497514 + blocks3[j + 1] << 0;
    a = a << 30 | a >>> 2;
    f3 = e ^ a ^ b;
    t = d << 5 | d >>> 27;
    c = t + f3 + c - 899497514 + blocks3[j + 2] << 0;
    e = e << 30 | e >>> 2;
    f3 = d ^ e ^ a;
    t = c << 5 | c >>> 27;
    b = t + f3 + b - 899497514 + blocks3[j + 3] << 0;
    d = d << 30 | d >>> 2;
    f3 = c ^ d ^ e;
    t = b << 5 | b >>> 27;
    a = t + f3 + a - 899497514 + blocks3[j + 4] << 0;
    c = c << 30 | c >>> 2;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b << 0;
  this.h2 = this.h2 + c << 0;
  this.h3 = this.h3 + d << 0;
  this.h4 = this.h4 + e << 0;
};
Sha1.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4;
  return HEX_CHARS[h0 >> 28 & 15] + HEX_CHARS[h0 >> 24 & 15] + HEX_CHARS[h0 >> 20 & 15] + HEX_CHARS[h0 >> 16 & 15] + HEX_CHARS[h0 >> 12 & 15] + HEX_CHARS[h0 >> 8 & 15] + HEX_CHARS[h0 >> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >> 28 & 15] + HEX_CHARS[h1 >> 24 & 15] + HEX_CHARS[h1 >> 20 & 15] + HEX_CHARS[h1 >> 16 & 15] + HEX_CHARS[h1 >> 12 & 15] + HEX_CHARS[h1 >> 8 & 15] + HEX_CHARS[h1 >> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >> 28 & 15] + HEX_CHARS[h2 >> 24 & 15] + HEX_CHARS[h2 >> 20 & 15] + HEX_CHARS[h2 >> 16 & 15] + HEX_CHARS[h2 >> 12 & 15] + HEX_CHARS[h2 >> 8 & 15] + HEX_CHARS[h2 >> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >> 28 & 15] + HEX_CHARS[h3 >> 24 & 15] + HEX_CHARS[h3 >> 20 & 15] + HEX_CHARS[h3 >> 16 & 15] + HEX_CHARS[h3 >> 12 & 15] + HEX_CHARS[h3 >> 8 & 15] + HEX_CHARS[h3 >> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >> 28 & 15] + HEX_CHARS[h4 >> 24 & 15] + HEX_CHARS[h4 >> 20 & 15] + HEX_CHARS[h4 >> 16 & 15] + HEX_CHARS[h4 >> 12 & 15] + HEX_CHARS[h4 >> 8 & 15] + HEX_CHARS[h4 >> 4 & 15] + HEX_CHARS[h4 & 15];
};
Sha1.prototype.toString = Sha1.prototype.hex;
Sha1.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4;
  return [
    h0 >> 24 & 255,
    h0 >> 16 & 255,
    h0 >> 8 & 255,
    h0 & 255,
    h1 >> 24 & 255,
    h1 >> 16 & 255,
    h1 >> 8 & 255,
    h1 & 255,
    h2 >> 24 & 255,
    h2 >> 16 & 255,
    h2 >> 8 & 255,
    h2 & 255,
    h3 >> 24 & 255,
    h3 >> 16 & 255,
    h3 >> 8 & 255,
    h3 & 255,
    h4 >> 24 & 255,
    h4 >> 16 & 255,
    h4 >> 8 & 255,
    h4 & 255
  ];
};
Sha1.prototype.array = Sha1.prototype.digest;
Sha1.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(20);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  return buffer;
};
var hasLoggedWarning = false;
var insecureHash = (message) => {
  if (!hasLoggedWarning) {
    console.warn([
      `The default method for hashing keys is insecure and will be replaced in a future version,`,
      `but hasn't been replaced yet as to not break existing caches. It's recommended that you use`,
      `a more secure hashing algorithm to avoid cache poisoning.`,
      ``,
      `See this page for more information:`,
      `|`,
      `└> https://js.langchain.com/docs/troubleshooting/warnings/insecure-cache-algorithm`
    ].join("\n"));
    hasLoggedWarning = true;
  }
  return new Sha1(true).update(message)["hex"]();
};

// node_modules/@langchain/core/dist/utils/js-sha256/hash.js
var HEX_CHARS2 = "0123456789abcdef".split("");
var EXTRA2 = [-2147483648, 8388608, 32768, 128];
var SHIFT2 = [24, 16, 8, 0];
var K = [
  1116352408,
  1899447441,
  3049323471,
  3921009573,
  961987163,
  1508970993,
  2453635748,
  2870763221,
  3624381080,
  310598401,
  607225278,
  1426881987,
  1925078388,
  2162078206,
  2614888103,
  3248222580,
  3835390401,
  4022224774,
  264347078,
  604807628,
  770255983,
  1249150122,
  1555081692,
  1996064986,
  2554220882,
  2821834349,
  2952996808,
  3210313671,
  3336571891,
  3584528711,
  113926993,
  338241895,
  666307205,
  773529912,
  1294757372,
  1396182291,
  1695183700,
  1986661051,
  2177026350,
  2456956037,
  2730485921,
  2820302411,
  3259730800,
  3345764771,
  3516065817,
  3600352804,
  4094571909,
  275423344,
  430227734,
  506948616,
  659060556,
  883997877,
  958139571,
  1322822218,
  1537002063,
  1747873779,
  1955562222,
  2024104815,
  2227730452,
  2361852424,
  2428436474,
  2756734187,
  3204031479,
  3329325298
];
var blocks2 = [];
function Sha256(is224, sharedMemory) {
  if (sharedMemory) {
    blocks2[0] = blocks2[16] = blocks2[1] = blocks2[2] = blocks2[3] = blocks2[4] = blocks2[5] = blocks2[6] = blocks2[7] = blocks2[8] = blocks2[9] = blocks2[10] = blocks2[11] = blocks2[12] = blocks2[13] = blocks2[14] = blocks2[15] = 0;
    this.blocks = blocks2;
  } else {
    this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
  }
  if (is224) {
    this.h0 = 3238371032;
    this.h1 = 914150663;
    this.h2 = 812702999;
    this.h3 = 4144912697;
    this.h4 = 4290775857;
    this.h5 = 1750603025;
    this.h6 = 1694076839;
    this.h7 = 3204075428;
  } else {
    this.h0 = 1779033703;
    this.h1 = 3144134277;
    this.h2 = 1013904242;
    this.h3 = 2773480762;
    this.h4 = 1359893119;
    this.h5 = 2600822924;
    this.h6 = 528734635;
    this.h7 = 1541459225;
  }
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
  this.is224 = is224;
}
Sha256.prototype.update = function(message) {
  if (this.finalized) {
    return;
  }
  var notString, type = typeof message;
  if (type !== "string") {
    if (type === "object") {
      if (message === null) {
        throw new Error(ERROR);
      } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
        message = new Uint8Array(message);
      } else if (!Array.isArray(message)) {
        if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
          throw new Error(ERROR);
        }
      }
    } else {
      throw new Error(ERROR);
    }
    notString = true;
  }
  var code, index = 0, i, length = message.length, blocks3 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks3[0] = this.block;
      this.block = blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
    }
    if (notString) {
      for (i = this.start; index < length && i < 64; ++index) {
        blocks3[i >>> 2] |= message[index] << SHIFT2[i++ & 3];
      }
    } else {
      for (i = this.start; index < length && i < 64; ++index) {
        code = message.charCodeAt(index);
        if (code < 128) {
          blocks3[i >>> 2] |= code << SHIFT2[i++ & 3];
        } else if (code < 2048) {
          blocks3[i >>> 2] |= (192 | code >>> 6) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code & 63) << SHIFT2[i++ & 3];
        } else if (code < 55296 || code >= 57344) {
          blocks3[i >>> 2] |= (224 | code >>> 12) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code & 63) << SHIFT2[i++ & 3];
        } else {
          code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
          blocks3[i >>> 2] |= (240 | code >>> 18) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code >>> 12 & 63) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT2[i++ & 3];
          blocks3[i >>> 2] |= (128 | code & 63) << SHIFT2[i++ & 3];
        }
      }
    }
    this.lastByteIndex = i;
    this.bytes += i - this.start;
    if (i >= 64) {
      this.block = blocks3[16];
      this.start = i - 64;
      this.hash();
      this.hashed = true;
    } else {
      this.start = i;
    }
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha256.prototype.finalize = function() {
  if (this.finalized) {
    return;
  }
  this.finalized = true;
  var blocks3 = this.blocks, i = this.lastByteIndex;
  blocks3[16] = this.block;
  blocks3[i >>> 2] |= EXTRA2[i & 3];
  this.block = blocks3[16];
  if (i >= 56) {
    if (!this.hashed) {
      this.hash();
    }
    blocks3[0] = this.block;
    blocks3[16] = blocks3[1] = blocks3[2] = blocks3[3] = blocks3[4] = blocks3[5] = blocks3[6] = blocks3[7] = blocks3[8] = blocks3[9] = blocks3[10] = blocks3[11] = blocks3[12] = blocks3[13] = blocks3[14] = blocks3[15] = 0;
  }
  blocks3[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks3[15] = this.bytes << 3;
  this.hash();
};
Sha256.prototype.hash = function() {
  var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f3 = this.h5, g = this.h6, h = this.h7, blocks3 = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;
  for (j = 16; j < 64; ++j) {
    t1 = blocks3[j - 15];
    s0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;
    t1 = blocks3[j - 2];
    s1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;
    blocks3[j] = blocks3[j - 16] + s0 + blocks3[j - 7] + s1 << 0;
  }
  bc = b & c;
  for (j = 0; j < 64; j += 4) {
    if (this.first) {
      if (this.is224) {
        ab = 300032;
        t1 = blocks3[0] - 1413257819;
        h = t1 - 150054599 << 0;
        d = t1 + 24177077 << 0;
      } else {
        ab = 704751109;
        t1 = blocks3[0] - 210244248;
        h = t1 - 1521486534 << 0;
        d = t1 + 143694565 << 0;
      }
      this.first = false;
    } else {
      s0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);
      s1 = (e >>> 6 | e << 26) ^ (e >>> 11 | e << 21) ^ (e >>> 25 | e << 7);
      ab = a & b;
      maj = ab ^ a & c ^ bc;
      ch = e & f3 ^ ~e & g;
      t1 = h + s1 + ch + K[j] + blocks3[j];
      t2 = s0 + maj;
      h = d + t1 << 0;
      d = t1 + t2 << 0;
    }
    s0 = (d >>> 2 | d << 30) ^ (d >>> 13 | d << 19) ^ (d >>> 22 | d << 10);
    s1 = (h >>> 6 | h << 26) ^ (h >>> 11 | h << 21) ^ (h >>> 25 | h << 7);
    da = d & a;
    maj = da ^ d & b ^ ab;
    ch = g & h ^ ~g & e;
    t1 = f3 + s1 + ch + K[j + 1] + blocks3[j + 1];
    t2 = s0 + maj;
    g = c + t1 << 0;
    c = t1 + t2 << 0;
    s0 = (c >>> 2 | c << 30) ^ (c >>> 13 | c << 19) ^ (c >>> 22 | c << 10);
    s1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);
    cd = c & d;
    maj = cd ^ c & a ^ da;
    ch = f3 & g ^ ~f3 & h;
    t1 = e + s1 + ch + K[j + 2] + blocks3[j + 2];
    t2 = s0 + maj;
    f3 = b + t1 << 0;
    b = t1 + t2 << 0;
    s0 = (b >>> 2 | b << 30) ^ (b >>> 13 | b << 19) ^ (b >>> 22 | b << 10);
    s1 = (f3 >>> 6 | f3 << 26) ^ (f3 >>> 11 | f3 << 21) ^ (f3 >>> 25 | f3 << 7);
    bc = b & c;
    maj = bc ^ b & d ^ cd;
    ch = f3 & g ^ ~f3 & h;
    t1 = e + s1 + ch + K[j + 3] + blocks3[j + 3];
    t2 = s0 + maj;
    e = a + t1 << 0;
    a = t1 + t2 << 0;
    this.chromeBugWorkAround = true;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b << 0;
  this.h2 = this.h2 + c << 0;
  this.h3 = this.h3 + d << 0;
  this.h4 = this.h4 + e << 0;
  this.h5 = this.h5 + f3 << 0;
  this.h6 = this.h6 + g << 0;
  this.h7 = this.h7 + h << 0;
};
Sha256.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var hex = HEX_CHARS2[h0 >>> 28 & 15] + HEX_CHARS2[h0 >>> 24 & 15] + HEX_CHARS2[h0 >>> 20 & 15] + HEX_CHARS2[h0 >>> 16 & 15] + HEX_CHARS2[h0 >>> 12 & 15] + HEX_CHARS2[h0 >>> 8 & 15] + HEX_CHARS2[h0 >>> 4 & 15] + HEX_CHARS2[h0 & 15] + HEX_CHARS2[h1 >>> 28 & 15] + HEX_CHARS2[h1 >>> 24 & 15] + HEX_CHARS2[h1 >>> 20 & 15] + HEX_CHARS2[h1 >>> 16 & 15] + HEX_CHARS2[h1 >>> 12 & 15] + HEX_CHARS2[h1 >>> 8 & 15] + HEX_CHARS2[h1 >>> 4 & 15] + HEX_CHARS2[h1 & 15] + HEX_CHARS2[h2 >>> 28 & 15] + HEX_CHARS2[h2 >>> 24 & 15] + HEX_CHARS2[h2 >>> 20 & 15] + HEX_CHARS2[h2 >>> 16 & 15] + HEX_CHARS2[h2 >>> 12 & 15] + HEX_CHARS2[h2 >>> 8 & 15] + HEX_CHARS2[h2 >>> 4 & 15] + HEX_CHARS2[h2 & 15] + HEX_CHARS2[h3 >>> 28 & 15] + HEX_CHARS2[h3 >>> 24 & 15] + HEX_CHARS2[h3 >>> 20 & 15] + HEX_CHARS2[h3 >>> 16 & 15] + HEX_CHARS2[h3 >>> 12 & 15] + HEX_CHARS2[h3 >>> 8 & 15] + HEX_CHARS2[h3 >>> 4 & 15] + HEX_CHARS2[h3 & 15] + HEX_CHARS2[h4 >>> 28 & 15] + HEX_CHARS2[h4 >>> 24 & 15] + HEX_CHARS2[h4 >>> 20 & 15] + HEX_CHARS2[h4 >>> 16 & 15] + HEX_CHARS2[h4 >>> 12 & 15] + HEX_CHARS2[h4 >>> 8 & 15] + HEX_CHARS2[h4 >>> 4 & 15] + HEX_CHARS2[h4 & 15] + HEX_CHARS2[h5 >>> 28 & 15] + HEX_CHARS2[h5 >>> 24 & 15] + HEX_CHARS2[h5 >>> 20 & 15] + HEX_CHARS2[h5 >>> 16 & 15] + HEX_CHARS2[h5 >>> 12 & 15] + HEX_CHARS2[h5 >>> 8 & 15] + HEX_CHARS2[h5 >>> 4 & 15] + HEX_CHARS2[h5 & 15] + HEX_CHARS2[h6 >>> 28 & 15] + HEX_CHARS2[h6 >>> 24 & 15] + HEX_CHARS2[h6 >>> 20 & 15] + HEX_CHARS2[h6 >>> 16 & 15] + HEX_CHARS2[h6 >>> 12 & 15] + HEX_CHARS2[h6 >>> 8 & 15] + HEX_CHARS2[h6 >>> 4 & 15] + HEX_CHARS2[h6 & 15];
  if (!this.is224) {
    hex += HEX_CHARS2[h7 >>> 28 & 15] + HEX_CHARS2[h7 >>> 24 & 15] + HEX_CHARS2[h7 >>> 20 & 15] + HEX_CHARS2[h7 >>> 16 & 15] + HEX_CHARS2[h7 >>> 12 & 15] + HEX_CHARS2[h7 >>> 8 & 15] + HEX_CHARS2[h7 >>> 4 & 15] + HEX_CHARS2[h7 & 15];
  }
  return hex;
};
Sha256.prototype.toString = Sha256.prototype.hex;
Sha256.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var arr2 = [
    h0 >>> 24 & 255,
    h0 >>> 16 & 255,
    h0 >>> 8 & 255,
    h0 & 255,
    h1 >>> 24 & 255,
    h1 >>> 16 & 255,
    h1 >>> 8 & 255,
    h1 & 255,
    h2 >>> 24 & 255,
    h2 >>> 16 & 255,
    h2 >>> 8 & 255,
    h2 & 255,
    h3 >>> 24 & 255,
    h3 >>> 16 & 255,
    h3 >>> 8 & 255,
    h3 & 255,
    h4 >>> 24 & 255,
    h4 >>> 16 & 255,
    h4 >>> 8 & 255,
    h4 & 255,
    h5 >>> 24 & 255,
    h5 >>> 16 & 255,
    h5 >>> 8 & 255,
    h5 & 255,
    h6 >>> 24 & 255,
    h6 >>> 16 & 255,
    h6 >>> 8 & 255,
    h6 & 255
  ];
  if (!this.is224) {
    arr2.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);
  }
  return arr2;
};
Sha256.prototype.array = Sha256.prototype.digest;
Sha256.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  dataView.setUint32(20, this.h5);
  dataView.setUint32(24, this.h6);
  if (!this.is224) {
    dataView.setUint32(28, this.h7);
  }
  return buffer;
};
var sha256 = (...strings) => {
  return new Sha256(false, true).update(strings.join("")).hex();
};

// node_modules/@langchain/core/dist/caches/base.js
var getCacheKey = (...strings) => insecureHash(strings.join("_"));
function deserializeStoredGeneration(storedGeneration) {
  if (storedGeneration.message !== void 0) {
    return {
      text: storedGeneration.text,
      message: mapStoredMessageToChatMessage(storedGeneration.message)
    };
  } else {
    return { text: storedGeneration.text };
  }
}
function serializeGeneration(generation) {
  const serializedValue = {
    text: generation.text
  };
  if (generation.message !== void 0) {
    serializedValue.message = generation.message.toDict();
  }
  return serializedValue;
}
var BaseCache = class {
  constructor() {
    Object.defineProperty(this, "keyEncoder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getCacheKey
    });
  }
  /**
   * Sets a custom key encoder function for the cache.
   * This function should take a prompt and an LLM key and return a string
   * that will be used as the cache key.
   * @param keyEncoderFn The custom key encoder function.
   */
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
};
var GLOBAL_MAP = /* @__PURE__ */ new Map();
var InMemoryCache = class _InMemoryCache extends BaseCache {
  constructor(map) {
    super();
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.cache = map ?? /* @__PURE__ */ new Map();
  }
  /**
   * Retrieves data from the cache using a prompt and an LLM key. If the
   * data is not found, it returns null.
   * @param prompt The prompt used to find the data.
   * @param llmKey The LLM key used to find the data.
   * @returns The data corresponding to the prompt and LLM key, or null if not found.
   */
  lookup(prompt, llmKey) {
    return Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);
  }
  /**
   * Updates the cache with new data using a prompt and an LLM key.
   * @param prompt The prompt used to store the data.
   * @param llmKey The LLM key used to store the data.
   * @param value The data to be stored.
   */
  async update(prompt, llmKey, value) {
    this.cache.set(this.keyEncoder(prompt, llmKey), value);
  }
  /**
   * Returns a global instance of InMemoryCache using a predefined global
   * map as the initial cache.
   * @returns A global instance of InMemoryCache.
   */
  static global() {
    return new _InMemoryCache(GLOBAL_MAP);
  }
};

// node_modules/@langchain/core/dist/chat_history.js
var chat_history_exports = {};
__export(chat_history_exports, {
  BaseChatMessageHistory: () => BaseChatMessageHistory,
  BaseListChatMessageHistory: () => BaseListChatMessageHistory,
  InMemoryChatMessageHistory: () => InMemoryChatMessageHistory
});
var BaseChatMessageHistory = class extends Serializable {
  /**
   * Add a list of messages.
   *
   * Implementations should override this method to handle bulk addition of messages
   * in an efficient manner to avoid unnecessary round-trips to the underlying store.
   *
   * @param messages - A list of BaseMessage objects to store.
   */
  async addMessages(messages) {
    for (const message of messages) {
      await this.addMessage(message);
    }
  }
};
var BaseListChatMessageHistory = class extends Serializable {
  /**
   * This is a convenience method for adding a human message string to the store.
   * Please note that this is a convenience method. Code should favor the
   * bulk addMessages interface instead to save on round-trips to the underlying
   * persistence layer.
   * This method may be deprecated in a future release.
   */
  addUserMessage(message) {
    return this.addMessage(new HumanMessage(message));
  }
  /** @deprecated Use addAIMessage instead */
  addAIChatMessage(message) {
    return this.addMessage(new AIMessage(message));
  }
  /**
   * This is a convenience method for adding an AI message string to the store.
   * Please note that this is a convenience method. Code should favor the bulk
   * addMessages interface instead to save on round-trips to the underlying
   * persistence layer.
   * This method may be deprecated in a future release.
   */
  addAIMessage(message) {
    return this.addMessage(new AIMessage(message));
  }
  /**
   * Add a list of messages.
   *
   * Implementations should override this method to handle bulk addition of messages
   * in an efficient manner to avoid unnecessary round-trips to the underlying store.
   *
   * @param messages - A list of BaseMessage objects to store.
   */
  async addMessages(messages) {
    for (const message of messages) {
      await this.addMessage(message);
    }
  }
  /**
   * Remove all messages from the store.
   */
  clear() {
    throw new Error("Not implemented.");
  }
};
var InMemoryChatMessageHistory = class extends BaseListChatMessageHistory {
  constructor(messages) {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "stores", "message", "in_memory"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.messages = messages ?? [];
  }
  /**
   * Method to get all the messages stored in the ChatMessageHistory
   * instance.
   * @returns Array of stored BaseMessage instances.
   */
  async getMessages() {
    return this.messages;
  }
  /**
   * Method to add a new message to the ChatMessageHistory instance.
   * @param message The BaseMessage instance to add.
   * @returns A promise that resolves when the message has been added.
   */
  async addMessage(message) {
    this.messages.push(message);
  }
  /**
   * Method to clear all the messages from the ChatMessageHistory instance.
   * @returns A promise that resolves when all messages have been cleared.
   */
  async clear() {
    this.messages = [];
  }
};

// node_modules/@langchain/core/dist/documents/index.js
var documents_exports = {};
__export(documents_exports, {
  BaseDocumentTransformer: () => BaseDocumentTransformer,
  Document: () => Document,
  MappingDocumentTransformer: () => MappingDocumentTransformer
});

// node_modules/@langchain/core/dist/documents/document.js
var Document = class {
  constructor(fields) {
    Object.defineProperty(this, "pageContent", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "id", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.pageContent = fields.pageContent !== void 0 ? fields.pageContent.toString() : "";
    this.metadata = fields.metadata ?? {};
    this.id = fields.id;
  }
};

// node_modules/@langchain/core/dist/documents/transformers.js
var BaseDocumentTransformer = class extends Runnable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "documents", "transformers"]
    });
  }
  /**
   * Method to invoke the document transformation. This method calls the
   * transformDocuments method with the provided input.
   * @param input The input documents to be transformed.
   * @param _options Optional configuration object to customize the behavior of callbacks.
   * @returns A Promise that resolves to the transformed documents.
   */
  invoke(input, _options) {
    return this.transformDocuments(input);
  }
};
var MappingDocumentTransformer = class extends BaseDocumentTransformer {
  async transformDocuments(documents) {
    const newDocuments = [];
    for (const document of documents) {
      const transformedDocument = await this._transformDocument(document);
      newDocuments.push(transformedDocument);
    }
    return newDocuments;
  }
};

// node_modules/@langchain/core/dist/embeddings.js
var embeddings_exports = {};
__export(embeddings_exports, {
  Embeddings: () => Embeddings
});
var Embeddings = class {
  constructor(params) {
    Object.defineProperty(this, "caller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.caller = new AsyncCaller(params ?? {});
  }
};

// node_modules/@langchain/core/dist/example_selectors/index.js
var example_selectors_exports = {};
__export(example_selectors_exports, {
  BaseExampleSelector: () => BaseExampleSelector,
  BasePromptSelector: () => BasePromptSelector,
  ConditionalPromptSelector: () => ConditionalPromptSelector,
  LengthBasedExampleSelector: () => LengthBasedExampleSelector,
  SemanticSimilarityExampleSelector: () => SemanticSimilarityExampleSelector,
  isChatModel: () => isChatModel,
  isLLM: () => isLLM
});

// node_modules/@langchain/core/dist/example_selectors/base.js
var BaseExampleSelector = class extends Serializable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "example_selectors", "base"]
    });
  }
};

// node_modules/@langchain/core/dist/example_selectors/conditional.js
var BasePromptSelector = class {
  /**
   * Asynchronous version of `getPrompt` that also accepts an options object
   * for partial variables.
   * @param llm The language model for which to get a prompt.
   * @param options Optional object for partial variables.
   * @returns A Promise that resolves to a prompt template.
   */
  async getPromptAsync(llm, options) {
    const prompt = this.getPrompt(llm);
    return prompt.partial((options == null ? void 0 : options.partialVariables) ?? {});
  }
};
var ConditionalPromptSelector = class extends BasePromptSelector {
  constructor(default_prompt, conditionals = []) {
    super();
    Object.defineProperty(this, "defaultPrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "conditionals", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.defaultPrompt = default_prompt;
    this.conditionals = conditionals;
  }
  /**
   * Method that selects a prompt based on a set of conditions. If none of
   * the conditions are met, it returns the default prompt.
   * @param llm The language model for which to get a prompt.
   * @returns A prompt template.
   */
  getPrompt(llm) {
    for (const [condition, prompt] of this.conditionals) {
      if (condition(llm)) {
        return prompt;
      }
    }
    return this.defaultPrompt;
  }
};
function isLLM(llm) {
  return llm._modelType() === "base_llm";
}
function isChatModel(llm) {
  return llm._modelType() === "base_chat_model";
}

// node_modules/@langchain/core/dist/example_selectors/length_based.js
function getLengthBased(text) {
  return text.split(/\n| /).length;
}
var LengthBasedExampleSelector = class _LengthBasedExampleSelector extends BaseExampleSelector {
  constructor(data) {
    super(data);
    Object.defineProperty(this, "examples", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "examplePrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "getTextLength", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getLengthBased
    });
    Object.defineProperty(this, "maxLength", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 2048
    });
    Object.defineProperty(this, "exampleTextLengths", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.examplePrompt = data.examplePrompt;
    this.maxLength = data.maxLength ?? 2048;
    this.getTextLength = data.getTextLength ?? getLengthBased;
  }
  /**
   * Adds an example to the list of examples and calculates its length.
   * @param example The example to be added.
   * @returns Promise that resolves when the example has been added and its length calculated.
   */
  async addExample(example) {
    this.examples.push(example);
    const stringExample = await this.examplePrompt.format(example);
    this.exampleTextLengths.push(this.getTextLength(stringExample));
  }
  /**
   * Calculates the lengths of the examples.
   * @param v Array of lengths of the examples.
   * @param values Instance of LengthBasedExampleSelector.
   * @returns Promise that resolves with an array of lengths of the examples.
   */
  async calculateExampleTextLengths(v, values) {
    if (v.length > 0) {
      return v;
    }
    const { examples, examplePrompt } = values;
    const stringExamples = await Promise.all(examples.map((eg) => examplePrompt.format(eg)));
    return stringExamples.map((eg) => this.getTextLength(eg));
  }
  /**
   * Selects examples until the total length of the selected examples
   * reaches the maxLength.
   * @param inputVariables The input variables for the examples.
   * @returns Promise that resolves with an array of selected examples.
   */
  async selectExamples(inputVariables) {
    const inputs = Object.values(inputVariables).join(" ");
    let remainingLength = this.maxLength - this.getTextLength(inputs);
    let i = 0;
    const examples = [];
    while (remainingLength > 0 && i < this.examples.length) {
      const newLength = remainingLength - this.exampleTextLengths[i];
      if (newLength < 0) {
        break;
      } else {
        examples.push(this.examples[i]);
        remainingLength = newLength;
      }
      i += 1;
    }
    return examples;
  }
  /**
   * Creates a new instance of LengthBasedExampleSelector and adds a list of
   * examples to it.
   * @param examples Array of examples to be added.
   * @param args Input parameters for the LengthBasedExampleSelector.
   * @returns Promise that resolves with a new instance of LengthBasedExampleSelector with the examples added.
   */
  static async fromExamples(examples, args) {
    const selector = new _LengthBasedExampleSelector(args);
    await Promise.all(examples.map((eg) => selector.addExample(eg)));
    return selector;
  }
};

// node_modules/@langchain/core/dist/example_selectors/semantic_similarity.js
function sortedValues(values) {
  return Object.keys(values).sort().map((key) => values[key]);
}
var SemanticSimilarityExampleSelector = class _SemanticSimilarityExampleSelector extends BaseExampleSelector {
  constructor(data) {
    super(data);
    Object.defineProperty(this, "vectorStoreRetriever", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "exampleKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.exampleKeys = data.exampleKeys;
    this.inputKeys = data.inputKeys;
    if (data.vectorStore !== void 0) {
      this.vectorStoreRetriever = data.vectorStore.asRetriever({
        k: data.k ?? 4,
        filter: data.filter
      });
    } else if (data.vectorStoreRetriever) {
      this.vectorStoreRetriever = data.vectorStoreRetriever;
    } else {
      throw new Error(`You must specify one of "vectorStore" and "vectorStoreRetriever".`);
    }
  }
  /**
   * Method that adds a new example to the vectorStore. The example is
   * converted to a string and added to the vectorStore as a document.
   * @param example The example to be added to the vectorStore.
   * @returns Promise that resolves when the example has been added to the vectorStore.
   */
  async addExample(example) {
    const inputKeys = this.inputKeys ?? Object.keys(example);
    const stringExample = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {})).join(" ");
    await this.vectorStoreRetriever.addDocuments([
      new Document({
        pageContent: stringExample,
        metadata: example
      })
    ]);
  }
  /**
   * Method that selects which examples to use based on semantic similarity.
   * It performs a similarity search in the vectorStore using the input
   * variables and returns the examples with the highest similarity.
   * @param inputVariables The input variables used for the similarity search.
   * @returns Promise that resolves with an array of the selected examples.
   */
  async selectExamples(inputVariables) {
    const inputKeys = this.inputKeys ?? Object.keys(inputVariables);
    const query = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: inputVariables[key] }), {})).join(" ");
    const exampleDocs = await this.vectorStoreRetriever.invoke(query);
    const examples = exampleDocs.map((doc) => doc.metadata);
    if (this.exampleKeys) {
      return examples.map((example) => this.exampleKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {}));
    }
    return examples;
  }
  /**
   * Static method that creates a new instance of
   * SemanticSimilarityExampleSelector. It takes a list of examples, an
   * instance of Embeddings, a VectorStore class, and an options object as
   * parameters. It converts the examples to strings, creates a VectorStore
   * from the strings and the embeddings, and returns a new
   * SemanticSimilarityExampleSelector with the created VectorStore and the
   * options provided.
   * @param examples The list of examples to be used.
   * @param embeddings The instance of Embeddings to be used.
   * @param vectorStoreCls The VectorStore class to be used.
   * @param options The options object for the SemanticSimilarityExampleSelector.
   * @returns Promise that resolves with a new instance of SemanticSimilarityExampleSelector.
   */
  static async fromExamples(examples, embeddings, vectorStoreCls, options = {}) {
    const inputKeys = options.inputKeys ?? null;
    const stringExamples = examples.map((example) => sortedValues(inputKeys ? inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {}) : example).join(" "));
    const vectorStore = await vectorStoreCls.fromTexts(
      stringExamples,
      examples,
      // metadatas
      embeddings,
      options
    );
    return new _SemanticSimilarityExampleSelector({
      vectorStore,
      k: options.k ?? 4,
      exampleKeys: options.exampleKeys,
      inputKeys: options.inputKeys
    });
  }
};

// node_modules/@langchain/core/dist/language_models/base.js
var base_exports4 = {};
__export(base_exports4, {
  BaseLangChain: () => BaseLangChain,
  BaseLanguageModel: () => BaseLanguageModel,
  calculateMaxTokens: () => calculateMaxTokens,
  getEmbeddingContextSize: () => getEmbeddingContextSize,
  getModelContextSize: () => getModelContextSize,
  getModelNameForTiktoken: () => getModelNameForTiktoken,
  isOpenAITool: () => isOpenAITool
});

// node_modules/@langchain/core/dist/utils/tiktoken.js
var tiktoken_exports = {};
__export(tiktoken_exports, {
  encodingForModel: () => encodingForModel,
  getEncoding: () => getEncoding
});

// node_modules/js-tiktoken/dist/chunk-VL2OQCWN.js
var import_base64_js = __toESM(require_base64_js(), 1);
var __defProp = Object.defineProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField2 = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
function bytePairMerge(piece, ranks) {
  let parts = Array.from(
    { length: piece.length },
    (_, i) => ({ start: i, end: i + 1 })
  );
  while (parts.length > 1) {
    let minRank = null;
    for (let i = 0; i < parts.length - 1; i++) {
      const slice = piece.slice(parts[i].start, parts[i + 1].end);
      const rank = ranks.get(slice.join(","));
      if (rank == null)
        continue;
      if (minRank == null || rank < minRank[0]) {
        minRank = [rank, i];
      }
    }
    if (minRank != null) {
      const i = minRank[1];
      parts[i] = { start: parts[i].start, end: parts[i + 1].end };
      parts.splice(i + 1, 1);
    } else {
      break;
    }
  }
  return parts;
}
function bytePairEncode(piece, ranks) {
  if (piece.length === 1)
    return [ranks.get(piece.join(","))];
  return bytePairMerge(piece, ranks).map((p) => ranks.get(piece.slice(p.start, p.end).join(","))).filter((x) => x != null);
}
function escapeRegex(str) {
  return str.replace(/[\\^$*+?.()|[\]{}]/g, "\\$&");
}
var _Tiktoken = class {
  constructor(ranks, extendedSpecialTokens) {
    /** @internal */
    __publicField(this, "specialTokens");
    /** @internal */
    __publicField(this, "inverseSpecialTokens");
    /** @internal */
    __publicField(this, "patStr");
    /** @internal */
    __publicField(this, "textEncoder", new TextEncoder());
    /** @internal */
    __publicField(this, "textDecoder", new TextDecoder("utf-8"));
    /** @internal */
    __publicField(this, "rankMap", /* @__PURE__ */ new Map());
    /** @internal */
    __publicField(this, "textMap", /* @__PURE__ */ new Map());
    this.patStr = ranks.pat_str;
    const uncompressed = ranks.bpe_ranks.split("\n").filter(Boolean).reduce((memo, x) => {
      const [_, offsetStr, ...tokens] = x.split(" ");
      const offset = Number.parseInt(offsetStr, 10);
      tokens.forEach((token, i) => memo[token] = offset + i);
      return memo;
    }, {});
    for (const [token, rank] of Object.entries(uncompressed)) {
      const bytes = import_base64_js.default.toByteArray(token);
      this.rankMap.set(bytes.join(","), rank);
      this.textMap.set(rank, bytes);
    }
    this.specialTokens = { ...ranks.special_tokens, ...extendedSpecialTokens };
    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {
      memo[rank] = this.textEncoder.encode(text);
      return memo;
    }, {});
  }
  encode(text, allowedSpecial = [], disallowedSpecial = "all") {
    const regexes = new RegExp(this.patStr, "ug");
    const specialRegex = _Tiktoken.specialTokenRegex(
      Object.keys(this.specialTokens)
    );
    const ret = [];
    const allowedSpecialSet = new Set(
      allowedSpecial === "all" ? Object.keys(this.specialTokens) : allowedSpecial
    );
    const disallowedSpecialSet = new Set(
      disallowedSpecial === "all" ? Object.keys(this.specialTokens).filter(
        (x) => !allowedSpecialSet.has(x)
      ) : disallowedSpecial
    );
    if (disallowedSpecialSet.size > 0) {
      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([
        ...disallowedSpecialSet
      ]);
      const specialMatch = text.match(disallowedSpecialRegex);
      if (specialMatch != null) {
        throw new Error(
          `The text contains a special token that is not allowed: ${specialMatch[0]}`
        );
      }
    }
    let start = 0;
    while (true) {
      let nextSpecial = null;
      let startFind = start;
      while (true) {
        specialRegex.lastIndex = startFind;
        nextSpecial = specialRegex.exec(text);
        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0]))
          break;
        startFind = nextSpecial.index + 1;
      }
      const end = (nextSpecial == null ? void 0 : nextSpecial.index) ?? text.length;
      for (const match of text.substring(start, end).matchAll(regexes)) {
        const piece = this.textEncoder.encode(match[0]);
        const token2 = this.rankMap.get(piece.join(","));
        if (token2 != null) {
          ret.push(token2);
          continue;
        }
        ret.push(...bytePairEncode(piece, this.rankMap));
      }
      if (nextSpecial == null)
        break;
      let token = this.specialTokens[nextSpecial[0]];
      ret.push(token);
      start = nextSpecial.index + nextSpecial[0].length;
    }
    return ret;
  }
  decode(tokens) {
    const res = [];
    let length = 0;
    for (let i2 = 0; i2 < tokens.length; ++i2) {
      const token = tokens[i2];
      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];
      if (bytes != null) {
        res.push(bytes);
        length += bytes.length;
      }
    }
    const mergedArray = new Uint8Array(length);
    let i = 0;
    for (const bytes of res) {
      mergedArray.set(bytes, i);
      i += bytes.length;
    }
    return this.textDecoder.decode(mergedArray);
  }
};
var Tiktoken = _Tiktoken;
__publicField2(Tiktoken, "specialTokenRegex", (tokens) => {
  return new RegExp(tokens.map((i) => escapeRegex(i)).join("|"), "g");
});
function getEncodingNameForModel(model) {
  switch (model) {
    case "gpt2": {
      return "gpt2";
    }
    case "code-cushman-001":
    case "code-cushman-002":
    case "code-davinci-001":
    case "code-davinci-002":
    case "cushman-codex":
    case "davinci-codex":
    case "davinci-002":
    case "text-davinci-002":
    case "text-davinci-003": {
      return "p50k_base";
    }
    case "code-davinci-edit-001":
    case "text-davinci-edit-001": {
      return "p50k_edit";
    }
    case "ada":
    case "babbage":
    case "babbage-002":
    case "code-search-ada-code-001":
    case "code-search-babbage-code-001":
    case "curie":
    case "davinci":
    case "text-ada-001":
    case "text-babbage-001":
    case "text-curie-001":
    case "text-davinci-001":
    case "text-search-ada-doc-001":
    case "text-search-babbage-doc-001":
    case "text-search-curie-doc-001":
    case "text-search-davinci-doc-001":
    case "text-similarity-ada-001":
    case "text-similarity-babbage-001":
    case "text-similarity-curie-001":
    case "text-similarity-davinci-001": {
      return "r50k_base";
    }
    case "gpt-3.5-turbo-instruct-0914":
    case "gpt-3.5-turbo-instruct":
    case "gpt-3.5-turbo-16k-0613":
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo":
    case "gpt-4-32k-0613":
    case "gpt-4-32k-0314":
    case "gpt-4-32k":
    case "gpt-4-0613":
    case "gpt-4-0314":
    case "gpt-4":
    case "gpt-3.5-turbo-1106":
    case "gpt-35-turbo":
    case "gpt-4-1106-preview":
    case "gpt-4-vision-preview":
    case "gpt-3.5-turbo-0125":
    case "gpt-4-turbo":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-turbo-preview":
    case "gpt-4-0125-preview":
    case "text-embedding-ada-002":
    case "text-embedding-3-small":
    case "text-embedding-3-large": {
      return "cl100k_base";
    }
    case "gpt-4o":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
    case "gpt-4o-2024-11-20":
    case "gpt-4o-mini-2024-07-18":
    case "gpt-4o-mini":
    case "gpt-4o-search-preview":
    case "gpt-4o-search-preview-2025-03-11":
    case "gpt-4o-mini-search-preview":
    case "gpt-4o-mini-search-preview-2025-03-11":
    case "gpt-4o-audio-preview":
    case "gpt-4o-audio-preview-2024-12-17":
    case "gpt-4o-audio-preview-2024-10-01":
    case "gpt-4o-mini-audio-preview":
    case "gpt-4o-mini-audio-preview-2024-12-17":
    case "o1":
    case "o1-2024-12-17":
    case "o1-mini":
    case "o1-mini-2024-09-12":
    case "o1-preview":
    case "o1-preview-2024-09-12":
    case "o1-pro":
    case "o1-pro-2025-03-19":
    case "o3":
    case "o3-2025-04-16":
    case "o3-mini":
    case "o3-mini-2025-01-31":
    case "o4-mini":
    case "o4-mini-2025-04-16":
    case "chatgpt-4o-latest":
    case "gpt-4o-realtime":
    case "gpt-4o-realtime-preview-2024-10-01":
    case "gpt-4o-realtime-preview-2024-12-17":
    case "gpt-4o-mini-realtime-preview":
    case "gpt-4o-mini-realtime-preview-2024-12-17":
    case "gpt-4.1":
    case "gpt-4.1-2025-04-14":
    case "gpt-4.1-mini":
    case "gpt-4.1-mini-2025-04-14":
    case "gpt-4.1-nano":
    case "gpt-4.1-nano-2025-04-14":
    case "gpt-4.5-preview":
    case "gpt-4.5-preview-2025-02-27":
    case "gpt-5":
    case "gpt-5-2025-08-07":
    case "gpt-5-nano":
    case "gpt-5-nano-2025-08-07":
    case "gpt-5-mini":
    case "gpt-5-mini-2025-08-07":
    case "gpt-5-chat-latest": {
      return "o200k_base";
    }
    default:
      throw new Error("Unknown model");
  }
}

// node_modules/@langchain/core/dist/utils/tiktoken.js
var cache = {};
var caller = new AsyncCaller({});
async function getEncoding(encoding) {
  if (!(encoding in cache)) {
    cache[encoding] = caller.fetch(`https://tiktoken.pages.dev/js/${encoding}.json`).then((res) => res.json()).then((data) => new Tiktoken(data)).catch((e) => {
      delete cache[encoding];
      throw e;
    });
  }
  return await cache[encoding];
}
async function encodingForModel(model) {
  return getEncoding(getEncodingNameForModel(model));
}

// node_modules/@langchain/core/dist/language_models/base.js
var getModelNameForTiktoken = (modelName) => {
  if (modelName.startsWith("gpt-3.5-turbo-16k")) {
    return "gpt-3.5-turbo-16k";
  }
  if (modelName.startsWith("gpt-3.5-turbo-")) {
    return "gpt-3.5-turbo";
  }
  if (modelName.startsWith("gpt-4-32k")) {
    return "gpt-4-32k";
  }
  if (modelName.startsWith("gpt-4-")) {
    return "gpt-4";
  }
  if (modelName.startsWith("gpt-4o")) {
    return "gpt-4o";
  }
  return modelName;
};
var getEmbeddingContextSize = (modelName) => {
  switch (modelName) {
    case "text-embedding-ada-002":
      return 8191;
    default:
      return 2046;
  }
};
var getModelContextSize = (modelName) => {
  switch (getModelNameForTiktoken(modelName)) {
    case "gpt-3.5-turbo-16k":
      return 16384;
    case "gpt-3.5-turbo":
      return 4096;
    case "gpt-4-32k":
      return 32768;
    case "gpt-4":
      return 8192;
    case "text-davinci-003":
      return 4097;
    case "text-curie-001":
      return 2048;
    case "text-babbage-001":
      return 2048;
    case "text-ada-001":
      return 2048;
    case "code-davinci-002":
      return 8e3;
    case "code-cushman-001":
      return 2048;
    default:
      return 4097;
  }
};
function isOpenAITool(tool2) {
  if (typeof tool2 !== "object" || !tool2)
    return false;
  if ("type" in tool2 && tool2.type === "function" && "function" in tool2 && typeof tool2.function === "object" && tool2.function && "name" in tool2.function && "parameters" in tool2.function) {
    return true;
  }
  return false;
}
var calculateMaxTokens = async ({ prompt, modelName }) => {
  let numTokens;
  try {
    numTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;
  } catch (error) {
    console.warn("Failed to calculate number of tokens, falling back to approximate count");
    numTokens = Math.ceil(prompt.length / 4);
  }
  const maxTokens = getModelContextSize(modelName);
  return maxTokens - numTokens;
};
var getVerbosity = () => false;
var BaseLangChain = class extends Runnable {
  get lc_attributes() {
    return {
      callbacks: void 0,
      verbose: void 0
    };
  }
  constructor(params) {
    super(params);
    Object.defineProperty(this, "verbose", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.verbose = params.verbose ?? getVerbosity();
    this.callbacks = params.callbacks;
    this.tags = params.tags ?? [];
    this.metadata = params.metadata ?? {};
  }
};
var BaseLanguageModel = class extends BaseLangChain {
  /**
   * Keys that the language model accepts as call options.
   */
  get callKeys() {
    return ["stop", "timeout", "signal", "tags", "metadata", "callbacks"];
  }
  constructor({ callbacks, callbackManager, ...params }) {
    const { cache: cache2, ...rest } = params;
    super({
      callbacks: callbacks ?? callbackManager,
      ...rest
    });
    Object.defineProperty(this, "caller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_encoding", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (typeof cache2 === "object") {
      this.cache = cache2;
    } else if (cache2) {
      this.cache = InMemoryCache.global();
    } else {
      this.cache = void 0;
    }
    this.caller = new AsyncCaller(params ?? {});
  }
  /**
   * Get the number of tokens in the content.
   * @param content The content to get the number of tokens for.
   * @returns The number of tokens in the content.
   */
  async getNumTokens(content) {
    let textContent;
    if (typeof content === "string") {
      textContent = content;
    } else {
      textContent = content.map((item) => {
        if (typeof item === "string")
          return item;
        if (item.type === "text" && "text" in item)
          return item.text;
        return "";
      }).join("");
    }
    let numTokens = Math.ceil(textContent.length / 4);
    if (!this._encoding) {
      try {
        this._encoding = await encodingForModel("modelName" in this ? getModelNameForTiktoken(this.modelName) : "gpt2");
      } catch (error) {
        console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
      }
    }
    if (this._encoding) {
      try {
        numTokens = this._encoding.encode(textContent).length;
      } catch (error) {
        console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
      }
    }
    return numTokens;
  }
  static _convertInputToPromptValue(input) {
    if (typeof input === "string") {
      return new StringPromptValue(input);
    } else if (Array.isArray(input)) {
      return new ChatPromptValue(input.map(coerceMessageLikeToMessage));
    } else {
      return input;
    }
  }
  /**
   * Get the identifying parameters of the LLM.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _identifyingParams() {
    return {};
  }
  /**
   * Create a unique cache key for a specific call to a specific language model.
   * @param callOptions Call options for the model
   * @returns A unique cache key.
   */
  _getSerializedCacheKeyParametersForCall({ config, ...callOptions }) {
    const params = {
      ...this._identifyingParams(),
      ...callOptions,
      _type: this._llmType(),
      _model: this._modelType()
    };
    const filteredEntries = Object.entries(params).filter(([_, value]) => value !== void 0);
    const serializedEntries = filteredEntries.map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(",");
    return serializedEntries;
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
   * @deprecated
   * Load an LLM from a json-like object describing it.
   */
  static async deserialize(_data) {
    throw new Error("Use .toJSON() instead");
  }
};

// node_modules/@langchain/core/dist/language_models/chat_models.js
var chat_models_exports = {};
__export(chat_models_exports, {
  BaseChatModel: () => BaseChatModel,
  SimpleChatModel: () => SimpleChatModel,
  createChatMessageChunkEncoderStream: () => createChatMessageChunkEncoderStream
});

// node_modules/@langchain/core/dist/runnables/passthrough.js
var RunnablePassthrough = class extends Runnable {
  static lc_name() {
    return "RunnablePassthrough";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (fields) {
      this.func = fields.func;
    }
  }
  async invoke(input, options) {
    const config = ensureConfig(options);
    if (this.func) {
      await this.func(input, config);
    }
    return this._callWithConfig((input2) => Promise.resolve(input2), input, config);
  }
  async *transform(generator, options) {
    const config = ensureConfig(options);
    let finalOutput;
    let finalOutputSupported = true;
    for await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config)) {
      yield chunk;
      if (finalOutputSupported) {
        if (finalOutput === void 0) {
          finalOutput = chunk;
        } else {
          try {
            finalOutput = concat(finalOutput, chunk);
          } catch {
            finalOutput = void 0;
            finalOutputSupported = false;
          }
        }
      }
    }
    if (this.func && finalOutput !== void 0) {
      await this.func(finalOutput, config);
    }
  }
  /**
   * A runnable that assigns key-value pairs to the input.
   *
   * The example below shows how you could use it with an inline function.
   *
   * @example
   * ```typescript
   * const prompt =
   *   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}
   * Question: {question}
   * SQL Query:`);
   *
   * // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`
   * // call (in this example it's the question), along with any inputs passed to the `.assign()` method.
   * // In this case, we're passing the schema.
   * const sqlQueryGeneratorChain = RunnableSequence.from([
   *   RunnablePassthrough.assign({
   *     schema: async () => db.getTableInfo(),
   *   }),
   *   prompt,
   *   new ChatOpenAI({ model: "gpt-4o-mini" }).withConfig({ stop: ["\nSQLResult:"] }),
   *   new StringOutputParser(),
   * ]);
   * const result = await sqlQueryGeneratorChain.invoke({
   *   question: "How many employees are there?",
   * });
   * ```
   */
  static assign(mapping) {
    return new RunnableAssign(new RunnableMap({ steps: mapping }));
  }
};

// node_modules/@langchain/core/dist/language_models/chat_models.js
function createChatMessageChunkEncoderStream() {
  const textEncoder = new TextEncoder();
  return new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(textEncoder.encode(typeof chunk.content === "string" ? chunk.content : JSON.stringify(chunk.content)));
    }
  });
}
function _formatForTracing(messages) {
  const messagesToTrace = [];
  for (const message of messages) {
    let messageToTrace = message;
    if (Array.isArray(message.content)) {
      for (let idx = 0; idx < message.content.length; idx++) {
        const block = message.content[idx];
        if (isURLContentBlock(block) || isBase64ContentBlock(block)) {
          if (messageToTrace === message) {
            messageToTrace = new message.constructor({
              ...messageToTrace,
              content: [
                ...message.content.slice(0, idx),
                convertToOpenAIImageBlock(block),
                ...message.content.slice(idx + 1)
              ]
            });
          }
        }
      }
    }
    messagesToTrace.push(messageToTrace);
  }
  return messagesToTrace;
}
var BaseChatModel = class _BaseChatModel extends BaseLanguageModel {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "chat_models", this._llmType()]
    });
    Object.defineProperty(this, "disableStreaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  /**
   * Invokes the chat model with a single input.
   * @param input The input for the language model.
   * @param options The call options.
   * @returns A Promise that resolves to a BaseMessageChunk.
   */
  async invoke(input, options) {
    const promptValue = _BaseChatModel._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options == null ? void 0 : options.callbacks);
    const chatGeneration = result.generations[0][0];
    return chatGeneration.message;
  }
  // eslint-disable-next-line require-yield
  async *_streamResponseChunks(_messages, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  async *_streamIterator(input, options) {
    var _a2;
    if (this._streamResponseChunks === _BaseChatModel.prototype._streamResponseChunks || this.disableStreaming) {
      yield this.invoke(input, options);
    } else {
      const prompt = _BaseChatModel._convertInputToPromptValue(input);
      const messages = prompt.toChatMessages();
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const inheritableMetadata = {
        ...runnableConfig.metadata,
        ...this.getLsParams(callOptions)
      };
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName));
      let generationChunk;
      let llmOutput;
      try {
        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers == null ? void 0 : runManagers[0])) {
          if (chunk.message.id == null) {
            const runId = (_a2 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a2.runId;
            if (runId != null)
              chunk.message._updateId(`run-${runId}`);
          }
          chunk.message.response_metadata = {
            ...chunk.generationInfo,
            ...chunk.message.response_metadata
          };
          yield chunk.message;
          if (!generationChunk) {
            generationChunk = chunk;
          } else {
            generationChunk = generationChunk.concat(chunk);
          }
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) {
            llmOutput = {
              tokenUsage: {
                promptTokens: chunk.message.usage_metadata.input_tokens,
                completionTokens: chunk.message.usage_metadata.output_tokens,
                totalTokens: chunk.message.usage_metadata.total_tokens
              }
            };
          }
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMEnd({
        // TODO: Remove cast after figuring out inheritance
        generations: [[generationChunk]],
        llmOutput
      })));
    }
  }
  getLsParams(options) {
    const providerName = this.getName().startsWith("Chat") ? this.getName().replace("Chat", "") : this.getName();
    return {
      ls_model_type: "chat",
      ls_stop: options.stop,
      ls_provider: providerName
    };
  }
  /** @ignore */
  async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {
    var _a2, _b;
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) {
      runManagers = startedRunManagers;
    } else {
      const inheritableMetadata = {
        ...handledOptions.metadata,
        ...this.getLsParams(parsedOptions)
      };
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
        batch_size: 1
      };
      runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName));
    }
    const generations = [];
    const llmOutputs = [];
    const hasStreamingHandler = !!(runManagers == null ? void 0 : runManagers[0].handlers.find(callbackHandlerPrefersStreaming));
    if (hasStreamingHandler && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== _BaseChatModel.prototype._streamResponseChunks) {
      try {
        const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers == null ? void 0 : runManagers[0]);
        let aggregated;
        let llmOutput;
        for await (const chunk of stream) {
          if (chunk.message.id == null) {
            const runId = (_a2 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a2.runId;
            if (runId != null)
              chunk.message._updateId(`run-${runId}`);
          }
          if (aggregated === void 0) {
            aggregated = chunk;
          } else {
            aggregated = concat(aggregated, chunk);
          }
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) {
            llmOutput = {
              tokenUsage: {
                promptTokens: chunk.message.usage_metadata.input_tokens,
                completionTokens: chunk.message.usage_metadata.output_tokens,
                totalTokens: chunk.message.usage_metadata.total_tokens
              }
            };
          }
        }
        if (aggregated === void 0) {
          throw new Error("Received empty response from chat model call.");
        }
        generations.push([aggregated]);
        await (runManagers == null ? void 0 : runManagers[0].handleLLMEnd({
          generations,
          llmOutput
        }));
      } catch (e) {
        await (runManagers == null ? void 0 : runManagers[0].handleLLMError(e));
        throw e;
      }
    } else {
      const results = await Promise.allSettled(baseMessages.map((messageList, i) => this._generate(messageList, { ...parsedOptions, promptIndex: i }, runManagers == null ? void 0 : runManagers[i])));
      await Promise.all(results.map(async (pResult, i) => {
        var _a3, _b2, _c;
        if (pResult.status === "fulfilled") {
          const result = pResult.value;
          for (const generation of result.generations) {
            if (generation.message.id == null) {
              const runId = (_a3 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a3.runId;
              if (runId != null)
                generation.message._updateId(`run-${runId}`);
            }
            generation.message.response_metadata = {
              ...generation.generationInfo,
              ...generation.message.response_metadata
            };
          }
          if (result.generations.length === 1) {
            result.generations[0].message.response_metadata = {
              ...result.llmOutput,
              ...result.generations[0].message.response_metadata
            };
          }
          generations[i] = result.generations;
          llmOutputs[i] = result.llmOutput;
          return (_b2 = runManagers == null ? void 0 : runManagers[i]) == null ? void 0 : _b2.handleLLMEnd({
            generations: [result.generations],
            llmOutput: result.llmOutput
          });
        } else {
          await ((_c = runManagers == null ? void 0 : runManagers[i]) == null ? void 0 : _c.handleLLMError(pResult.reason));
          return Promise.reject(pResult.reason);
        }
      }));
    }
    const output = {
      generations,
      llmOutput: llmOutputs.length ? (_b = this._combineLLMOutput) == null ? void 0 : _b.call(this, ...llmOutputs) : void 0
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers == null ? void 0 : runManagers.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ messages, cache: cache2, llmStringKey, parsedOptions, handledOptions }) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const inheritableMetadata = {
      ...handledOptions.metadata,
      ...this.getLsParams(parsedOptions)
    };
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
      batch_size: 1
    };
    const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName));
    const missingPromptIndices = [];
    const results = await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {
      const prompt = _BaseChatModel._convertInputToPromptValue(baseMessage).toString();
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) {
        missingPromptIndices.push(index);
      }
      return result;
    }));
    const cachedResults = results.map((result, index) => ({ result, runManager: runManagers == null ? void 0 : runManagers[index] })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result2) => {
          if ("message" in result2 && isBaseMessage(result2.message) && isAIMessage(result2.message)) {
            result2.message.usage_metadata = {
              input_tokens: 0,
              output_tokens: 0,
              total_tokens: 0
            };
          }
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) {
          await (runManager == null ? void 0 : runManager.handleLLMNewToken(result[0].text));
        }
        return runManager == null ? void 0 : runManager.handleLLMEnd({
          generations: [result]
        }, void 0, void 0, void 0, {
          cached: true
        });
      } else {
        await (runManager == null ? void 0 : runManager.handleLLMError(promiseResult.reason, void 0, void 0, void 0, {
          cached: true
        }));
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers == null ? void 0 : runManagers.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
   * Generates chat based on the input messages.
   * @param messages An array of arrays of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to an LLMResult.
   */
  async generate(messages, options, callbacks) {
    let parsedOptions;
    if (Array.isArray(options)) {
      parsedOptions = { stop: options };
    } else {
      parsedOptions = options;
    }
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) {
      return this._generateUncached(baseMessages, callOptions, runnableConfig);
    }
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      messages: baseMessages,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers == null ? void 0 : startedRunManagers[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        const prompt = _BaseChatModel._convertInputToPromptValue(baseMessages[promptIndex]).toString();
        return cache2.update(prompt, llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return { generations, llmOutput };
  }
  /**
   * Get the parameters used to invoke the model
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  invocationParams(_options) {
    return {};
  }
  _modelType() {
    return "base_chat_model";
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this.invocationParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
   * Generates a prompt based on the input prompt values.
   * @param promptValues An array of BasePromptValue instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to an LLMResult.
   */
  async generatePrompt(promptValues, options, callbacks) {
    const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());
    return this.generate(promptMessages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Makes a single call to the chat model.
   * @param messages An array of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async call(messages, options, callbacks) {
    const result = await this.generate([messages.map(coerceMessageLikeToMessage)], options, callbacks);
    const generations = result.generations;
    return generations[0][0].message;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Makes a single call to the chat model with a prompt value.
   * @param promptValue The value of the prompt.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async callPrompt(promptValue, options, callbacks) {
    const promptMessages = promptValue.toChatMessages();
    return this.call(promptMessages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Predicts the next message based on the input messages.
   * @param messages An array of BaseMessage instances.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a BaseMessage.
   */
  async predictMessages(messages, options, callbacks) {
    return this.call(messages, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * Predicts the next message based on a text input.
   * @param text The text input.
   * @param options The call options or an array of stop sequences.
   * @param callbacks The callbacks for the language model.
   * @returns A Promise that resolves to a string.
   */
  async predict(text, options, callbacks) {
    const message = new HumanMessage(text);
    const result = await this.call([message], options, callbacks);
    if (typeof result.content !== "string") {
      throw new Error("Cannot use predict when output is not a string.");
    }
    return result.content;
  }
  withStructuredOutput(outputSchema, config) {
    if (typeof this.bindTools !== "function") {
      throw new Error(`Chat model must implement ".bindTools()" to use withStructuredOutput.`);
    }
    if (config == null ? void 0 : config.strict) {
      throw new Error(`"strict" mode is not supported for this model by default.`);
    }
    const schema = outputSchema;
    const name = config == null ? void 0 : config.name;
    const description = getSchemaDescription(schema) ?? "A function available to call.";
    const method = config == null ? void 0 : config.method;
    const includeRaw = config == null ? void 0 : config.includeRaw;
    if (method === "jsonMode") {
      throw new Error(`Base withStructuredOutput implementation only supports "functionCalling" as a method.`);
    }
    let functionName = name ?? "extract";
    let tools;
    if (isInteropZodSchema(schema)) {
      tools = [
        {
          type: "function",
          function: {
            name: functionName,
            description,
            parameters: toJsonSchema(schema)
          }
        }
      ];
    } else {
      if ("name" in schema) {
        functionName = schema.name;
      }
      tools = [
        {
          type: "function",
          function: {
            name: functionName,
            description,
            parameters: schema
          }
        }
      ];
    }
    const llm = this.bindTools(tools);
    const outputParser = RunnableLambda.from((input) => {
      if (!input.tool_calls || input.tool_calls.length === 0) {
        throw new Error("No tool calls found in the response.");
      }
      const toolCall = input.tool_calls.find((tc) => tc.name === functionName);
      if (!toolCall) {
        throw new Error(`No tool call found with name ${functionName}.`);
      }
      return toolCall.args;
    });
    if (!includeRaw) {
      return llm.pipe(outputParser).withConfig({
        runName: "StructuredOutput"
      });
    }
    const parserAssign = RunnablePassthrough.assign({
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      parsed: (input, config2) => outputParser.invoke(input.raw, config2)
    });
    const parserNone = RunnablePassthrough.assign({
      parsed: () => null
    });
    const parsedWithFallback = parserAssign.withFallbacks({
      fallbacks: [parserNone]
    });
    return RunnableSequence.from([
      {
        raw: llm
      },
      parsedWithFallback
    ]).withConfig({
      runName: "StructuredOutputRunnable"
    });
  }
};
var SimpleChatModel = class extends BaseChatModel {
  async _generate(messages, options, runManager) {
    const text = await this._call(messages, options, runManager);
    const message = new AIMessage(text);
    if (typeof message.content !== "string") {
      throw new Error("Cannot generate with a simple chat model when output is not a string.");
    }
    return {
      generations: [
        {
          text: message.content,
          message
        }
      ]
    };
  }
};

// node_modules/@langchain/core/dist/language_models/llms.js
var llms_exports = {};
__export(llms_exports, {
  BaseLLM: () => BaseLLM,
  LLM: () => LLM
});
var BaseLLM = class _BaseLLM extends BaseLanguageModel {
  constructor({ concurrency, ...rest }) {
    super(concurrency ? { maxConcurrency: concurrency, ...rest } : rest);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "llms", this._llmType()]
    });
  }
  /**
   * This method takes an input and options, and returns a string. It
   * converts the input to a prompt value and generates a result based on
   * the prompt.
   * @param input Input for the LLM.
   * @param options Options for the LLM call.
   * @returns A string result based on the prompt.
   */
  async invoke(input, options) {
    const promptValue = _BaseLLM._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options == null ? void 0 : options.callbacks);
    return result.generations[0][0].text;
  }
  // eslint-disable-next-line require-yield
  async *_streamResponseChunks(_input, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === _BaseLLM.prototype._streamResponseChunks) {
      yield this.invoke(input, options);
    } else {
      const prompt = _BaseLLM._convertInputToPromptValue(input);
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleLLMStart(this.toJSON(), [prompt.toString()], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName));
      let generation = new GenerationChunk({
        text: ""
      });
      try {
        for await (const chunk of this._streamResponseChunks(prompt.toString(), callOptions, runManagers == null ? void 0 : runManagers[0])) {
          if (!generation) {
            generation = chunk;
          } else {
            generation = generation.concat(chunk);
          }
          if (typeof chunk.text === "string") {
            yield chunk.text;
          }
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMEnd({
        generations: [[generation]]
      })));
    }
  }
  /**
   * This method takes prompt values, options, and callbacks, and generates
   * a result based on the prompts.
   * @param promptValues Prompt values for the LLM.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns An LLMResult based on the prompts.
   */
  async generatePrompt(promptValues, options, callbacks) {
    const prompts = promptValues.map((promptValue) => promptValue.toString());
    return this.generate(prompts, options, callbacks);
  }
  /**
   * Get the parameters used to invoke the model
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  invocationParams(_options) {
    return {};
  }
  _flattenLLMResult(llmResult) {
    const llmResults = [];
    for (let i = 0; i < llmResult.generations.length; i += 1) {
      const genList = llmResult.generations[i];
      if (i === 0) {
        llmResults.push({
          generations: [genList],
          llmOutput: llmResult.llmOutput
        });
      } else {
        const llmOutput = llmResult.llmOutput ? { ...llmResult.llmOutput, tokenUsage: {} } : void 0;
        llmResults.push({
          generations: [genList],
          llmOutput
        });
      }
    }
    return llmResults;
  }
  /** @ignore */
  async _generateUncached(prompts, parsedOptions, handledOptions, startedRunManagers) {
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === prompts.length) {
      runManagers = startedRunManagers;
    } else {
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
        batch_size: prompts.length
      };
      runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleLLMStart(this.toJSON(), prompts, handledOptions.runId, void 0, extra, void 0, void 0, handledOptions == null ? void 0 : handledOptions.runName));
    }
    const hasStreamingHandler = !!(runManagers == null ? void 0 : runManagers[0].handlers.find(callbackHandlerPrefersStreaming));
    let output;
    if (hasStreamingHandler && prompts.length === 1 && this._streamResponseChunks !== _BaseLLM.prototype._streamResponseChunks) {
      try {
        const stream = await this._streamResponseChunks(prompts[0], parsedOptions, runManagers == null ? void 0 : runManagers[0]);
        let aggregated;
        for await (const chunk of stream) {
          if (aggregated === void 0) {
            aggregated = chunk;
          } else {
            aggregated = concat(aggregated, chunk);
          }
        }
        if (aggregated === void 0) {
          throw new Error("Received empty response from chat model call.");
        }
        output = { generations: [[aggregated]], llmOutput: {} };
        await (runManagers == null ? void 0 : runManagers[0].handleLLMEnd(output));
      } catch (e) {
        await (runManagers == null ? void 0 : runManagers[0].handleLLMError(e));
        throw e;
      }
    } else {
      try {
        output = await this._generate(prompts, parsedOptions, runManagers == null ? void 0 : runManagers[0]);
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMError(err)));
        throw err;
      }
      const flattenedOutputs = this._flattenLLMResult(output);
      await Promise.all((runManagers ?? []).map((runManager, i) => runManager == null ? void 0 : runManager.handleLLMEnd(flattenedOutputs[i])));
    }
    const runIds = (runManagers == null ? void 0 : runManagers.map((manager) => manager.runId)) || void 0;
    Object.defineProperty(output, RUN_KEY, {
      value: runIds ? { runIds } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ prompts, cache: cache2, llmStringKey, parsedOptions, handledOptions, runId }) {
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
      batch_size: prompts.length
    };
    const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleLLMStart(this.toJSON(), prompts, runId, void 0, extra, void 0, void 0, handledOptions == null ? void 0 : handledOptions.runName));
    const missingPromptIndices = [];
    const results = await Promise.allSettled(prompts.map(async (prompt, index) => {
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) {
        missingPromptIndices.push(index);
      }
      return result;
    }));
    const cachedResults = results.map((result, index) => ({ result, runManager: runManagers == null ? void 0 : runManagers[index] })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result2) => {
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) {
          await (runManager == null ? void 0 : runManager.handleLLMNewToken(result[0].text));
        }
        return runManager == null ? void 0 : runManager.handleLLMEnd({
          generations: [result]
        }, void 0, void 0, void 0, {
          cached: true
        });
      } else {
        await (runManager == null ? void 0 : runManager.handleLLMError(promiseResult.reason, void 0, void 0, void 0, {
          cached: true
        }));
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers == null ? void 0 : runManagers.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
   * Run the LLM on the given prompts and input, handling caching.
   */
  async generate(prompts, options, callbacks) {
    if (!Array.isArray(prompts)) {
      throw new Error("Argument 'prompts' is expected to be a string[]");
    }
    let parsedOptions;
    if (Array.isArray(options)) {
      parsedOptions = { stop: options };
    } else {
      parsedOptions = options;
    }
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) {
      return this._generateUncached(prompts, callOptions, runnableConfig);
    }
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      prompts,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig,
      runId: runnableConfig.runId
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => prompts[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers == null ? void 0 : startedRunManagers[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        return cache2.update(prompts[promptIndex], llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return { generations, llmOutput };
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   * Convenience wrapper for {@link generate} that takes in a single string prompt and returns a single string output.
   */
  async call(prompt, options, callbacks) {
    const { generations } = await this.generate([prompt], options, callbacks);
    return generations[0][0].text;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * This method is similar to `call`, but it's used for making predictions
   * based on the input text.
   * @param text Input text for the prediction.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns A prediction based on the input text.
   */
  async predict(text, options, callbacks) {
    return this.call(text, options, callbacks);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.2.0.
   *
   * This method takes a list of messages, options, and callbacks, and
   * returns a predicted message.
   * @param messages A list of messages for the prediction.
   * @param options Options for the LLM call.
   * @param callbacks Callbacks for the LLM call.
   * @returns A predicted message based on the list of messages.
   */
  async predictMessages(messages, options, callbacks) {
    const text = getBufferString(messages);
    const prediction = await this.call(text, options, callbacks);
    return new AIMessage(prediction);
  }
  /**
   * Get the identifying parameters of the LLM.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _identifyingParams() {
    return {};
  }
  /**
   * @deprecated
   * Return a json-like object representing this LLM.
   */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  _modelType() {
    return "base_llm";
  }
};
var LLM = class extends BaseLLM {
  async _generate(prompts, options, runManager) {
    const generations = await Promise.all(prompts.map((prompt, promptIndex) => this._call(prompt, { ...options, promptIndex }, runManager).then((text) => [{ text }])));
    return { generations };
  }
};

// node_modules/@langchain/core/dist/memory.js
var memory_exports = {};
__export(memory_exports, {
  BaseMemory: () => BaseMemory,
  getInputValue: () => getInputValue,
  getOutputValue: () => getOutputValue,
  getPromptInputKey: () => getPromptInputKey
});
var BaseMemory = class {
};
var getValue = (values, key) => {
  if (key !== void 0) {
    return values[key];
  }
  const keys = Object.keys(values);
  if (keys.length === 1) {
    return values[keys[0]];
  }
};
var getInputValue = (inputValues, inputKey) => {
  const value = getValue(inputValues, inputKey);
  if (!value) {
    const keys = Object.keys(inputValues);
    throw new Error(`input values have ${keys.length} keys, you must specify an input key or pass only 1 key as input`);
  }
  return value;
};
var getOutputValue = (outputValues, outputKey) => {
  const value = getValue(outputValues, outputKey);
  if (!value && value !== "") {
    const keys = Object.keys(outputValues);
    throw new Error(`output values have ${keys.length} keys, you must specify an output key or pass only 1 key as output`);
  }
  return value;
};
function getPromptInputKey(inputs, memoryVariables) {
  const promptInputKeys = Object.keys(inputs).filter((key) => !memoryVariables.includes(key) && key !== "stop");
  if (promptInputKeys.length !== 1) {
    throw new Error(`One input key expected, but got ${promptInputKeys.length}`);
  }
  return promptInputKeys[0];
}

// node_modules/@langchain/core/dist/output_parsers/index.js
var output_parsers_exports = {};
__export(output_parsers_exports, {
  AsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,
  BaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,
  BaseLLMOutputParser: () => BaseLLMOutputParser,
  BaseOutputParser: () => BaseOutputParser,
  BaseTransformOutputParser: () => BaseTransformOutputParser,
  BytesOutputParser: () => BytesOutputParser,
  CommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,
  CustomListOutputParser: () => CustomListOutputParser,
  JsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,
  JsonOutputParser: () => JsonOutputParser,
  ListOutputParser: () => ListOutputParser,
  MarkdownListOutputParser: () => MarkdownListOutputParser,
  NumberedListOutputParser: () => NumberedListOutputParser,
  OutputParserException: () => OutputParserException,
  StringOutputParser: () => StringOutputParser,
  StructuredOutputParser: () => StructuredOutputParser,
  XMLOutputParser: () => XMLOutputParser,
  XML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,
  parseJsonMarkdown: () => parseJsonMarkdown,
  parsePartialJson: () => parsePartialJson,
  parseXMLMarkdown: () => parseXMLMarkdown
});

// node_modules/@langchain/core/dist/runnables/index.js
var runnables_exports = {};
__export(runnables_exports, {
  RouterRunnable: () => RouterRunnable,
  Runnable: () => Runnable,
  RunnableAssign: () => RunnableAssign,
  RunnableBinding: () => RunnableBinding,
  RunnableBranch: () => RunnableBranch,
  RunnableEach: () => RunnableEach,
  RunnableLambda: () => RunnableLambda,
  RunnableMap: () => RunnableMap,
  RunnableParallel: () => RunnableParallel,
  RunnablePassthrough: () => RunnablePassthrough,
  RunnablePick: () => RunnablePick,
  RunnableRetry: () => RunnableRetry,
  RunnableSequence: () => RunnableSequence,
  RunnableToolLike: () => RunnableToolLike,
  RunnableWithFallbacks: () => RunnableWithFallbacks,
  RunnableWithMessageHistory: () => RunnableWithMessageHistory,
  _coerceToRunnable: () => _coerceToRunnable,
  ensureConfig: () => ensureConfig,
  getCallbackManagerForConfig: () => getCallbackManagerForConfig,
  mergeConfigs: () => mergeConfigs,
  patchConfig: () => patchConfig,
  pickRunnableConfigKeys: () => pickRunnableConfigKeys
});

// node_modules/@langchain/core/dist/runnables/router.js
var RouterRunnable = class extends Runnable {
  static lc_name() {
    return "RouterRunnable";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "runnables", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.runnables = fields.runnables;
  }
  async invoke(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) {
      throw new Error(`No runnable associated with key "${key}".`);
    }
    return runnable.invoke(actualInput, ensureConfig(options));
  }
  async batch(inputs, options, batchOptions) {
    var _a2;
    const keys = inputs.map((input) => input.key);
    const actualInputs = inputs.map((input) => input.input);
    const missingKey = keys.find((key) => this.runnables[key] === void 0);
    if (missingKey !== void 0) {
      throw new Error(`One or more keys do not have a corresponding runnable.`);
    }
    const runnables = keys.map((key) => this.runnables[key]);
    const optionsList = this._getOptionsList(options ?? {}, inputs.length);
    const maxConcurrency = ((_a2 = optionsList[0]) == null ? void 0 : _a2.maxConcurrency) ?? (batchOptions == null ? void 0 : batchOptions.maxConcurrency);
    const batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;
    const batchResults = [];
    for (let i = 0; i < actualInputs.length; i += batchSize) {
      const batchPromises = actualInputs.slice(i, i + batchSize).map((actualInput, i2) => runnables[i2].invoke(actualInput, optionsList[i2]));
      const batchResult = await Promise.all(batchPromises);
      batchResults.push(batchResult);
    }
    return batchResults.flat();
  }
  async stream(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) {
      throw new Error(`No runnable associated with key "${key}".`);
    }
    return runnable.stream(actualInput, options);
  }
};

// node_modules/@langchain/core/dist/runnables/branch.js
var RunnableBranch = class extends Runnable {
  static lc_name() {
    return "RunnableBranch";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "runnables"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "default", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "branches", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.branches = fields.branches;
    this.default = fields.default;
  }
  /**
   * Convenience method for instantiating a RunnableBranch from
   * RunnableLikes (objects, functions, or Runnables).
   *
   * Each item in the input except for the last one should be a
   * tuple with two items. The first is a "condition" RunnableLike that
   * returns "true" if the second RunnableLike in the tuple should run.
   *
   * The final item in the input should be a RunnableLike that acts as a
   * default branch if no other branches match.
   *
   * @example
   * ```ts
   * import { RunnableBranch } from "@langchain/core/runnables";
   *
   * const branch = RunnableBranch.from([
   *   [(x: number) => x > 0, (x: number) => x + 1],
   *   [(x: number) => x < 0, (x: number) => x - 1],
   *   (x: number) => x
   * ]);
   * ```
   * @param branches An array where the every item except the last is a tuple of [condition, runnable]
   *   pairs. The last item is a default runnable which is invoked if no other condition matches.
   * @returns A new RunnableBranch.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static from(branches) {
    if (branches.length < 1) {
      throw new Error("RunnableBranch requires at least one branch");
    }
    const branchLikes = branches.slice(0, -1);
    const coercedBranches = branchLikes.map(([condition, runnable]) => [
      _coerceToRunnable(condition),
      _coerceToRunnable(runnable)
    ]);
    const defaultBranch = _coerceToRunnable(branches[branches.length - 1]);
    return new this({
      branches: coercedBranches,
      default: defaultBranch
    });
  }
  async _invoke(input, config, runManager) {
    let result;
    for (let i = 0; i < this.branches.length; i += 1) {
      const [condition, branchRunnable] = this.branches[i];
      const conditionValue = await condition.invoke(input, patchConfig(config, {
        callbacks: runManager == null ? void 0 : runManager.getChild(`condition:${i + 1}`)
      }));
      if (conditionValue) {
        result = await branchRunnable.invoke(input, patchConfig(config, {
          callbacks: runManager == null ? void 0 : runManager.getChild(`branch:${i + 1}`)
        }));
        break;
      }
    }
    if (!result) {
      result = await this.default.invoke(input, patchConfig(config, {
        callbacks: runManager == null ? void 0 : runManager.getChild("branch:default")
      }));
    }
    return result;
  }
  async invoke(input, config = {}) {
    return this._callWithConfig(this._invoke, input, config);
  }
  async *_streamIterator(input, config) {
    const callbackManager_ = await getCallbackManagerForConfig(config);
    const runManager = await (callbackManager_ == null ? void 0 : callbackManager_.handleChainStart(this.toJSON(), _coerceToDict(input, "input"), config == null ? void 0 : config.runId, void 0, void 0, void 0, config == null ? void 0 : config.runName));
    let finalOutput;
    let finalOutputSupported = true;
    let stream;
    try {
      for (let i = 0; i < this.branches.length; i += 1) {
        const [condition, branchRunnable] = this.branches[i];
        const conditionValue = await condition.invoke(input, patchConfig(config, {
          callbacks: runManager == null ? void 0 : runManager.getChild(`condition:${i + 1}`)
        }));
        if (conditionValue) {
          stream = await branchRunnable.stream(input, patchConfig(config, {
            callbacks: runManager == null ? void 0 : runManager.getChild(`branch:${i + 1}`)
          }));
          for await (const chunk of stream) {
            yield chunk;
            if (finalOutputSupported) {
              if (finalOutput === void 0) {
                finalOutput = chunk;
              } else {
                try {
                  finalOutput = concat(finalOutput, chunk);
                } catch (e) {
                  finalOutput = void 0;
                  finalOutputSupported = false;
                }
              }
            }
          }
          break;
        }
      }
      if (stream === void 0) {
        stream = await this.default.stream(input, patchConfig(config, {
          callbacks: runManager == null ? void 0 : runManager.getChild("branch:default")
        }));
        for await (const chunk of stream) {
          yield chunk;
          if (finalOutputSupported) {
            if (finalOutput === void 0) {
              finalOutput = chunk;
            } else {
              try {
                finalOutput = concat(finalOutput, chunk);
              } catch (e) {
                finalOutput = void 0;
                finalOutputSupported = false;
              }
            }
          }
        }
      }
    } catch (e) {
      await (runManager == null ? void 0 : runManager.handleChainError(e));
      throw e;
    }
    await (runManager == null ? void 0 : runManager.handleChainEnd(finalOutput ?? {}));
  }
};

// node_modules/@langchain/core/dist/runnables/history.js
var RunnableWithMessageHistory = class extends RunnableBinding {
  constructor(fields) {
    let historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: "loadHistory" });
    const messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;
    if (messagesKey) {
      historyChain = RunnablePassthrough.assign({
        [messagesKey]: historyChain
      }).withConfig({ runName: "insertHistory" });
    }
    const bound = historyChain.pipe(fields.runnable.withListeners({
      onEnd: (run, config2) => this._exitHistory(run, config2 ?? {})
    })).withConfig({ runName: "RunnableWithMessageHistory" });
    const config = fields.config ?? {};
    super({
      ...fields,
      config,
      bound
    });
    Object.defineProperty(this, "runnable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "historyMessagesKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "getMessageHistory", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.runnable = fields.runnable;
    this.getMessageHistory = fields.getMessageHistory;
    this.inputMessagesKey = fields.inputMessagesKey;
    this.outputMessagesKey = fields.outputMessagesKey;
    this.historyMessagesKey = fields.historyMessagesKey;
  }
  _getInputMessages(inputValue) {
    let parsedInputValue;
    if (typeof inputValue === "object" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {
      let key;
      if (this.inputMessagesKey) {
        key = this.inputMessagesKey;
      } else if (Object.keys(inputValue).length === 1) {
        key = Object.keys(inputValue)[0];
      } else {
        key = "input";
      }
      if (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) {
        parsedInputValue = inputValue[key][0];
      } else {
        parsedInputValue = inputValue[key];
      }
    } else {
      parsedInputValue = inputValue;
    }
    if (typeof parsedInputValue === "string") {
      return [new HumanMessage(parsedInputValue)];
    } else if (Array.isArray(parsedInputValue)) {
      return parsedInputValue;
    } else if (isBaseMessage(parsedInputValue)) {
      return [parsedInputValue];
    } else {
      throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.
Got ${JSON.stringify(parsedInputValue, null, 2)}`);
    }
  }
  _getOutputMessages(outputValue) {
    let parsedOutputValue;
    if (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== "string") {
      let key;
      if (this.outputMessagesKey !== void 0) {
        key = this.outputMessagesKey;
      } else if (Object.keys(outputValue).length === 1) {
        key = Object.keys(outputValue)[0];
      } else {
        key = "output";
      }
      if (outputValue.generations !== void 0) {
        parsedOutputValue = outputValue.generations[0][0].message;
      } else {
        parsedOutputValue = outputValue[key];
      }
    } else {
      parsedOutputValue = outputValue;
    }
    if (typeof parsedOutputValue === "string") {
      return [new AIMessage(parsedOutputValue)];
    } else if (Array.isArray(parsedOutputValue)) {
      return parsedOutputValue;
    } else if (isBaseMessage(parsedOutputValue)) {
      return [parsedOutputValue];
    } else {
      throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);
    }
  }
  async _enterHistory(input, kwargs) {
    var _a2;
    const history = (_a2 = kwargs == null ? void 0 : kwargs.configurable) == null ? void 0 : _a2.messageHistory;
    const messages = await history.getMessages();
    if (this.historyMessagesKey === void 0) {
      return messages.concat(this._getInputMessages(input));
    }
    return messages;
  }
  async _exitHistory(run, config) {
    var _a2;
    const history = (_a2 = config.configurable) == null ? void 0 : _a2.messageHistory;
    let inputs;
    if (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) {
      inputs = run.inputs[0];
    } else {
      inputs = run.inputs;
    }
    let inputMessages = this._getInputMessages(inputs);
    if (this.historyMessagesKey === void 0) {
      const existingMessages = await history.getMessages();
      inputMessages = inputMessages.slice(existingMessages.length);
    }
    const outputValue = run.outputs;
    if (!outputValue) {
      throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);
    }
    const outputMessages = this._getOutputMessages(outputValue);
    await history.addMessages([...inputMessages, ...outputMessages]);
  }
  async _mergeConfig(...configs) {
    const config = await super._mergeConfig(...configs);
    if (!config.configurable || !config.configurable.sessionId) {
      const exampleInput = {
        [this.inputMessagesKey ?? "input"]: "foo"
      };
      const exampleConfig = { configurable: { sessionId: "123" } };
      throw new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()
eg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify(exampleConfig)})`);
    }
    const { sessionId } = config.configurable;
    config.configurable.messageHistory = await this.getMessageHistory(sessionId);
    return config;
  }
};

// node_modules/@langchain/core/dist/output_parsers/base.js
var BaseLLMOutputParser = class extends Runnable {
  /**
   * Parses the result of an LLM call with a given prompt. By default, it
   * simply calls `parseResult`.
   * @param generations The generations from an LLM call.
   * @param _prompt The prompt used in the LLM call.
   * @param callbacks Optional callbacks.
   * @returns A promise of the parsed output.
   */
  parseResultWithPrompt(generations, _prompt, callbacks) {
    return this.parseResult(generations, callbacks);
  }
  _baseMessageToString(message) {
    return typeof message.content === "string" ? message.content : this._baseMessageContentToString(message.content);
  }
  _baseMessageContentToString(content) {
    return JSON.stringify(content);
  }
  /**
   * Calls the parser with a given input and optional configuration options.
   * If the input is a string, it creates a generation with the input as
   * text and calls `parseResult`. If the input is a `BaseMessage`, it
   * creates a generation with the input as a message and the content of the
   * input as text, and then calls `parseResult`.
   * @param input The input to the parser, which can be a string or a `BaseMessage`.
   * @param options Optional configuration options.
   * @returns A promise of the parsed output.
   */
  async invoke(input, options) {
    if (typeof input === "string") {
      return this._callWithConfig(async (input2, options2) => this.parseResult([{ text: input2 }], options2 == null ? void 0 : options2.callbacks), input, { ...options, runType: "parser" });
    } else {
      return this._callWithConfig(async (input2, options2) => this.parseResult([
        {
          message: input2,
          text: this._baseMessageToString(input2)
        }
      ], options2 == null ? void 0 : options2.callbacks), input, { ...options, runType: "parser" });
    }
  }
};
var BaseOutputParser = class extends BaseLLMOutputParser {
  parseResult(generations, callbacks) {
    return this.parse(generations[0].text, callbacks);
  }
  async parseWithPrompt(text, _prompt, callbacks) {
    return this.parse(text, callbacks);
  }
  /**
   * Return the string type key uniquely identifying this class of parser
   */
  _type() {
    throw new Error("_type not implemented");
  }
};
var OutputParserException = class extends Error {
  constructor(message, llmOutput, observation, sendToLLM = false) {
    super(message);
    Object.defineProperty(this, "llmOutput", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "observation", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "sendToLLM", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.llmOutput = llmOutput;
    this.observation = observation;
    this.sendToLLM = sendToLLM;
    if (sendToLLM) {
      if (observation === void 0 || llmOutput === void 0) {
        throw new Error("Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true");
      }
    }
    addLangChainErrorFields(this, "OUTPUT_PARSING_FAILURE");
  }
};

// node_modules/@langchain/core/dist/output_parsers/transform.js
var BaseTransformOutputParser = class extends BaseOutputParser {
  async *_transform(inputGenerator) {
    for await (const chunk of inputGenerator) {
      if (typeof chunk === "string") {
        yield this.parseResult([{ text: chunk }]);
      } else {
        yield this.parseResult([
          {
            message: chunk,
            text: this._baseMessageToString(chunk)
          }
        ]);
      }
    }
  }
  /**
   * Transforms an asynchronous generator of input into an asynchronous
   * generator of parsed output.
   * @param inputGenerator An asynchronous generator of input.
   * @param options A configuration object.
   * @returns An asynchronous generator of parsed output.
   */
  async *transform(inputGenerator, options) {
    yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {
      ...options,
      runType: "parser"
    });
  }
};
var BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "diff", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    this.diff = (fields == null ? void 0 : fields.diff) ?? this.diff;
  }
  async *_transform(inputGenerator) {
    let prevParsed;
    let accGen;
    for await (const chunk of inputGenerator) {
      if (typeof chunk !== "string" && typeof chunk.content !== "string") {
        throw new Error("Cannot handle non-string output.");
      }
      let chunkGen;
      if (isBaseMessageChunk(chunk)) {
        if (typeof chunk.content !== "string") {
          throw new Error("Cannot handle non-string message output.");
        }
        chunkGen = new ChatGenerationChunk({
          message: chunk,
          text: chunk.content
        });
      } else if (isBaseMessage(chunk)) {
        if (typeof chunk.content !== "string") {
          throw new Error("Cannot handle non-string message output.");
        }
        chunkGen = new ChatGenerationChunk({
          message: convertToChunk(chunk),
          text: chunk.content
        });
      } else {
        chunkGen = new GenerationChunk({ text: chunk });
      }
      if (accGen === void 0) {
        accGen = chunkGen;
      } else {
        accGen = accGen.concat(chunkGen);
      }
      const parsed = await this.parsePartialResult([accGen]);
      if (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {
        if (this.diff) {
          yield this._diff(prevParsed, parsed);
        } else {
          yield parsed;
        }
        prevParsed = parsed;
      }
    }
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/bytes.js
var BytesOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "bytes"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "textEncoder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new TextEncoder()
    });
  }
  static lc_name() {
    return "BytesOutputParser";
  }
  parse(text) {
    return Promise.resolve(this.textEncoder.encode(text));
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/list.js
var ListOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
  }
  async *_transform(inputGenerator) {
    let buffer = "";
    for await (const input of inputGenerator) {
      if (typeof input === "string") {
        buffer += input;
      } else {
        buffer += input.content;
      }
      if (!this.re) {
        const parts = await this.parse(buffer);
        if (parts.length > 1) {
          for (const part of parts.slice(0, -1)) {
            yield [part];
          }
          buffer = parts[parts.length - 1];
        }
      } else {
        const matches = [...buffer.matchAll(this.re)];
        if (matches.length > 1) {
          let doneIdx = 0;
          for (const match of matches.slice(0, -1)) {
            yield [match[1]];
            doneIdx += (match.index ?? 0) + match[0].length;
          }
          buffer = buffer.slice(doneIdx);
        }
      }
    }
    for (const part of await this.parse(buffer)) {
      yield [part];
    }
  }
};
var CommaSeparatedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "CommaSeparatedListOutputParser";
  }
  /**
   * Parses the given text into an array of strings, using a comma as the
   * separator. If the parsing fails, throws an OutputParserException.
   * @param text The text to parse.
   * @returns An array of strings obtained by splitting the input text at each comma.
   */
  async parse(text) {
    try {
      return text.trim().split(",").map((s) => s.trim());
    } catch (e) {
      throw new OutputParserException(`Could not parse output: ${text}`, text);
    }
  }
  /**
   * Provides instructions on the expected format of the response for the
   * CommaSeparatedListOutputParser.
   * @returns A string containing instructions on the expected format of the response.
   */
  getFormatInstructions() {
    return `Your response should be a list of comma separated values, eg: \`foo, bar, baz\``;
  }
};
var CustomListOutputParser = class extends ListOutputParser {
  constructor({ length, separator }) {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "length", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "separator", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.length = length;
    this.separator = separator || ",";
  }
  /**
   * Parses the given text into an array of strings, using the specified
   * separator. If the parsing fails or the number of items in the list
   * doesn't match the expected length, throws an OutputParserException.
   * @param text The text to parse.
   * @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.
   */
  async parse(text) {
    try {
      const items = text.trim().split(this.separator).map((s) => s.trim());
      if (this.length !== void 0 && items.length !== this.length) {
        throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);
      }
      return items;
    } catch (e) {
      if (Object.getPrototypeOf(e) === OutputParserException.prototype) {
        throw e;
      }
      throw new OutputParserException(`Could not parse output: ${text}`);
    }
  }
  /**
   * Provides instructions on the expected format of the response for the
   * CustomListOutputParser, including the number of items and the
   * separator.
   * @returns A string containing instructions on the expected format of the response.
   */
  getFormatInstructions() {
    return `Your response should be a list of ${this.length === void 0 ? "" : `${this.length} `}items separated by "${this.separator}" (eg: \`foo${this.separator} bar${this.separator} baz\`)`;
  }
};
var NumberedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /\d+\.\s([^\n]+)/g
    });
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};
var MarkdownListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "list"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "re", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /^\s*[-*]\s([^\n]+)$/gm
    });
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};

// node_modules/@langchain/core/dist/output_parsers/string.js
var StringOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers", "string"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "StrOutputParser";
  }
  /**
   * Parses a string output from an LLM call. This method is meant to be
   * implemented by subclasses to define how a string output from an LLM
   * should be parsed.
   * @param text The string output from an LLM call.
   * @param callbacks Optional callbacks.
   * @returns A promise of the parsed output.
   */
  parse(text) {
    return Promise.resolve(text);
  }
  getFormatInstructions() {
    return "";
  }
  _textContentToString(content) {
    return content.text;
  }
  _imageUrlContentToString(_content) {
    throw new Error(`Cannot coerce a multimodal "image_url" message part into a string.`);
  }
  _messageContentComplexToString(content) {
    switch (content.type) {
      case "text":
      case "text_delta":
        if ("text" in content) {
          return this._textContentToString(content);
        }
        break;
      case "image_url":
        if ("image_url" in content) {
          return this._imageUrlContentToString(content);
        }
        break;
      default:
        throw new Error(`Cannot coerce "${content.type}" message part into a string.`);
    }
    throw new Error(`Invalid content type: ${content.type}`);
  }
  _baseMessageContentToString(content) {
    return content.reduce((acc, item) => acc + this._messageContentComplexToString(item), "");
  }
};

// node_modules/@langchain/core/dist/output_parsers/structured.js
var StructuredOutputParser = class extends BaseOutputParser {
  static lc_name() {
    return "StructuredOutputParser";
  }
  toJSON() {
    return this.toJSONNotImplemented();
  }
  constructor(schema) {
    super(schema);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: schema
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "output_parsers", "structured"]
    });
  }
  /**
   * Creates a new StructuredOutputParser from a Zod schema.
   * @param schema The Zod schema which the output should match
   * @returns A new instance of StructuredOutputParser.
   */
  static fromZodSchema(schema) {
    return new this(schema);
  }
  /**
   * Creates a new StructuredOutputParser from a set of names and
   * descriptions.
   * @param schemas An object where each key is a name and each value is a description
   * @returns A new instance of StructuredOutputParser.
   */
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
  /**
   * Returns a markdown code snippet with a JSON object formatted according
   * to the schema.
   * @param options Optional. The options for formatting the instructions
   * @returns A markdown code snippet with a JSON object formatted according to the schema.
   */
  getFormatInstructions() {
    return `You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
\`\`\`json
${JSON.stringify(toJsonSchema(this.schema))}
\`\`\`
`;
  }
  /**
   * Parses the given text according to the schema.
   * @param text The text to parse
   * @returns The parsed output.
   */
  async parse(text) {
    try {
      const json = text.includes("```") ? text.trim().split(/```(?:json)?/)[1] : text.trim();
      const escapedJson = json.replace(/"([^"\\]*(\\.[^"\\]*)*)"/g, (_match, capturedGroup) => {
        const escapedInsideQuotes = capturedGroup.replace(/\n/g, "\\n");
        return `"${escapedInsideQuotes}"`;
      }).replace(/\n/g, "");
      return await interopParseAsync(this.schema, JSON.parse(escapedJson));
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
  }
};
var JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {
  static lc_name() {
    return "JsonMarkdownStructuredOutputParser";
  }
  getFormatInstructions(options) {
    const interpolationDepth = (options == null ? void 0 : options.interpolationDepth) ?? 1;
    if (interpolationDepth < 1) {
      throw new Error("f string interpolation depth must be at least 1");
    }
    return `Return a markdown code snippet with a JSON object formatted to look like:
\`\`\`json
${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll("{", "{".repeat(interpolationDepth)).replaceAll("}", "}".repeat(interpolationDepth))}
\`\`\``;
  }
  _schemaToInstruction(schemaInput, indent = 2) {
    const schema = schemaInput;
    if ("type" in schema) {
      let nullable = false;
      let type;
      if (Array.isArray(schema.type)) {
        const nullIdx = schema.type.findIndex((type2) => type2 === "null");
        if (nullIdx !== -1) {
          nullable = true;
          schema.type.splice(nullIdx, 1);
        }
        type = schema.type.join(" | ");
      } else {
        type = schema.type;
      }
      if (schema.type === "object" && schema.properties) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        const properties = Object.entries(schema.properties).map(([key, value]) => {
          var _a2;
          const isOptional = ((_a2 = schema.required) == null ? void 0 : _a2.includes(key)) ? "" : " (optional)";
          return `${" ".repeat(indent)}"${key}": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;
        }).join("\n");
        return `{
${properties}
${" ".repeat(indent - 2)}}${description2}`;
      }
      if (schema.type === "array" && schema.items) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        return `array[
${" ".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}
${" ".repeat(indent - 2)}] ${description2}`;
      }
      const isNullable = nullable ? " (nullable)" : "";
      const description = schema.description ? ` // ${schema.description}` : "";
      return `${type}${description}${isNullable}`;
    }
    if ("anyOf" in schema) {
      return schema.anyOf.map((s) => this._schemaToInstruction(s, indent)).join(`
${" ".repeat(indent - 2)}`);
    }
    throw new Error("unsupported schema type");
  }
  static fromZodSchema(schema) {
    return new this(schema);
  }
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
};
var AsymmetricStructuredOutputParser = class extends BaseOutputParser {
  constructor({ inputSchema }) {
    super(...arguments);
    Object.defineProperty(this, "structuredInputParser", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);
  }
  async parse(text) {
    let parsedInput;
    try {
      parsedInput = await this.structuredInputParser.parse(text);
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
    return this.outputProcessor(parsedInput);
  }
  getFormatInstructions() {
    return this.structuredInputParser.getFormatInstructions();
  }
};

// node_modules/@langchain/core/dist/utils/json_patch.js
var json_patch_exports = {};
__export(json_patch_exports, {
  applyPatch: () => applyPatch,
  compare: () => compare
});

// node_modules/@langchain/core/dist/output_parsers/json.js
var JsonOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  static lc_name() {
    return "JsonOutputParser";
  }
  /** @internal */
  _concatOutputChunks(first, second) {
    if (this.diff) {
      return super._concatOutputChunks(first, second);
    }
    return second;
  }
  _diff(prev, next) {
    if (!next) {
      return void 0;
    }
    if (!prev) {
      return [{ op: "replace", path: "", value: next }];
    }
    return compare(prev, next);
  }
  // This should actually return Partial<T>, but there's no way
  // to specify emitted chunks as instances separate from the main output type.
  async parsePartialResult(generations) {
    return parseJsonMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseJsonMarkdown(text, JSON.parse);
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/utils/sax-js/sax.js
var initializeSax = function() {
  const sax2 = {};
  sax2.parser = function(strict, opt) {
    return new SAXParser(strict, opt);
  };
  sax2.SAXParser = SAXParser;
  sax2.SAXStream = SAXStream;
  sax2.createStream = createStream;
  sax2.MAX_BUFFER_LENGTH = 64 * 1024;
  const buffers = [
    "comment",
    "sgmlDecl",
    "textNode",
    "tagName",
    "doctype",
    "procInstName",
    "procInstBody",
    "entity",
    "attribName",
    "attribValue",
    "cdata",
    "script"
  ];
  sax2.EVENTS = [
    "text",
    "processinginstruction",
    "sgmldeclaration",
    "doctype",
    "comment",
    "opentagstart",
    "attribute",
    "opentag",
    "closetag",
    "opencdata",
    "cdata",
    "closecdata",
    "error",
    "end",
    "ready",
    "script",
    "opennamespace",
    "closenamespace"
  ];
  function SAXParser(strict, opt) {
    if (!(this instanceof SAXParser)) {
      return new SAXParser(strict, opt);
    }
    var parser = this;
    clearBuffers(parser);
    parser.q = parser.c = "";
    parser.bufferCheckPosition = sax2.MAX_BUFFER_LENGTH;
    parser.opt = opt || {};
    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;
    parser.looseCase = parser.opt.lowercase ? "toLowerCase" : "toUpperCase";
    parser.tags = [];
    parser.closed = parser.closedRoot = parser.sawRoot = false;
    parser.tag = parser.error = null;
    parser.strict = !!strict;
    parser.noscript = !!(strict || parser.opt.noscript);
    parser.state = S.BEGIN;
    parser.strictEntities = parser.opt.strictEntities;
    parser.ENTITIES = parser.strictEntities ? Object.create(sax2.XML_ENTITIES) : Object.create(sax2.ENTITIES);
    parser.attribList = [];
    if (parser.opt.xmlns) {
      parser.ns = Object.create(rootNS);
    }
    parser.trackPosition = parser.opt.position !== false;
    if (parser.trackPosition) {
      parser.position = parser.line = parser.column = 0;
    }
    emit(parser, "onready");
  }
  if (!Object.create) {
    Object.create = function(o) {
      function F() {
      }
      F.prototype = o;
      var newf = new F();
      return newf;
    };
  }
  if (!Object.keys) {
    Object.keys = function(o) {
      var a = [];
      for (var i in o)
        if (o.hasOwnProperty(i))
          a.push(i);
      return a;
    };
  }
  function checkBufferLength(parser) {
    var maxAllowed = Math.max(sax2.MAX_BUFFER_LENGTH, 10);
    var maxActual = 0;
    for (var i = 0, l = buffers.length; i < l; i++) {
      var len = parser[buffers[i]].length;
      if (len > maxAllowed) {
        switch (buffers[i]) {
          case "textNode":
            closeText(parser);
            break;
          case "cdata":
            emitNode(parser, "oncdata", parser.cdata);
            parser.cdata = "";
            break;
          case "script":
            emitNode(parser, "onscript", parser.script);
            parser.script = "";
            break;
          default:
            error(parser, "Max buffer length exceeded: " + buffers[i]);
        }
      }
      maxActual = Math.max(maxActual, len);
    }
    var m = sax2.MAX_BUFFER_LENGTH - maxActual;
    parser.bufferCheckPosition = m + parser.position;
  }
  function clearBuffers(parser) {
    for (var i = 0, l = buffers.length; i < l; i++) {
      parser[buffers[i]] = "";
    }
  }
  function flushBuffers(parser) {
    closeText(parser);
    if (parser.cdata !== "") {
      emitNode(parser, "oncdata", parser.cdata);
      parser.cdata = "";
    }
    if (parser.script !== "") {
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
  }
  SAXParser.prototype = {
    end: function() {
      end(this);
    },
    write,
    resume: function() {
      this.error = null;
      return this;
    },
    close: function() {
      return this.write(null);
    },
    flush: function() {
      flushBuffers(this);
    }
  };
  var Stream = ReadableStream;
  if (!Stream)
    Stream = function() {
    };
  var streamWraps = sax2.EVENTS.filter(function(ev) {
    return ev !== "error" && ev !== "end";
  });
  function createStream(strict, opt) {
    return new SAXStream(strict, opt);
  }
  function SAXStream(strict, opt) {
    if (!(this instanceof SAXStream)) {
      return new SAXStream(strict, opt);
    }
    Stream.apply(this);
    this._parser = new SAXParser(strict, opt);
    this.writable = true;
    this.readable = true;
    var me = this;
    this._parser.onend = function() {
      me.emit("end");
    };
    this._parser.onerror = function(er) {
      me.emit("error", er);
      me._parser.error = null;
    };
    this._decoder = null;
    streamWraps.forEach(function(ev) {
      Object.defineProperty(me, "on" + ev, {
        get: function() {
          return me._parser["on" + ev];
        },
        set: function(h) {
          if (!h) {
            me.removeAllListeners(ev);
            me._parser["on" + ev] = h;
            return h;
          }
          me.on(ev, h);
        },
        enumerable: true,
        configurable: false
      });
    });
  }
  SAXStream.prototype = Object.create(Stream.prototype, {
    constructor: {
      value: SAXStream
    }
  });
  SAXStream.prototype.write = function(data) {
    this._parser.write(data.toString());
    this.emit("data", data);
    return true;
  };
  SAXStream.prototype.end = function(chunk) {
    if (chunk && chunk.length) {
      this.write(chunk);
    }
    this._parser.end();
    return true;
  };
  SAXStream.prototype.on = function(ev, handler) {
    var me = this;
    if (!me._parser["on" + ev] && streamWraps.indexOf(ev) !== -1) {
      me._parser["on" + ev] = function() {
        var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);
        args.splice(0, 0, ev);
        me.emit.apply(me, args);
      };
    }
    return Stream.prototype.on.call(me, ev, handler);
  };
  var CDATA = "[CDATA[";
  var DOCTYPE = "DOCTYPE";
  var XML_NAMESPACE = "http://www.w3.org/XML/1998/namespace";
  var XMLNS_NAMESPACE = "http://www.w3.org/2000/xmlns/";
  var rootNS = { xml: XML_NAMESPACE, xmlns: XMLNS_NAMESPACE };
  var nameStart = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var nameBody = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  var entityStart = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var entityBody = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  function isWhitespace(c) {
    return c === " " || c === "\n" || c === "\r" || c === "	";
  }
  function isQuote(c) {
    return c === '"' || c === "'";
  }
  function isAttribEnd(c) {
    return c === ">" || isWhitespace(c);
  }
  function isMatch(regex, c) {
    return regex.test(c);
  }
  function notMatch(regex, c) {
    return !isMatch(regex, c);
  }
  var S = 0;
  sax2.STATE = {
    BEGIN: S++,
    // leading byte order mark or whitespace
    BEGIN_WHITESPACE: S++,
    // leading whitespace
    TEXT: S++,
    // general stuff
    TEXT_ENTITY: S++,
    // &amp and such.
    OPEN_WAKA: S++,
    // <
    SGML_DECL: S++,
    // <!BLARG
    SGML_DECL_QUOTED: S++,
    // <!BLARG foo "bar
    DOCTYPE: S++,
    // <!DOCTYPE
    DOCTYPE_QUOTED: S++,
    // <!DOCTYPE "//blah
    DOCTYPE_DTD: S++,
    // <!DOCTYPE "//blah" [ ...
    DOCTYPE_DTD_QUOTED: S++,
    // <!DOCTYPE "//blah" [ "foo
    COMMENT_STARTING: S++,
    // <!-
    COMMENT: S++,
    // <!--
    COMMENT_ENDING: S++,
    // <!-- blah -
    COMMENT_ENDED: S++,
    // <!-- blah --
    CDATA: S++,
    // <![CDATA[ something
    CDATA_ENDING: S++,
    // ]
    CDATA_ENDING_2: S++,
    // ]]
    PROC_INST: S++,
    // <?hi
    PROC_INST_BODY: S++,
    // <?hi there
    PROC_INST_ENDING: S++,
    // <?hi "there" ?
    OPEN_TAG: S++,
    // <strong
    OPEN_TAG_SLASH: S++,
    // <strong /
    ATTRIB: S++,
    // <a
    ATTRIB_NAME: S++,
    // <a foo
    ATTRIB_NAME_SAW_WHITE: S++,
    // <a foo _
    ATTRIB_VALUE: S++,
    // <a foo=
    ATTRIB_VALUE_QUOTED: S++,
    // <a foo="bar
    ATTRIB_VALUE_CLOSED: S++,
    // <a foo="bar"
    ATTRIB_VALUE_UNQUOTED: S++,
    // <a foo=bar
    ATTRIB_VALUE_ENTITY_Q: S++,
    // <foo bar="&quot;"
    ATTRIB_VALUE_ENTITY_U: S++,
    // <foo bar=&quot
    CLOSE_TAG: S++,
    // </a
    CLOSE_TAG_SAW_WHITE: S++,
    // </a   >
    SCRIPT: S++,
    // <script> ...
    SCRIPT_ENDING: S++
    // <script> ... <
  };
  sax2.XML_ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'"
  };
  sax2.ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'",
    AElig: 198,
    Aacute: 193,
    Acirc: 194,
    Agrave: 192,
    Aring: 197,
    Atilde: 195,
    Auml: 196,
    Ccedil: 199,
    ETH: 208,
    Eacute: 201,
    Ecirc: 202,
    Egrave: 200,
    Euml: 203,
    Iacute: 205,
    Icirc: 206,
    Igrave: 204,
    Iuml: 207,
    Ntilde: 209,
    Oacute: 211,
    Ocirc: 212,
    Ograve: 210,
    Oslash: 216,
    Otilde: 213,
    Ouml: 214,
    THORN: 222,
    Uacute: 218,
    Ucirc: 219,
    Ugrave: 217,
    Uuml: 220,
    Yacute: 221,
    aacute: 225,
    acirc: 226,
    aelig: 230,
    agrave: 224,
    aring: 229,
    atilde: 227,
    auml: 228,
    ccedil: 231,
    eacute: 233,
    ecirc: 234,
    egrave: 232,
    eth: 240,
    euml: 235,
    iacute: 237,
    icirc: 238,
    igrave: 236,
    iuml: 239,
    ntilde: 241,
    oacute: 243,
    ocirc: 244,
    ograve: 242,
    oslash: 248,
    otilde: 245,
    ouml: 246,
    szlig: 223,
    thorn: 254,
    uacute: 250,
    ucirc: 251,
    ugrave: 249,
    uuml: 252,
    yacute: 253,
    yuml: 255,
    copy: 169,
    reg: 174,
    nbsp: 160,
    iexcl: 161,
    cent: 162,
    pound: 163,
    curren: 164,
    yen: 165,
    brvbar: 166,
    sect: 167,
    uml: 168,
    ordf: 170,
    laquo: 171,
    not: 172,
    shy: 173,
    macr: 175,
    deg: 176,
    plusmn: 177,
    sup1: 185,
    sup2: 178,
    sup3: 179,
    acute: 180,
    micro: 181,
    para: 182,
    middot: 183,
    cedil: 184,
    ordm: 186,
    raquo: 187,
    frac14: 188,
    frac12: 189,
    frac34: 190,
    iquest: 191,
    times: 215,
    divide: 247,
    OElig: 338,
    oelig: 339,
    Scaron: 352,
    scaron: 353,
    Yuml: 376,
    fnof: 402,
    circ: 710,
    tilde: 732,
    Alpha: 913,
    Beta: 914,
    Gamma: 915,
    Delta: 916,
    Epsilon: 917,
    Zeta: 918,
    Eta: 919,
    Theta: 920,
    Iota: 921,
    Kappa: 922,
    Lambda: 923,
    Mu: 924,
    Nu: 925,
    Xi: 926,
    Omicron: 927,
    Pi: 928,
    Rho: 929,
    Sigma: 931,
    Tau: 932,
    Upsilon: 933,
    Phi: 934,
    Chi: 935,
    Psi: 936,
    Omega: 937,
    alpha: 945,
    beta: 946,
    gamma: 947,
    delta: 948,
    epsilon: 949,
    zeta: 950,
    eta: 951,
    theta: 952,
    iota: 953,
    kappa: 954,
    lambda: 955,
    mu: 956,
    nu: 957,
    xi: 958,
    omicron: 959,
    pi: 960,
    rho: 961,
    sigmaf: 962,
    sigma: 963,
    tau: 964,
    upsilon: 965,
    phi: 966,
    chi: 967,
    psi: 968,
    omega: 969,
    thetasym: 977,
    upsih: 978,
    piv: 982,
    ensp: 8194,
    emsp: 8195,
    thinsp: 8201,
    zwnj: 8204,
    zwj: 8205,
    lrm: 8206,
    rlm: 8207,
    ndash: 8211,
    mdash: 8212,
    lsquo: 8216,
    rsquo: 8217,
    sbquo: 8218,
    ldquo: 8220,
    rdquo: 8221,
    bdquo: 8222,
    dagger: 8224,
    Dagger: 8225,
    bull: 8226,
    hellip: 8230,
    permil: 8240,
    prime: 8242,
    Prime: 8243,
    lsaquo: 8249,
    rsaquo: 8250,
    oline: 8254,
    frasl: 8260,
    euro: 8364,
    image: 8465,
    weierp: 8472,
    real: 8476,
    trade: 8482,
    alefsym: 8501,
    larr: 8592,
    uarr: 8593,
    rarr: 8594,
    darr: 8595,
    harr: 8596,
    crarr: 8629,
    lArr: 8656,
    uArr: 8657,
    rArr: 8658,
    dArr: 8659,
    hArr: 8660,
    forall: 8704,
    part: 8706,
    exist: 8707,
    empty: 8709,
    nabla: 8711,
    isin: 8712,
    notin: 8713,
    ni: 8715,
    prod: 8719,
    sum: 8721,
    minus: 8722,
    lowast: 8727,
    radic: 8730,
    prop: 8733,
    infin: 8734,
    ang: 8736,
    and: 8743,
    or: 8744,
    cap: 8745,
    cup: 8746,
    int: 8747,
    there4: 8756,
    sim: 8764,
    cong: 8773,
    asymp: 8776,
    ne: 8800,
    equiv: 8801,
    le: 8804,
    ge: 8805,
    sub: 8834,
    sup: 8835,
    nsub: 8836,
    sube: 8838,
    supe: 8839,
    oplus: 8853,
    otimes: 8855,
    perp: 8869,
    sdot: 8901,
    lceil: 8968,
    rceil: 8969,
    lfloor: 8970,
    rfloor: 8971,
    lang: 9001,
    rang: 9002,
    loz: 9674,
    spades: 9824,
    clubs: 9827,
    hearts: 9829,
    diams: 9830
  };
  Object.keys(sax2.ENTITIES).forEach(function(key) {
    var e = sax2.ENTITIES[key];
    var s2 = typeof e === "number" ? String.fromCharCode(e) : e;
    sax2.ENTITIES[key] = s2;
  });
  for (var s in sax2.STATE) {
    sax2.STATE[sax2.STATE[s]] = s;
  }
  S = sax2.STATE;
  function emit(parser, event, data) {
    parser[event] && parser[event](data);
  }
  function emitNode(parser, nodeType, data) {
    if (parser.textNode)
      closeText(parser);
    emit(parser, nodeType, data);
  }
  function closeText(parser) {
    parser.textNode = textopts(parser.opt, parser.textNode);
    if (parser.textNode)
      emit(parser, "ontext", parser.textNode);
    parser.textNode = "";
  }
  function textopts(opt, text) {
    if (opt.trim)
      text = text.trim();
    if (opt.normalize)
      text = text.replace(/\s+/g, " ");
    return text;
  }
  function error(parser, er) {
    closeText(parser);
    if (parser.trackPosition) {
      er += "\nLine: " + parser.line + "\nColumn: " + parser.column + "\nChar: " + parser.c;
    }
    er = new Error(er);
    parser.error = er;
    emit(parser, "onerror", er);
    return parser;
  }
  function end(parser) {
    if (parser.sawRoot && !parser.closedRoot)
      strictFail(parser, "Unclosed root tag");
    if (parser.state !== S.BEGIN && parser.state !== S.BEGIN_WHITESPACE && parser.state !== S.TEXT) {
      error(parser, "Unexpected end");
    }
    closeText(parser);
    parser.c = "";
    parser.closed = true;
    emit(parser, "onend");
    SAXParser.call(parser, parser.strict, parser.opt);
    return parser;
  }
  function strictFail(parser, message) {
    if (typeof parser !== "object" || !(parser instanceof SAXParser)) {
      throw new Error("bad call to strictFail");
    }
    if (parser.strict) {
      error(parser, message);
    }
  }
  function newTag(parser) {
    if (!parser.strict)
      parser.tagName = parser.tagName[parser.looseCase]();
    var parent = parser.tags[parser.tags.length - 1] || parser;
    var tag = parser.tag = { name: parser.tagName, attributes: {} };
    if (parser.opt.xmlns) {
      tag.ns = parent.ns;
    }
    parser.attribList.length = 0;
    emitNode(parser, "onopentagstart", tag);
  }
  function qname(name, attribute) {
    var i = name.indexOf(":");
    var qualName = i < 0 ? ["", name] : name.split(":");
    var prefix = qualName[0];
    var local = qualName[1];
    if (attribute && name === "xmlns") {
      prefix = "xmlns";
      local = "";
    }
    return { prefix, local };
  }
  function attrib(parser) {
    if (!parser.strict) {
      parser.attribName = parser.attribName[parser.looseCase]();
    }
    if (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {
      parser.attribName = parser.attribValue = "";
      return;
    }
    if (parser.opt.xmlns) {
      var qn = qname(parser.attribName, true);
      var prefix = qn.prefix;
      var local = qn.local;
      if (prefix === "xmlns") {
        if (local === "xml" && parser.attribValue !== XML_NAMESPACE) {
          strictFail(parser, "xml: prefix must be bound to " + XML_NAMESPACE + "\nActual: " + parser.attribValue);
        } else if (local === "xmlns" && parser.attribValue !== XMLNS_NAMESPACE) {
          strictFail(parser, "xmlns: prefix must be bound to " + XMLNS_NAMESPACE + "\nActual: " + parser.attribValue);
        } else {
          var tag = parser.tag;
          var parent = parser.tags[parser.tags.length - 1] || parser;
          if (tag.ns === parent.ns) {
            tag.ns = Object.create(parent.ns);
          }
          tag.ns[local] = parser.attribValue;
        }
      }
      parser.attribList.push([parser.attribName, parser.attribValue]);
    } else {
      parser.tag.attributes[parser.attribName] = parser.attribValue;
      emitNode(parser, "onattribute", {
        name: parser.attribName,
        value: parser.attribValue
      });
    }
    parser.attribName = parser.attribValue = "";
  }
  function openTag(parser, selfClosing) {
    if (parser.opt.xmlns) {
      var tag = parser.tag;
      var qn = qname(parser.tagName);
      tag.prefix = qn.prefix;
      tag.local = qn.local;
      tag.uri = tag.ns[qn.prefix] || "";
      if (tag.prefix && !tag.uri) {
        strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(parser.tagName));
        tag.uri = qn.prefix;
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (tag.ns && parent.ns !== tag.ns) {
        Object.keys(tag.ns).forEach(function(p) {
          emitNode(parser, "onopennamespace", {
            prefix: p,
            uri: tag.ns[p]
          });
        });
      }
      for (var i = 0, l = parser.attribList.length; i < l; i++) {
        var nv = parser.attribList[i];
        var name = nv[0];
        var value = nv[1];
        var qualName = qname(name, true);
        var prefix = qualName.prefix;
        var local = qualName.local;
        var uri = prefix === "" ? "" : tag.ns[prefix] || "";
        var a = {
          name,
          value,
          prefix,
          local,
          uri
        };
        if (prefix && prefix !== "xmlns" && !uri) {
          strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(prefix));
          a.uri = prefix;
        }
        parser.tag.attributes[name] = a;
        emitNode(parser, "onattribute", a);
      }
      parser.attribList.length = 0;
    }
    parser.tag.isSelfClosing = !!selfClosing;
    parser.sawRoot = true;
    parser.tags.push(parser.tag);
    emitNode(parser, "onopentag", parser.tag);
    if (!selfClosing) {
      if (!parser.noscript && parser.tagName.toLowerCase() === "script") {
        parser.state = S.SCRIPT;
      } else {
        parser.state = S.TEXT;
      }
      parser.tag = null;
      parser.tagName = "";
    }
    parser.attribName = parser.attribValue = "";
    parser.attribList.length = 0;
  }
  function closeTag(parser) {
    if (!parser.tagName) {
      strictFail(parser, "Weird empty close tag.");
      parser.textNode += "</>";
      parser.state = S.TEXT;
      return;
    }
    if (parser.script) {
      if (parser.tagName !== "script") {
        parser.script += "</" + parser.tagName + ">";
        parser.tagName = "";
        parser.state = S.SCRIPT;
        return;
      }
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
    var t = parser.tags.length;
    var tagName = parser.tagName;
    if (!parser.strict) {
      tagName = tagName[parser.looseCase]();
    }
    var closeTo = tagName;
    while (t--) {
      var close = parser.tags[t];
      if (close.name !== closeTo) {
        strictFail(parser, "Unexpected close tag");
      } else {
        break;
      }
    }
    if (t < 0) {
      strictFail(parser, "Unmatched closing tag: " + parser.tagName);
      parser.textNode += "</" + parser.tagName + ">";
      parser.state = S.TEXT;
      return;
    }
    parser.tagName = tagName;
    var s2 = parser.tags.length;
    while (s2-- > t) {
      var tag = parser.tag = parser.tags.pop();
      parser.tagName = parser.tag.name;
      emitNode(parser, "onclosetag", parser.tagName);
      var x = {};
      for (var i in tag.ns) {
        x[i] = tag.ns[i];
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (parser.opt.xmlns && tag.ns !== parent.ns) {
        Object.keys(tag.ns).forEach(function(p) {
          var n2 = tag.ns[p];
          emitNode(parser, "onclosenamespace", { prefix: p, uri: n2 });
        });
      }
    }
    if (t === 0)
      parser.closedRoot = true;
    parser.tagName = parser.attribValue = parser.attribName = "";
    parser.attribList.length = 0;
    parser.state = S.TEXT;
  }
  function parseEntity(parser) {
    var entity = parser.entity;
    var entityLC = entity.toLowerCase();
    var num;
    var numStr = "";
    if (parser.ENTITIES[entity]) {
      return parser.ENTITIES[entity];
    }
    if (parser.ENTITIES[entityLC]) {
      return parser.ENTITIES[entityLC];
    }
    entity = entityLC;
    if (entity.charAt(0) === "#") {
      if (entity.charAt(1) === "x") {
        entity = entity.slice(2);
        num = parseInt(entity, 16);
        numStr = num.toString(16);
      } else {
        entity = entity.slice(1);
        num = parseInt(entity, 10);
        numStr = num.toString(10);
      }
    }
    entity = entity.replace(/^0+/, "");
    if (isNaN(num) || numStr.toLowerCase() !== entity) {
      strictFail(parser, "Invalid character entity");
      return "&" + parser.entity + ";";
    }
    return String.fromCodePoint(num);
  }
  function beginWhiteSpace(parser, c) {
    if (c === "<") {
      parser.state = S.OPEN_WAKA;
      parser.startTagPosition = parser.position;
    } else if (!isWhitespace(c)) {
      strictFail(parser, "Non-whitespace before first tag.");
      parser.textNode = c;
      parser.state = S.TEXT;
    }
  }
  function charAt(chunk, i) {
    var result = "";
    if (i < chunk.length) {
      result = chunk.charAt(i);
    }
    return result;
  }
  function write(chunk) {
    var parser = this;
    if (this.error) {
      throw this.error;
    }
    if (parser.closed) {
      return error(parser, "Cannot write after close. Assign an onready handler.");
    }
    if (chunk === null) {
      return end(parser);
    }
    if (typeof chunk === "object") {
      chunk = chunk.toString();
    }
    var i = 0;
    var c = "";
    while (true) {
      c = charAt(chunk, i++);
      parser.c = c;
      if (!c) {
        break;
      }
      if (parser.trackPosition) {
        parser.position++;
        if (c === "\n") {
          parser.line++;
          parser.column = 0;
        } else {
          parser.column++;
        }
      }
      switch (parser.state) {
        case S.BEGIN:
          parser.state = S.BEGIN_WHITESPACE;
          if (c === "\uFEFF") {
            continue;
          }
          beginWhiteSpace(parser, c);
          continue;
        case S.BEGIN_WHITESPACE:
          beginWhiteSpace(parser, c);
          continue;
        case S.TEXT:
          if (parser.sawRoot && !parser.closedRoot) {
            var starti = i - 1;
            while (c && c !== "<" && c !== "&") {
              c = charAt(chunk, i++);
              if (c && parser.trackPosition) {
                parser.position++;
                if (c === "\n") {
                  parser.line++;
                  parser.column = 0;
                } else {
                  parser.column++;
                }
              }
            }
            parser.textNode += chunk.substring(starti, i - 1);
          }
          if (c === "<" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {
            parser.state = S.OPEN_WAKA;
            parser.startTagPosition = parser.position;
          } else {
            if (!isWhitespace(c) && (!parser.sawRoot || parser.closedRoot)) {
              strictFail(parser, "Text data outside of root node.");
            }
            if (c === "&") {
              parser.state = S.TEXT_ENTITY;
            } else {
              parser.textNode += c;
            }
          }
          continue;
        case S.SCRIPT:
          if (c === "<") {
            parser.state = S.SCRIPT_ENDING;
          } else {
            parser.script += c;
          }
          continue;
        case S.SCRIPT_ENDING:
          if (c === "/") {
            parser.state = S.CLOSE_TAG;
          } else {
            parser.script += "<" + c;
            parser.state = S.SCRIPT;
          }
          continue;
        case S.OPEN_WAKA:
          if (c === "!") {
            parser.state = S.SGML_DECL;
            parser.sgmlDecl = "";
          } else if (isWhitespace(c)) {
          } else if (isMatch(nameStart, c)) {
            parser.state = S.OPEN_TAG;
            parser.tagName = c;
          } else if (c === "/") {
            parser.state = S.CLOSE_TAG;
            parser.tagName = "";
          } else if (c === "?") {
            parser.state = S.PROC_INST;
            parser.procInstName = parser.procInstBody = "";
          } else {
            strictFail(parser, "Unencoded <");
            if (parser.startTagPosition + 1 < parser.position) {
              var pad = parser.position - parser.startTagPosition;
              c = new Array(pad).join(" ") + c;
            }
            parser.textNode += "<" + c;
            parser.state = S.TEXT;
          }
          continue;
        case S.SGML_DECL:
          if ((parser.sgmlDecl + c).toUpperCase() === CDATA) {
            emitNode(parser, "onopencdata");
            parser.state = S.CDATA;
            parser.sgmlDecl = "";
            parser.cdata = "";
          } else if (parser.sgmlDecl + c === "--") {
            parser.state = S.COMMENT;
            parser.comment = "";
            parser.sgmlDecl = "";
          } else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {
            parser.state = S.DOCTYPE;
            if (parser.doctype || parser.sawRoot) {
              strictFail(parser, "Inappropriately located doctype declaration");
            }
            parser.doctype = "";
            parser.sgmlDecl = "";
          } else if (c === ">") {
            emitNode(parser, "onsgmldeclaration", parser.sgmlDecl);
            parser.sgmlDecl = "";
            parser.state = S.TEXT;
          } else if (isQuote(c)) {
            parser.state = S.SGML_DECL_QUOTED;
            parser.sgmlDecl += c;
          } else {
            parser.sgmlDecl += c;
          }
          continue;
        case S.SGML_DECL_QUOTED:
          if (c === parser.q) {
            parser.state = S.SGML_DECL;
            parser.q = "";
          }
          parser.sgmlDecl += c;
          continue;
        case S.DOCTYPE:
          if (c === ">") {
            parser.state = S.TEXT;
            emitNode(parser, "ondoctype", parser.doctype);
            parser.doctype = true;
          } else {
            parser.doctype += c;
            if (c === "[") {
              parser.state = S.DOCTYPE_DTD;
            } else if (isQuote(c)) {
              parser.state = S.DOCTYPE_QUOTED;
              parser.q = c;
            }
          }
          continue;
        case S.DOCTYPE_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.q = "";
            parser.state = S.DOCTYPE;
          }
          continue;
        case S.DOCTYPE_DTD:
          parser.doctype += c;
          if (c === "]") {
            parser.state = S.DOCTYPE;
          } else if (isQuote(c)) {
            parser.state = S.DOCTYPE_DTD_QUOTED;
            parser.q = c;
          }
          continue;
        case S.DOCTYPE_DTD_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.state = S.DOCTYPE_DTD;
            parser.q = "";
          }
          continue;
        case S.COMMENT:
          if (c === "-") {
            parser.state = S.COMMENT_ENDING;
          } else {
            parser.comment += c;
          }
          continue;
        case S.COMMENT_ENDING:
          if (c === "-") {
            parser.state = S.COMMENT_ENDED;
            parser.comment = textopts(parser.opt, parser.comment);
            if (parser.comment) {
              emitNode(parser, "oncomment", parser.comment);
            }
            parser.comment = "";
          } else {
            parser.comment += "-" + c;
            parser.state = S.COMMENT;
          }
          continue;
        case S.COMMENT_ENDED:
          if (c !== ">") {
            strictFail(parser, "Malformed comment");
            parser.comment += "--" + c;
            parser.state = S.COMMENT;
          } else {
            parser.state = S.TEXT;
          }
          continue;
        case S.CDATA:
          if (c === "]") {
            parser.state = S.CDATA_ENDING;
          } else {
            parser.cdata += c;
          }
          continue;
        case S.CDATA_ENDING:
          if (c === "]") {
            parser.state = S.CDATA_ENDING_2;
          } else {
            parser.cdata += "]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.CDATA_ENDING_2:
          if (c === ">") {
            if (parser.cdata) {
              emitNode(parser, "oncdata", parser.cdata);
            }
            emitNode(parser, "onclosecdata");
            parser.cdata = "";
            parser.state = S.TEXT;
          } else if (c === "]") {
            parser.cdata += "]";
          } else {
            parser.cdata += "]]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.PROC_INST:
          if (c === "?") {
            parser.state = S.PROC_INST_ENDING;
          } else if (isWhitespace(c)) {
            parser.state = S.PROC_INST_BODY;
          } else {
            parser.procInstName += c;
          }
          continue;
        case S.PROC_INST_BODY:
          if (!parser.procInstBody && isWhitespace(c)) {
            continue;
          } else if (c === "?") {
            parser.state = S.PROC_INST_ENDING;
          } else {
            parser.procInstBody += c;
          }
          continue;
        case S.PROC_INST_ENDING:
          if (c === ">") {
            emitNode(parser, "onprocessinginstruction", {
              name: parser.procInstName,
              body: parser.procInstBody
            });
            parser.procInstName = parser.procInstBody = "";
            parser.state = S.TEXT;
          } else {
            parser.procInstBody += "?" + c;
            parser.state = S.PROC_INST_BODY;
          }
          continue;
        case S.OPEN_TAG:
          if (isMatch(nameBody, c)) {
            parser.tagName += c;
          } else {
            newTag(parser);
            if (c === ">") {
              openTag(parser);
            } else if (c === "/") {
              parser.state = S.OPEN_TAG_SLASH;
            } else {
              if (!isWhitespace(c)) {
                strictFail(parser, "Invalid character in tag name");
              }
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.OPEN_TAG_SLASH:
          if (c === ">") {
            openTag(parser, true);
            closeTag(parser);
          } else {
            strictFail(parser, "Forward-slash in opening tag not followed by >");
            parser.state = S.ATTRIB;
          }
          continue;
        case S.ATTRIB:
          if (isWhitespace(c)) {
            continue;
          } else if (c === ">") {
            openTag(parser);
          } else if (c === "/") {
            parser.state = S.OPEN_TAG_SLASH;
          } else if (isMatch(nameStart, c)) {
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S.ATTRIB_NAME:
          if (c === "=") {
            parser.state = S.ATTRIB_VALUE;
          } else if (c === ">") {
            strictFail(parser, "Attribute without value");
            parser.attribValue = parser.attribName;
            attrib(parser);
            openTag(parser);
          } else if (isWhitespace(c)) {
            parser.state = S.ATTRIB_NAME_SAW_WHITE;
          } else if (isMatch(nameBody, c)) {
            parser.attribName += c;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S.ATTRIB_NAME_SAW_WHITE:
          if (c === "=") {
            parser.state = S.ATTRIB_VALUE;
          } else if (isWhitespace(c)) {
            continue;
          } else {
            strictFail(parser, "Attribute without value");
            parser.tag.attributes[parser.attribName] = "";
            parser.attribValue = "";
            emitNode(parser, "onattribute", {
              name: parser.attribName,
              value: ""
            });
            parser.attribName = "";
            if (c === ">") {
              openTag(parser);
            } else if (isMatch(nameStart, c)) {
              parser.attribName = c;
              parser.state = S.ATTRIB_NAME;
            } else {
              strictFail(parser, "Invalid attribute name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.ATTRIB_VALUE:
          if (isWhitespace(c)) {
            continue;
          } else if (isQuote(c)) {
            parser.q = c;
            parser.state = S.ATTRIB_VALUE_QUOTED;
          } else {
            strictFail(parser, "Unquoted attribute value");
            parser.state = S.ATTRIB_VALUE_UNQUOTED;
            parser.attribValue = c;
          }
          continue;
        case S.ATTRIB_VALUE_QUOTED:
          if (c !== parser.q) {
            if (c === "&") {
              parser.state = S.ATTRIB_VALUE_ENTITY_Q;
            } else {
              parser.attribValue += c;
            }
            continue;
          }
          attrib(parser);
          parser.q = "";
          parser.state = S.ATTRIB_VALUE_CLOSED;
          continue;
        case S.ATTRIB_VALUE_CLOSED:
          if (isWhitespace(c)) {
            parser.state = S.ATTRIB;
          } else if (c === ">") {
            openTag(parser);
          } else if (c === "/") {
            parser.state = S.OPEN_TAG_SLASH;
          } else if (isMatch(nameStart, c)) {
            strictFail(parser, "No whitespace between attributes");
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else {
            strictFail(parser, "Invalid attribute name");
          }
          continue;
        case S.ATTRIB_VALUE_UNQUOTED:
          if (!isAttribEnd(c)) {
            if (c === "&") {
              parser.state = S.ATTRIB_VALUE_ENTITY_U;
            } else {
              parser.attribValue += c;
            }
            continue;
          }
          attrib(parser);
          if (c === ">") {
            openTag(parser);
          } else {
            parser.state = S.ATTRIB;
          }
          continue;
        case S.CLOSE_TAG:
          if (!parser.tagName) {
            if (isWhitespace(c)) {
              continue;
            } else if (notMatch(nameStart, c)) {
              if (parser.script) {
                parser.script += "</" + c;
                parser.state = S.SCRIPT;
              } else {
                strictFail(parser, "Invalid tagname in closing tag.");
              }
            } else {
              parser.tagName = c;
            }
          } else if (c === ">") {
            closeTag(parser);
          } else if (isMatch(nameBody, c)) {
            parser.tagName += c;
          } else if (parser.script) {
            parser.script += "</" + parser.tagName;
            parser.tagName = "";
            parser.state = S.SCRIPT;
          } else {
            if (!isWhitespace(c)) {
              strictFail(parser, "Invalid tagname in closing tag");
            }
            parser.state = S.CLOSE_TAG_SAW_WHITE;
          }
          continue;
        case S.CLOSE_TAG_SAW_WHITE:
          if (isWhitespace(c)) {
            continue;
          }
          if (c === ">") {
            closeTag(parser);
          } else {
            strictFail(parser, "Invalid characters in closing tag");
          }
          continue;
        case S.TEXT_ENTITY:
        case S.ATTRIB_VALUE_ENTITY_Q:
        case S.ATTRIB_VALUE_ENTITY_U:
          var returnState;
          var buffer;
          switch (parser.state) {
            case S.TEXT_ENTITY:
              returnState = S.TEXT;
              buffer = "textNode";
              break;
            case S.ATTRIB_VALUE_ENTITY_Q:
              returnState = S.ATTRIB_VALUE_QUOTED;
              buffer = "attribValue";
              break;
            case S.ATTRIB_VALUE_ENTITY_U:
              returnState = S.ATTRIB_VALUE_UNQUOTED;
              buffer = "attribValue";
              break;
          }
          if (c === ";") {
            if (parser.opt.unparsedEntities) {
              var parsedEntity = parseEntity(parser);
              parser.entity = "";
              parser.state = returnState;
              parser.write(parsedEntity);
            } else {
              parser[buffer] += parseEntity(parser);
              parser.entity = "";
              parser.state = returnState;
            }
          } else if (isMatch(parser.entity.length ? entityBody : entityStart, c)) {
            parser.entity += c;
          } else {
            strictFail(parser, "Invalid character in entity name");
            parser[buffer] += "&" + parser.entity + c;
            parser.entity = "";
            parser.state = returnState;
          }
          continue;
        default: {
          throw new Error(parser, "Unknown state: " + parser.state);
        }
      }
    }
    if (parser.position >= parser.bufferCheckPosition) {
      checkBufferLength(parser);
    }
    return parser;
  }
  if (!String.fromCodePoint) {
    (function() {
      var stringFromCharCode = String.fromCharCode;
      var floor = Math.floor;
      var fromCodePoint = function() {
        var MAX_SIZE = 16384;
        var codeUnits = [];
        var highSurrogate;
        var lowSurrogate;
        var index = -1;
        var length = arguments.length;
        if (!length) {
          return "";
        }
        var result = "";
        while (++index < length) {
          var codePoint = Number(arguments[index]);
          if (!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`
          codePoint < 0 || // not a valid Unicode code point
          codePoint > 1114111 || // not a valid Unicode code point
          floor(codePoint) !== codePoint) {
            throw RangeError("Invalid code point: " + codePoint);
          }
          if (codePoint <= 65535) {
            codeUnits.push(codePoint);
          } else {
            codePoint -= 65536;
            highSurrogate = (codePoint >> 10) + 55296;
            lowSurrogate = codePoint % 1024 + 56320;
            codeUnits.push(highSurrogate, lowSurrogate);
          }
          if (index + 1 === length || codeUnits.length > MAX_SIZE) {
            result += stringFromCharCode.apply(null, codeUnits);
            codeUnits.length = 0;
          }
        }
        return result;
      };
      if (Object.defineProperty) {
        Object.defineProperty(String, "fromCodePoint", {
          value: fromCodePoint,
          configurable: true,
          writable: true
        });
      } else {
        String.fromCodePoint = fromCodePoint;
      }
    })();
  }
  return sax2;
};
var sax = initializeSax();

// node_modules/@langchain/core/dist/output_parsers/xml.js
var XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags ["foo", "bar", "baz"]:
1. String "<foo>
   <bar>
      <baz></baz>
   </bar>
</foo>" is a well-formatted instance of the schema. 
2. String "<foo>
   <bar>
   </foo>" is a badly-formatted instance.
3. String "<foo>
   <tag>
   </tag>
</foo>" is a badly-formatted instance.

Here are the output tags:
\`\`\`
{tags}
\`\`\``;
var XMLOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "output_parsers"]
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.tags = fields == null ? void 0 : fields.tags;
  }
  static lc_name() {
    return "XMLOutputParser";
  }
  _diff(prev, next) {
    if (!next) {
      return void 0;
    }
    if (!prev) {
      return [{ op: "replace", path: "", value: next }];
    }
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseXMLMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseXMLMarkdown(text);
  }
  getFormatInstructions() {
    var _a2;
    const withTags = !!(this.tags && this.tags.length > 0);
    return withTags ? XML_FORMAT_INSTRUCTIONS.replace("{tags}", ((_a2 = this.tags) == null ? void 0 : _a2.join(", ")) ?? "") : XML_FORMAT_INSTRUCTIONS;
  }
};
var strip = (text) => text.split("\n").map((line) => line.replace(/^\s+/, "")).join("\n").trim();
var parseParsedResult = (input) => {
  if (Object.keys(input).length === 0) {
    return {};
  }
  const result = {};
  if (input.children.length > 0) {
    result[input.name] = input.children.map(parseParsedResult);
    return result;
  } else {
    result[input.name] = input.text ?? void 0;
    return result;
  }
};
function parseXMLMarkdown(s) {
  const cleanedString = strip(s);
  const parser = sax.parser(true);
  let parsedResult = {};
  const elementStack = [];
  parser.onopentag = (node) => {
    const element = {
      name: node.name,
      attributes: node.attributes,
      children: [],
      text: "",
      isSelfClosing: node.isSelfClosing
    };
    if (elementStack.length > 0) {
      const parentElement = elementStack[elementStack.length - 1];
      parentElement.children.push(element);
    } else {
      parsedResult = element;
    }
    if (!node.isSelfClosing) {
      elementStack.push(element);
    }
  };
  parser.onclosetag = () => {
    if (elementStack.length > 0) {
      const lastElement = elementStack.pop();
      if (elementStack.length === 0 && lastElement) {
        parsedResult = lastElement;
      }
    }
  };
  parser.ontext = (text) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.text += text;
    }
  };
  parser.onattribute = (attr) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.attributes[attr.name] = attr.value;
    }
  };
  const match = /```(xml)?(.*)```/s.exec(cleanedString);
  const xmlString = match ? match[2] : cleanedString;
  parser.write(xmlString).close();
  if (parsedResult && parsedResult.name === "?xml") {
    parsedResult = parsedResult.children[0];
  }
  return parseParsedResult(parsedResult);
}

// node_modules/@langchain/core/dist/prompts/index.js
var prompts_exports = {};
__export(prompts_exports, {
  AIMessagePromptTemplate: () => AIMessagePromptTemplate,
  BaseChatPromptTemplate: () => BaseChatPromptTemplate,
  BaseMessagePromptTemplate: () => BaseMessagePromptTemplate,
  BaseMessageStringPromptTemplate: () => BaseMessageStringPromptTemplate,
  BasePromptTemplate: () => BasePromptTemplate,
  BaseStringPromptTemplate: () => BaseStringPromptTemplate,
  ChatMessagePromptTemplate: () => ChatMessagePromptTemplate,
  ChatPromptTemplate: () => ChatPromptTemplate,
  DEFAULT_FORMATTER_MAPPING: () => DEFAULT_FORMATTER_MAPPING,
  DEFAULT_PARSER_MAPPING: () => DEFAULT_PARSER_MAPPING,
  DictPromptTemplate: () => DictPromptTemplate,
  FewShotChatMessagePromptTemplate: () => FewShotChatMessagePromptTemplate,
  FewShotPromptTemplate: () => FewShotPromptTemplate,
  HumanMessagePromptTemplate: () => HumanMessagePromptTemplate,
  ImagePromptTemplate: () => ImagePromptTemplate,
  MessagesPlaceholder: () => MessagesPlaceholder,
  PipelinePromptTemplate: () => PipelinePromptTemplate,
  PromptTemplate: () => PromptTemplate,
  StructuredPrompt: () => StructuredPrompt,
  SystemMessagePromptTemplate: () => SystemMessagePromptTemplate,
  checkValidTemplate: () => checkValidTemplate,
  interpolateFString: () => interpolateFString,
  interpolateMustache: () => interpolateMustache,
  parseFString: () => parseFString,
  parseMustache: () => parseMustache,
  parseTemplate: () => parseTemplate,
  renderTemplate: () => renderTemplate
});

// node_modules/@langchain/core/dist/prompts/pipeline.js
var PipelinePromptTemplate = class _PipelinePromptTemplate extends BasePromptTemplate {
  static lc_name() {
    return "PipelinePromptTemplate";
  }
  constructor(input) {
    super({ ...input, inputVariables: [] });
    Object.defineProperty(this, "pipelinePrompts", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "finalPrompt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.pipelinePrompts = input.pipelinePrompts;
    this.finalPrompt = input.finalPrompt;
    this.inputVariables = this.computeInputValues();
  }
  /**
   * Computes the input values required by the pipeline prompts.
   * @returns Array of input values required by the pipeline prompts.
   */
  computeInputValues() {
    const intermediateValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.name);
    const inputValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.prompt.inputVariables.filter((inputValue) => !intermediateValues.includes(inputValue))).flat();
    return [...new Set(inputValues)];
  }
  static extractRequiredInputValues(allValues, requiredValueNames) {
    return requiredValueNames.reduce((requiredValues, valueName) => {
      requiredValues[valueName] = allValues[valueName];
      return requiredValues;
    }, {});
  }
  /**
   * Formats the pipeline prompts based on the provided input values.
   * @param values Input values to format the pipeline prompts.
   * @returns Promise that resolves with the formatted input values.
   */
  async formatPipelinePrompts(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    for (const { name: pipelinePromptName, prompt: pipelinePrompt } of this.pipelinePrompts) {
      const pipelinePromptInputValues = _PipelinePromptTemplate.extractRequiredInputValues(allValues, pipelinePrompt.inputVariables);
      if (pipelinePrompt instanceof ChatPromptTemplate) {
        allValues[pipelinePromptName] = await pipelinePrompt.formatMessages(pipelinePromptInputValues);
      } else {
        allValues[pipelinePromptName] = await pipelinePrompt.format(pipelinePromptInputValues);
      }
    }
    return _PipelinePromptTemplate.extractRequiredInputValues(allValues, this.finalPrompt.inputVariables);
  }
  /**
   * Formats the final prompt value based on the provided input values.
   * @param values Input values to format the final prompt value.
   * @returns Promise that resolves with the formatted final prompt value.
   */
  async formatPromptValue(values) {
    return this.finalPrompt.formatPromptValue(await this.formatPipelinePrompts(values));
  }
  async format(values) {
    return this.finalPrompt.format(await this.formatPipelinePrompts(values));
  }
  /**
   * Handles partial prompts, which are prompts that have been partially
   * filled with input values.
   * @param values Partial input values.
   * @returns Promise that resolves with a new PipelinePromptTemplate instance with updated input variables.
   */
  async partial(values) {
    const promptDict = { ...this };
    promptDict.inputVariables = this.inputVariables.filter((iv) => !(iv in values));
    promptDict.partialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    return new _PipelinePromptTemplate(promptDict);
  }
  serialize() {
    throw new Error("Not implemented.");
  }
  _getPromptType() {
    return "pipeline";
  }
};

// node_modules/@langchain/core/dist/prompts/structured.js
function isWithStructuredOutput(x) {
  return typeof x === "object" && x != null && "withStructuredOutput" in x && typeof x.withStructuredOutput === "function";
}
function isRunnableBinding(x) {
  return typeof x === "object" && x != null && "lc_id" in x && Array.isArray(x.lc_id) && x.lc_id.join("/") === "langchain_core/runnables/RunnableBinding";
}
var StructuredPrompt = class _StructuredPrompt extends ChatPromptTemplate {
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      schema: "schema_"
    };
  }
  constructor(input) {
    super(input);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "method", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "prompts", "structured"]
    });
    this.schema = input.schema;
    this.method = input.method;
  }
  pipe(coerceable) {
    if (isWithStructuredOutput(coerceable)) {
      return super.pipe(coerceable.withStructuredOutput(this.schema));
    }
    if (isRunnableBinding(coerceable) && isWithStructuredOutput(coerceable.bound)) {
      return super.pipe(new RunnableBinding({
        bound: coerceable.bound.withStructuredOutput(this.schema, ...this.method ? [{ method: this.method }] : []),
        kwargs: coerceable.kwargs ?? {},
        config: coerceable.config,
        configFactories: coerceable.configFactories
      }));
    }
    throw new Error(`Structured prompts need to be piped to a language model that supports the "withStructuredOutput()" method.`);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static fromMessagesAndSchema(promptMessages, schema, method) {
    return _StructuredPrompt.fromMessages(promptMessages, { schema, method });
  }
};

// node_modules/@langchain/core/dist/retrievers/index.js
var retrievers_exports = {};
__export(retrievers_exports, {
  BaseRetriever: () => BaseRetriever
});
var BaseRetriever = class extends Runnable {
  /**
   * Constructs a new `BaseRetriever` instance with optional configuration fields.
   *
   * @param fields - Optional input configuration that can include `callbacks`,
   *                 `tags`, `metadata`, and `verbose` settings for custom retriever behavior.
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "verbose", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.callbacks = fields == null ? void 0 : fields.callbacks;
    this.tags = (fields == null ? void 0 : fields.tags) ?? [];
    this.metadata = (fields == null ? void 0 : fields.metadata) ?? {};
    this.verbose = (fields == null ? void 0 : fields.verbose) ?? false;
  }
  /**
   * TODO: This should be an abstract method, but we'd like to avoid breaking
   * changes to people currently using subclassed custom retrievers.
   * Change it on next major release.
   */
  /**
   * Placeholder method for retrieving relevant documents based on a query.
   *
   * This method is intended to be implemented by subclasses and will be
   * converted to an abstract method in the next major release. Currently, it
   * throws an error if not implemented, ensuring that custom retrievers define
   * the specific retrieval logic.
   *
   * @param _query - The query string used to search for relevant documents.
   * @param _callbacks - (optional) Callback manager for managing callbacks
   *                     during retrieval.
   * @returns A promise resolving to an array of `DocumentInterface` instances relevant to the query.
   * @throws {Error} Throws an error indicating the method is not implemented.
   */
  _getRelevantDocuments(_query, _callbacks) {
    throw new Error("Not implemented!");
  }
  /**
   * Executes a retrieval operation.
   *
   * @param input - The query string used to search for relevant documents.
   * @param options - (optional) Configuration options for the retrieval run,
   *                  which may include callbacks, tags, and metadata.
   * @returns A promise that resolves to an array of `DocumentInterface` instances
   *          representing the most relevant documents to the query.
   */
  async invoke(input, options) {
    return this.getRelevantDocuments(input, ensureConfig(options));
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Main method used to retrieve relevant documents. It takes a query
   * string and an optional configuration object, and returns a promise that
   * resolves to an array of `Document` objects. This method handles the
   * retrieval process, including starting and ending callbacks, and error
   * handling.
   * @param query The query string to retrieve relevant documents for.
   * @param config Optional configuration object for the retrieval process.
   * @returns A promise that resolves to an array of `Document` objects.
   */
  async getRelevantDocuments(query, config) {
    const parsedConfig = ensureConfig(parseCallbackConfigArg(config));
    const callbackManager_ = await CallbackManager.configure(parsedConfig.callbacks, this.callbacks, parsedConfig.tags, this.tags, parsedConfig.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await (callbackManager_ == null ? void 0 : callbackManager_.handleRetrieverStart(this.toJSON(), query, parsedConfig.runId, void 0, void 0, void 0, parsedConfig.runName));
    try {
      const results = await this._getRelevantDocuments(query, runManager);
      await (runManager == null ? void 0 : runManager.handleRetrieverEnd(results));
      return results;
    } catch (error) {
      await (runManager == null ? void 0 : runManager.handleRetrieverError(error));
      throw error;
    }
  }
};

// node_modules/@langchain/core/dist/stores.js
var stores_exports = {};
__export(stores_exports, {
  BaseStore: () => BaseStore,
  InMemoryStore: () => InMemoryStore
});
var BaseStore = class extends Serializable {
};
var InMemoryStore = class extends BaseStore {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "storage"]
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
  }
  /**
   * Retrieves the values associated with the given keys from the store.
   * @param keys Keys to retrieve values for.
   * @returns Array of values associated with the given keys.
   */
  async mget(keys) {
    return keys.map((key) => this.store[key]);
  }
  /**
   * Sets the values for the given keys in the store.
   * @param keyValuePairs Array of key-value pairs to set in the store.
   * @returns Promise that resolves when all key-value pairs have been set.
   */
  async mset(keyValuePairs) {
    for (const [key, value] of keyValuePairs) {
      this.store[key] = value;
    }
  }
  /**
   * Deletes the given keys and their associated values from the store.
   * @param keys Keys to delete from the store.
   * @returns Promise that resolves when all keys have been deleted.
   */
  async mdelete(keys) {
    for (const key of keys) {
      delete this.store[key];
    }
  }
  /**
   * Asynchronous generator that yields keys from the store. If a prefix is
   * provided, it only yields keys that start with the prefix.
   * @param prefix Optional prefix to filter keys.
   * @returns AsyncGenerator that yields keys from the store.
   */
  async *yieldKeys(prefix) {
    const keys = Object.keys(this.store);
    for (const key of keys) {
      if (prefix === void 0 || key.startsWith(prefix)) {
        yield key;
      }
    }
  }
};

// node_modules/@langchain/core/dist/tools/index.js
var tools_exports = {};
__export(tools_exports, {
  BaseToolkit: () => BaseToolkit,
  DynamicStructuredTool: () => DynamicStructuredTool,
  DynamicTool: () => DynamicTool,
  StructuredTool: () => StructuredTool,
  Tool: () => Tool,
  ToolInputParsingException: () => ToolInputParsingException,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams,
  tool: () => tool
});

// node_modules/@langchain/core/dist/tools/types.js
function isStructuredTool(tool2) {
  return tool2 !== void 0 && Array.isArray(tool2.lc_namespace);
}
function isRunnableToolLike(tool2) {
  return tool2 !== void 0 && Runnable.isRunnable(tool2) && "lc_name" in tool2.constructor && typeof tool2.constructor.lc_name === "function" && tool2.constructor.lc_name() === "RunnableToolLike";
}
function isStructuredToolParams(tool2) {
  return !!tool2 && typeof tool2 === "object" && "name" in tool2 && "schema" in tool2 && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  (isInteropZodSchema(tool2.schema) || tool2.schema != null && typeof tool2.schema === "object" && "type" in tool2.schema && typeof tool2.schema.type === "string" && ["null", "boolean", "object", "array", "number", "string"].includes(tool2.schema.type));
}
function isLangChainTool(tool2) {
  return isStructuredToolParams(tool2) || isRunnableToolLike(tool2) || // eslint-disable-next-line @typescript-eslint/no-explicit-any
  isStructuredTool(tool2);
}

// node_modules/@langchain/core/dist/tools/index.js
var StructuredTool = class extends BaseLangChain {
  get lc_namespace() {
    return ["langchain", "tools"];
  }
  constructor(fields) {
    super(fields ?? {});
    Object.defineProperty(this, "returnDirect", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "verboseParsingErrors", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "responseFormat", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "content"
    });
    Object.defineProperty(this, "defaultConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.verboseParsingErrors = (fields == null ? void 0 : fields.verboseParsingErrors) ?? this.verboseParsingErrors;
    this.responseFormat = (fields == null ? void 0 : fields.responseFormat) ?? this.responseFormat;
    this.defaultConfig = (fields == null ? void 0 : fields.defaultConfig) ?? this.defaultConfig;
    this.metadata = (fields == null ? void 0 : fields.metadata) ?? this.metadata;
  }
  /**
   * Invokes the tool with the provided input and configuration.
   * @param input The input for the tool.
   * @param config Optional configuration for the tool.
   * @returns A Promise that resolves with the tool's output.
   */
  async invoke(input, config) {
    let toolInput;
    let enrichedConfig = ensureConfig(mergeConfigs(this.defaultConfig, config));
    if (_isToolCall(input)) {
      toolInput = input.args;
      enrichedConfig = {
        ...enrichedConfig,
        toolCall: input
      };
    } else {
      toolInput = input;
    }
    return this.call(toolInput, enrichedConfig);
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Calls the tool with the provided argument, configuration, and tags. It
   * parses the input according to the schema, handles any errors, and
   * manages callbacks.
   * @param arg The input argument for the tool.
   * @param configArg Optional configuration or callbacks for the tool.
   * @param tags Optional tags for the tool.
   * @returns A Promise that resolves with a string.
   */
  async call(arg, configArg, tags) {
    const inputForValidation = _isToolCall(arg) ? arg.args : arg;
    let parsed;
    if (isInteropZodSchema(this.schema)) {
      try {
        parsed = await interopParseAsync(this.schema, inputForValidation);
      } catch (e) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) {
          message = `${message}
Details: ${e.message}`;
        }
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
    } else {
      const result2 = validate(inputForValidation, this.schema);
      if (!result2.valid) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) {
          message = `${message}
Details: ${result2.errors.map((e) => `${e.keywordLocation}: ${e.error}`).join("\n")}`;
        }
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
      parsed = inputForValidation;
    }
    const config = parseCallbackConfigArg(configArg);
    const callbackManager_ = CallbackManager.configure(config.callbacks, this.callbacks, config.tags || tags, this.tags, config.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await (callbackManager_ == null ? void 0 : callbackManager_.handleToolStart(
      this.toJSON(),
      // Log the original raw input arg
      typeof arg === "string" ? arg : JSON.stringify(arg),
      config.runId,
      void 0,
      void 0,
      void 0,
      config.runName
    ));
    delete config.runId;
    let result;
    try {
      result = await this._call(parsed, runManager, config);
    } catch (e) {
      await (runManager == null ? void 0 : runManager.handleToolError(e));
      throw e;
    }
    let content;
    let artifact;
    if (this.responseFormat === "content_and_artifact") {
      if (Array.isArray(result) && result.length === 2) {
        [content, artifact] = result;
      } else {
        throw new Error(`Tool response format is "content_and_artifact" but the output was not a two-tuple.
Result: ${JSON.stringify(result)}`);
      }
    } else {
      content = result;
    }
    let toolCallId;
    if (_isToolCall(arg)) {
      toolCallId = arg.id;
    }
    if (!toolCallId && _configHasToolCallId(config)) {
      toolCallId = config.toolCall.id;
    }
    const formattedOutput = _formatToolOutput({
      content,
      artifact,
      toolCallId,
      name: this.name,
      metadata: this.metadata
    });
    await (runManager == null ? void 0 : runManager.handleToolEnd(formattedOutput));
    return formattedOutput;
  }
};
var Tool = class extends StructuredTool {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: external_exports.object({ input: external_exports.string().optional() }).transform((obj) => obj.input)
    });
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   *
   * Calls the tool with the provided argument and callbacks. It handles
   * string inputs specifically.
   * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
   * @param callbacks Optional callbacks for the tool.
   * @returns A Promise that resolves with a string.
   */
  // Match the base class signature including the generics and conditional return type
  call(arg, callbacks) {
    const structuredArg = typeof arg === "string" || arg == null ? { input: arg } : arg;
    return super.call(structuredArg, callbacks);
  }
};
var DynamicTool = class extends Tool {
  static lc_name() {
    return "DynamicTool";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   */
  async call(arg, configArg) {
    const config = parseCallbackConfigArg(configArg);
    if (config.runName === void 0) {
      config.runName = this.name;
    }
    return super.call(arg, config);
  }
  /** @ignore */
  async _call(input, runManager, parentConfig) {
    return this.func(input, runManager, parentConfig);
  }
};
var DynamicStructuredTool = class extends StructuredTool {
  static lc_name() {
    return "DynamicStructuredTool";
  }
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
    this.schema = fields.schema;
  }
  /**
   * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
   */
  // Match the base class signature
  async call(arg, configArg, tags) {
    const config = parseCallbackConfigArg(configArg);
    if (config.runName === void 0) {
      config.runName = this.name;
    }
    return super.call(arg, config, tags);
  }
  _call(arg, runManager, parentConfig) {
    return this.func(arg, runManager, parentConfig);
  }
};
var BaseToolkit = class {
  getTools() {
    return this.tools;
  }
};
function tool(func, fields) {
  const isSimpleStringSchema = isSimpleStringZodSchema(fields.schema);
  const isStringJSONSchema = validatesOnlyStrings(fields.schema);
  if (!fields.schema || isSimpleStringSchema || isStringJSONSchema) {
    return new DynamicTool({
      ...fields,
      description: fields.description ?? (fields.schema && getSchemaDescription(fields.schema)) ?? `${fields.name} tool`,
      func: async (input, runManager, config) => {
        return new Promise((resolve, reject) => {
          const childConfig = patchConfig(config, {
            callbacks: runManager == null ? void 0 : runManager.getChild()
          });
          void AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
            try {
              resolve(func(input, childConfig));
            } catch (e) {
              reject(e);
            }
          });
        });
      }
    });
  }
  const schema = fields.schema;
  const description = fields.description ?? fields.schema.description ?? `${fields.name} tool`;
  return new DynamicStructuredTool({
    ...fields,
    description,
    schema,
    func: async (input, runManager, config) => {
      return new Promise((resolve, reject) => {
        const childConfig = patchConfig(config, {
          callbacks: runManager == null ? void 0 : runManager.getChild()
        });
        void AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            resolve(func(input, childConfig));
          } catch (e) {
            reject(e);
          }
        });
      });
    }
  });
}
function _formatToolOutput(params) {
  const { content, artifact, toolCallId, metadata } = params;
  if (toolCallId && !isDirectToolOutput(content)) {
    if (typeof content === "string" || Array.isArray(content) && content.every((item) => typeof item === "object")) {
      return new ToolMessage({
        status: "success",
        content,
        artifact,
        tool_call_id: toolCallId,
        name: params.name,
        metadata
      });
    } else {
      return new ToolMessage({
        status: "success",
        content: _stringify(content),
        artifact,
        tool_call_id: toolCallId,
        name: params.name,
        metadata
      });
    }
  } else {
    return content;
  }
}
function _stringify(content) {
  try {
    return JSON.stringify(content, null, 2) ?? "";
  } catch (_noOp) {
    return `${content}`;
  }
}

// node_modules/@langchain/core/dist/tracers/initialize.js
var initialize_exports = {};
__export(initialize_exports, {
  getTracingCallbackHandler: () => getTracingCallbackHandler,
  getTracingV2CallbackHandler: () => getTracingV2CallbackHandler
});

// node_modules/@langchain/core/dist/tracers/tracer_langchain_v1.js
var tracer_langchain_v1_exports = {};
__export(tracer_langchain_v1_exports, {
  LangChainTracerV1: () => LangChainTracerV1
});
var LangChainTracerV1 = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "langchain_tracer"
    });
    Object.defineProperty(this, "endpoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: getEnvironmentVariable("LANGCHAIN_ENDPOINT") || "http://localhost:1984"
    });
    Object.defineProperty(this, "headers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {
        "Content-Type": "application/json"
      }
    });
    Object.defineProperty(this, "session", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    const apiKey = getEnvironmentVariable("LANGCHAIN_API_KEY");
    if (apiKey) {
      this.headers["x-api-key"] = apiKey;
    }
  }
  async newSession(sessionName) {
    const sessionCreate = {
      start_time: Date.now(),
      name: sessionName
    };
    const session = await this.persistSession(sessionCreate);
    this.session = session;
    return session;
  }
  async loadSession(sessionName) {
    const endpoint = `${this.endpoint}/sessions?name=${sessionName}`;
    return this._handleSessionResponse(endpoint);
  }
  async loadDefaultSession() {
    const endpoint = `${this.endpoint}/sessions?name=default`;
    return this._handleSessionResponse(endpoint);
  }
  async convertV2RunToRun(run) {
    var _a2;
    const session = this.session ?? await this.loadDefaultSession();
    const serialized = run.serialized;
    let runResult;
    if (run.run_type === "llm") {
      const prompts = run.inputs.prompts ? run.inputs.prompts : run.inputs.messages.map((x) => getBufferString(x));
      const llmRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        prompts,
        response: run.outputs
      };
      runResult = llmRun;
    } else if (run.run_type === "chain") {
      const child_runs = await Promise.all(run.child_runs.map((child_run) => this.convertV2RunToRun(child_run)));
      const chainRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        inputs: run.inputs,
        outputs: run.outputs,
        child_llm_runs: child_runs.filter((child_run) => child_run.type === "llm"),
        child_chain_runs: child_runs.filter((child_run) => child_run.type === "chain"),
        child_tool_runs: child_runs.filter((child_run) => child_run.type === "tool")
      };
      runResult = chainRun;
    } else if (run.run_type === "tool") {
      const child_runs = await Promise.all(run.child_runs.map((child_run) => this.convertV2RunToRun(child_run)));
      const toolRun = {
        uuid: run.id,
        start_time: run.start_time,
        end_time: run.end_time,
        execution_order: run.execution_order,
        child_execution_order: run.child_execution_order,
        serialized,
        type: run.run_type,
        session_id: session.id,
        tool_input: run.inputs.input,
        output: (_a2 = run.outputs) == null ? void 0 : _a2.output,
        action: JSON.stringify(serialized),
        child_llm_runs: child_runs.filter((child_run) => child_run.type === "llm"),
        child_chain_runs: child_runs.filter((child_run) => child_run.type === "chain"),
        child_tool_runs: child_runs.filter((child_run) => child_run.type === "tool")
      };
      runResult = toolRun;
    } else {
      throw new Error(`Unknown run type: ${run.run_type}`);
    }
    return runResult;
  }
  async persistRun(run) {
    let endpoint;
    let v1Run;
    if (run.run_type !== void 0) {
      v1Run = await this.convertV2RunToRun(run);
    } else {
      v1Run = run;
    }
    if (v1Run.type === "llm") {
      endpoint = `${this.endpoint}/llm-runs`;
    } else if (v1Run.type === "chain") {
      endpoint = `${this.endpoint}/chain-runs`;
    } else {
      endpoint = `${this.endpoint}/tool-runs`;
    }
    const response = await fetch(endpoint, {
      method: "POST",
      headers: this.headers,
      body: JSON.stringify(v1Run)
    });
    if (!response.ok) {
      console.error(`Failed to persist run: ${response.status} ${response.statusText}`);
    }
  }
  async persistSession(sessionCreate) {
    const endpoint = `${this.endpoint}/sessions`;
    const response = await fetch(endpoint, {
      method: "POST",
      headers: this.headers,
      body: JSON.stringify(sessionCreate)
    });
    if (!response.ok) {
      console.error(`Failed to persist session: ${response.status} ${response.statusText}, using default session.`);
      return {
        id: 1,
        ...sessionCreate
      };
    }
    return {
      id: (await response.json()).id,
      ...sessionCreate
    };
  }
  async _handleSessionResponse(endpoint) {
    const response = await fetch(endpoint, {
      method: "GET",
      headers: this.headers
    });
    let tracerSession;
    if (!response.ok) {
      console.error(`Failed to load session: ${response.status} ${response.statusText}`);
      tracerSession = {
        id: 1,
        start_time: Date.now()
      };
      this.session = tracerSession;
      return tracerSession;
    }
    const resp = await response.json();
    if (resp.length === 0) {
      tracerSession = {
        id: 1,
        start_time: Date.now()
      };
      this.session = tracerSession;
      return tracerSession;
    }
    [tracerSession] = resp;
    this.session = tracerSession;
    return tracerSession;
  }
};

// node_modules/@langchain/core/dist/tracers/initialize.js
async function getTracingCallbackHandler(session) {
  const tracer = new LangChainTracerV1();
  if (session) {
    await tracer.loadSession(session);
  } else {
    await tracer.loadDefaultSession();
  }
  return tracer;
}
async function getTracingV2CallbackHandler() {
  return new LangChainTracer();
}

// node_modules/@langchain/core/dist/tracers/run_collector.js
var run_collector_exports = {};
__export(run_collector_exports, {
  RunCollectorCallbackHandler: () => RunCollectorCallbackHandler
});
var RunCollectorCallbackHandler = class extends BaseTracer {
  /**
   * Creates a new instance of the RunCollectorCallbackHandler class.
   * @param exampleId The ID of the example.
   */
  constructor({ exampleId } = {}) {
    super({ _awaitHandler: true });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "run_collector"
    });
    Object.defineProperty(this, "exampleId", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tracedRuns", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.exampleId = exampleId;
    this.tracedRuns = [];
  }
  /**
   * Persists the given run object.
   * @param run The run object to persist.
   */
  async persistRun(run) {
    const run_ = { ...run };
    run_.reference_example_id = this.exampleId;
    this.tracedRuns.push(run_);
  }
};

// node_modules/@langchain/core/dist/utils/chunk_array.js
var chunk_array_exports = {};
__export(chunk_array_exports, {
  chunkArray: () => chunkArray
});
var chunkArray = (arr2, chunkSize) => arr2.reduce((chunks, elem, index) => {
  const chunkIndex = Math.floor(index / chunkSize);
  const chunk = chunks[chunkIndex] || [];
  chunks[chunkIndex] = chunk.concat([elem]);
  return chunks;
}, []);

// node_modules/@langchain/core/dist/utils/function_calling.js
var function_calling_exports = {};
__export(function_calling_exports, {
  convertToOpenAIFunction: () => convertToOpenAIFunction,
  convertToOpenAITool: () => convertToOpenAITool,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams
});
function convertToOpenAIFunction(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  return {
    name: tool2.name,
    description: tool2.description,
    parameters: toJsonSchema(tool2.schema),
    // Do not include the `strict` field if it is `undefined`.
    ...(fieldsCopy == null ? void 0 : fieldsCopy.strict) !== void 0 ? { strict: fieldsCopy.strict } : {}
  };
}
function convertToOpenAITool(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  let toolDef;
  if (isLangChainTool(tool2)) {
    toolDef = {
      type: "function",
      function: convertToOpenAIFunction(tool2)
    };
  } else {
    toolDef = tool2;
  }
  if ((fieldsCopy == null ? void 0 : fieldsCopy.strict) !== void 0) {
    toolDef.function.strict = fieldsCopy.strict;
  }
  return toolDef;
}

// node_modules/@langchain/core/dist/utils/math.js
var math_exports = {};
__export(math_exports, {
  cosineSimilarity: () => cosineSimilarity,
  euclideanDistance: () => euclideanDistance,
  innerProduct: () => innerProduct2,
  matrixFunc: () => matrixFunc,
  maximalMarginalRelevance: () => maximalMarginalRelevance,
  normalize: () => normalize
});

// node_modules/@langchain/core/dist/utils/ml-distance/similarities.js
function cosine(a, b) {
  let p = 0;
  let p2 = 0;
  let q2 = 0;
  for (let i = 0; i < a.length; i++) {
    p += a[i] * b[i];
    p2 += a[i] * a[i];
    q2 += b[i] * b[i];
  }
  return p / (Math.sqrt(p2) * Math.sqrt(q2));
}

// node_modules/@langchain/core/dist/utils/ml-distance/distances.js
function innerProduct(a, b) {
  let ans = 0;
  for (let i = 0; i < a.length; i++) {
    ans += a[i] * b[i];
  }
  return ans;
}

// node_modules/@langchain/core/dist/utils/ml-distance-euclidean/euclidean.js
function squaredEuclidean(p, q) {
  let d = 0;
  for (let i = 0; i < p.length; i++) {
    d += (p[i] - q[i]) * (p[i] - q[i]);
  }
  return d;
}
function euclidean(p, q) {
  return Math.sqrt(squaredEuclidean(p, q));
}

// node_modules/@langchain/core/dist/utils/math.js
function matrixFunc(X, Y, func) {
  if (X.length === 0 || X[0].length === 0 || Y.length === 0 || Y[0].length === 0) {
    return [[]];
  }
  if (X[0].length !== Y[0].length) {
    throw new Error(`Number of columns in X and Y must be the same. X has shape ${[
      X.length,
      X[0].length
    ]} and Y has shape ${[Y.length, Y[0].length]}.`);
  }
  return X.map((xVector) => Y.map((yVector) => func(xVector, yVector)).map((similarity) => Number.isNaN(similarity) ? 0 : similarity));
}
function normalize(M, similarity = false) {
  const max = matrixMaxVal(M);
  return M.map((row) => row.map((val) => similarity ? 1 - val / max : val / max));
}
function cosineSimilarity(X, Y) {
  return matrixFunc(X, Y, cosine);
}
function innerProduct2(X, Y) {
  return matrixFunc(X, Y, innerProduct);
}
function euclideanDistance(X, Y) {
  return matrixFunc(X, Y, euclidean);
}
function maximalMarginalRelevance(queryEmbedding, embeddingList, lambda = 0.5, k = 4) {
  if (Math.min(k, embeddingList.length) <= 0) {
    return [];
  }
  const queryEmbeddingExpanded = Array.isArray(queryEmbedding[0]) ? queryEmbedding : [queryEmbedding];
  const similarityToQuery = cosineSimilarity(queryEmbeddingExpanded, embeddingList)[0];
  const mostSimilarEmbeddingIndex = argMax(similarityToQuery).maxIndex;
  const selectedEmbeddings = [embeddingList[mostSimilarEmbeddingIndex]];
  const selectedEmbeddingsIndexes = [mostSimilarEmbeddingIndex];
  while (selectedEmbeddingsIndexes.length < Math.min(k, embeddingList.length)) {
    let bestScore = -Infinity;
    let bestIndex = -1;
    const similarityToSelected = cosineSimilarity(embeddingList, selectedEmbeddings);
    similarityToQuery.forEach((queryScore, queryScoreIndex) => {
      if (selectedEmbeddingsIndexes.includes(queryScoreIndex)) {
        return;
      }
      const maxSimilarityToSelected = Math.max(...similarityToSelected[queryScoreIndex]);
      const score = lambda * queryScore - (1 - lambda) * maxSimilarityToSelected;
      if (score > bestScore) {
        bestScore = score;
        bestIndex = queryScoreIndex;
      }
    });
    selectedEmbeddings.push(embeddingList[bestIndex]);
    selectedEmbeddingsIndexes.push(bestIndex);
  }
  return selectedEmbeddingsIndexes;
}
function argMax(array) {
  if (array.length === 0) {
    return {
      maxIndex: -1,
      maxValue: NaN
    };
  }
  let maxValue = array[0];
  let maxIndex = 0;
  for (let i = 1; i < array.length; i += 1) {
    if (array[i] > maxValue) {
      maxIndex = i;
      maxValue = array[i];
    }
  }
  return { maxIndex, maxValue };
}
function matrixMaxVal(arrays) {
  return arrays.reduce((acc, array) => Math.max(acc, argMax(array).maxValue), 0);
}

// node_modules/@langchain/core/dist/utils/testing/index.js
var testing_exports = {};
__export(testing_exports, {
  FakeChatMessageHistory: () => FakeChatMessageHistory,
  FakeChatModel: () => FakeChatModel,
  FakeEmbeddings: () => FakeEmbeddings,
  FakeLLM: () => FakeLLM,
  FakeListChatMessageHistory: () => FakeListChatMessageHistory,
  FakeListChatModel: () => FakeListChatModel,
  FakeRetriever: () => FakeRetriever,
  FakeRunnable: () => FakeRunnable,
  FakeSplitIntoListParser: () => FakeSplitIntoListParser,
  FakeStreamingChatModel: () => FakeStreamingChatModel,
  FakeStreamingLLM: () => FakeStreamingLLM,
  FakeTool: () => FakeTool,
  FakeTracer: () => FakeTracer,
  FakeVectorStore: () => FakeVectorStore,
  SingleRunExtractor: () => SingleRunExtractor,
  SyntheticEmbeddings: () => SyntheticEmbeddings
});

// node_modules/@langchain/core/dist/vectorstores.js
var vectorstores_exports = {};
__export(vectorstores_exports, {
  SaveableVectorStore: () => SaveableVectorStore,
  VectorStore: () => VectorStore,
  VectorStoreRetriever: () => VectorStoreRetriever
});
var VectorStoreRetriever = class extends BaseRetriever {
  static lc_name() {
    return "VectorStoreRetriever";
  }
  get lc_namespace() {
    return ["langchain_core", "vectorstores"];
  }
  /**
   * Returns the type of vector store, as defined by the `vectorStore` instance.
   *
   * @returns {string} The vector store type.
   */
  _vectorstoreType() {
    return this.vectorStore._vectorstoreType();
  }
  /**
   * Initializes a new instance of `VectorStoreRetriever` with the specified configuration.
   *
   * This constructor configures the retriever to interact with a given `VectorStore`
   * and supports different retrieval strategies, including similarity search and maximal
   * marginal relevance (MMR) search. Various options allow customization of the number
   * of documents retrieved per query, filtering based on conditions, and fine-tuning
   * MMR-specific parameters.
   *
   * @param fields - Configuration options for setting up the retriever:
   *
   *   - `vectorStore` (required): The `VectorStore` instance implementing `VectorStoreInterface`
   *     that will be used to store and retrieve document embeddings. This is the core component
   *     of the retriever, enabling vector-based similarity and MMR searches.
   *
   *   - `k` (optional): Specifies the number of documents to retrieve per search query. If not
   *     provided, defaults to 4. This count determines the number of most relevant documents returned
   *     for each search operation, balancing performance with comprehensiveness.
   *
   *   - `searchType` (optional): Defines the search approach used by the retriever, allowing for
   *     flexibility between two methods:
   *       - `"similarity"` (default): A similarity-based search, retrieving documents with high vector
   *         similarity to the query. This type prioritizes relevance and is often used when diversity
   *         among results is less critical.
   *       - `"mmr"`: Maximal Marginal Relevance search, which combines relevance with diversity. MMR
   *         is useful for scenarios where varied content is essential, as it selects results that
   *         both match the query and introduce content diversity.
   *
   *   - `filter` (optional): A filter of type `FilterType`, defined by the vector store, that allows
   *     for refined and targeted search results. This filter applies specified conditions to limit
   *     which documents are eligible for retrieval, offering control over the scope of results.
   *
   *   - `searchKwargs` (optional, applicable only if `searchType` is `"mmr"`): Additional settings
   *     for configuring MMR-specific behavior. These parameters allow further tuning of the MMR
   *     search process:
   *       - `fetchK`: The initial number of documents fetched from the vector store before the MMR
   *         algorithm is applied. Fetching a larger set enables the algorithm to select a more
   *         diverse subset of documents.
   *       - `lambda`: A parameter controlling the relevance-diversity balance, where 0 emphasizes
   *         diversity and 1 prioritizes relevance. Intermediate values provide a blend of the two,
   *         allowing customization based on the importance of content variety relative to query relevance.
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "vectorStore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "k", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 4
    });
    Object.defineProperty(this, "searchType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "similarity"
    });
    Object.defineProperty(this, "searchKwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "filter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.vectorStore = fields.vectorStore;
    this.k = fields.k ?? this.k;
    this.searchType = fields.searchType ?? this.searchType;
    this.filter = fields.filter;
    if (fields.searchType === "mmr") {
      this.searchKwargs = fields.searchKwargs;
    }
  }
  /**
   * Retrieves relevant documents based on the specified query, using either
   * similarity or maximal marginal relevance (MMR) search.
   *
   * If `searchType` is set to `"mmr"`, performs an MMR search to balance
   * similarity and diversity among results. If `searchType` is `"similarity"`,
   * retrieves results purely based on similarity to the query.
   *
   * @param query - The query string used to find relevant documents.
   * @param runManager - Optional callback manager for tracking retrieval progress.
   * @returns A promise that resolves to an array of `DocumentInterface` instances
   *          representing the most relevant documents to the query.
   * @throws {Error} Throws an error if MMR search is requested but not supported
   *                 by the vector store.
   * @protected
   */
  async _getRelevantDocuments(query, runManager) {
    if (this.searchType === "mmr") {
      if (typeof this.vectorStore.maxMarginalRelevanceSearch !== "function") {
        throw new Error(`The vector store backing this retriever, ${this._vectorstoreType()} does not support max marginal relevance search.`);
      }
      return this.vectorStore.maxMarginalRelevanceSearch(query, {
        k: this.k,
        filter: this.filter,
        ...this.searchKwargs
      }, runManager == null ? void 0 : runManager.getChild("vectorstore"));
    }
    return this.vectorStore.similaritySearch(query, this.k, this.filter, runManager == null ? void 0 : runManager.getChild("vectorstore"));
  }
  /**
   * Adds an array of documents to the vector store, embedding them as part of
   * the storage process.
   *
   * This method delegates document embedding and storage to the `addDocuments`
   * method of the underlying vector store.
   *
   * @param documents - An array of documents to embed and add to the vector store.
   * @param options - Optional settings to customize document addition.
   * @returns A promise that resolves to an array of document IDs or `void`,
   *          depending on the vector store's implementation.
   */
  async addDocuments(documents, options) {
    return this.vectorStore.addDocuments(documents, options);
  }
};
var VectorStore = class extends Serializable {
  /**
   * Initializes a new vector store with embeddings and database configuration.
   *
   * @param embeddings - Instance of `EmbeddingsInterface` used to embed queries.
   * @param dbConfig - Configuration settings for the database or storage system.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(embeddings, dbConfig) {
    super(dbConfig);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain", "vectorstores", this._vectorstoreType()]
    });
    Object.defineProperty(this, "embeddings", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.embeddings = embeddings;
  }
  /**
   * Deletes documents from the vector store based on the specified parameters.
   *
   * @param _params - Flexible key-value pairs defining conditions for document deletion.
   * @returns A promise that resolves once the deletion is complete.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  async delete(_params) {
    throw new Error("Not implemented.");
  }
  /**
   * Searches for documents similar to a text query by embedding the query and
   * performing a similarity search on the resulting vector.
   *
   * @param query - Text query for finding similar documents.
   * @param k - Number of similar results to return. Defaults to 4.
   * @param filter - Optional filter based on `FilterType`.
   * @param _callbacks - Optional callbacks for monitoring search progress
   * @returns A promise resolving to an array of `DocumentInterface` instances representing similar documents.
   */
  async similaritySearch(query, k = 4, filter = void 0, _callbacks = void 0) {
    const results = await this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);
    return results.map((result) => result[0]);
  }
  /**
   * Searches for documents similar to a text query by embedding the query,
   * and returns results with similarity scores.
   *
   * @param query - Text query for finding similar documents.
   * @param k - Number of similar results to return. Defaults to 4.
   * @param filter - Optional filter based on `FilterType`.
   * @param _callbacks - Optional callbacks for monitoring search progress
   * @returns A promise resolving to an array of tuples, each containing a
   *          document and its similarity score.
   */
  async similaritySearchWithScore(query, k = 4, filter = void 0, _callbacks = void 0) {
    return this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);
  }
  /**
   * Creates a `VectorStore` instance from an array of text strings and optional
   * metadata, using the specified embeddings and database configuration.
   *
   * Subclasses must implement this method to define how text and metadata
   * are embedded and stored in the vector store. Throws an error if not overridden.
   *
   * @param _texts - Array of strings representing the text documents to be stored.
   * @param _metadatas - Metadata for the texts, either as an array (one for each text)
   *                     or a single object (applied to all texts).
   * @param _embeddings - Instance of `EmbeddingsInterface` to embed the texts.
   * @param _dbConfig - Database configuration settings.
   * @returns A promise that resolves to a new `VectorStore` instance.
   * @throws {Error} Throws an error if this method is not overridden by a subclass.
   */
  static fromTexts(_texts, _metadatas, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
   * Creates a `VectorStore` instance from an array of documents, using the specified
   * embeddings and database configuration.
   *
   * Subclasses must implement this method to define how documents are embedded
   * and stored. Throws an error if not overridden.
   *
   * @param _docs - Array of `DocumentInterface` instances representing the documents to be stored.
   * @param _embeddings - Instance of `EmbeddingsInterface` to embed the documents.
   * @param _dbConfig - Database configuration settings.
   * @returns A promise that resolves to a new `VectorStore` instance.
   * @throws {Error} Throws an error if this method is not overridden by a subclass.
   */
  static fromDocuments(_docs, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
   * Creates a `VectorStoreRetriever` instance with flexible configuration options.
   *
   * @param kOrFields
   *    - If a number is provided, it sets the `k` parameter (number of items to retrieve).
   *    - If an object is provided, it should contain various configuration options.
   * @param filter
   *    - Optional filter criteria to limit the items retrieved based on the specified filter type.
   * @param callbacks
   *    - Optional callbacks that may be triggered at specific stages of the retrieval process.
   * @param tags
   *    - Tags to categorize or label the `VectorStoreRetriever`. Defaults to an empty array if not provided.
   * @param metadata
   *    - Additional metadata as key-value pairs to add contextual information for the retrieval process.
   * @param verbose
   *    - If `true`, enables detailed logging for the retrieval process. Defaults to `false`.
   *
   * @returns
   *    - A configured `VectorStoreRetriever` instance based on the provided parameters.
   *
   * @example
   * Basic usage with a `k` value:
   * ```typescript
   * const retriever = myVectorStore.asRetriever(5);
   * ```
   *
   * Usage with a configuration object:
   * ```typescript
   * const retriever = myVectorStore.asRetriever({
   *   k: 10,
   *   filter: myFilter,
   *   tags: ['example', 'test'],
   *   verbose: true,
   *   searchType: 'mmr',
   *   searchKwargs: { alpha: 0.5 },
   * });
   * ```
   */
  asRetriever(kOrFields, filter, callbacks, tags, metadata, verbose) {
    if (typeof kOrFields === "number") {
      return new VectorStoreRetriever({
        vectorStore: this,
        k: kOrFields,
        filter,
        tags: [...tags ?? [], this._vectorstoreType()],
        metadata,
        verbose,
        callbacks
      });
    } else {
      const params = {
        vectorStore: this,
        k: kOrFields == null ? void 0 : kOrFields.k,
        filter: kOrFields == null ? void 0 : kOrFields.filter,
        tags: [...(kOrFields == null ? void 0 : kOrFields.tags) ?? [], this._vectorstoreType()],
        metadata: kOrFields == null ? void 0 : kOrFields.metadata,
        verbose: kOrFields == null ? void 0 : kOrFields.verbose,
        callbacks: kOrFields == null ? void 0 : kOrFields.callbacks,
        searchType: kOrFields == null ? void 0 : kOrFields.searchType
      };
      if ((kOrFields == null ? void 0 : kOrFields.searchType) === "mmr") {
        return new VectorStoreRetriever({
          ...params,
          searchKwargs: kOrFields.searchKwargs
        });
      }
      return new VectorStoreRetriever({ ...params });
    }
  }
};
var SaveableVectorStore = class extends VectorStore {
  /**
   * Loads a vector store instance from the specified directory, using the
   * provided embeddings to ensure compatibility.
   *
   * This static method reconstructs a `SaveableVectorStore` from previously
   * saved data. Implementations should interpret the saved data format to
   * recreate the vector store instance.
   *
   * @param _directory - The directory path from which the vector store
   * data will be loaded.
   * @param _embeddings - An instance of `EmbeddingsInterface` to align
   * the embeddings with the loaded vector data.
   * @returns A promise that resolves to a `SaveableVectorStore` instance
   * constructed from the saved data.
   */
  static load(_directory, _embeddings) {
    throw new Error("Not implemented");
  }
};

// node_modules/@langchain/core/dist/utils/testing/index.js
var FakeSplitIntoListParser = class extends BaseOutputParser {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["tests", "fake"]
    });
  }
  getFormatInstructions() {
    return "";
  }
  async parse(text) {
    return text.split(",").map((value) => value.trim());
  }
};
var FakeRunnable = class extends Runnable {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["tests", "fake"]
    });
    Object.defineProperty(this, "returnOptions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.returnOptions = fields.returnOptions;
  }
  async invoke(input, options) {
    if (this.returnOptions) {
      return options ?? {};
    }
    return { input };
  }
};
var FakeLLM = class extends LLM {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "response", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.response = fields.response;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt, _options, runManager) {
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = this.response ?? prompt;
    await (runManager == null ? void 0 : runManager.handleLLMNewToken(response));
    return response;
  }
};
var FakeStreamingLLM = class extends LLM {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 50
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.sleep = fields.sleep ?? this.sleep;
    this.responses = fields.responses;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt) {
    var _a2, _b;
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = (_a2 = this.responses) == null ? void 0 : _a2[0];
    this.responses = (_b = this.responses) == null ? void 0 : _b.slice(1);
    return response ?? prompt;
  }
  async *_streamResponseChunks(input, _options, runManager) {
    var _a2, _b;
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const response = (_a2 = this.responses) == null ? void 0 : _a2[0];
    this.responses = (_b = this.responses) == null ? void 0 : _b.slice(1);
    for (const c of response ?? input) {
      await new Promise((resolve) => setTimeout(resolve, this.sleep));
      yield { text: c, generationInfo: {} };
      await (runManager == null ? void 0 : runManager.handleLLMNewToken(c));
    }
  }
};
var FakeChatModel = class extends BaseChatModel {
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake";
  }
  async _generate(messages, options, runManager) {
    var _a2;
    if ((_a2 = options == null ? void 0 : options.stop) == null ? void 0 : _a2.length) {
      return {
        generations: [
          {
            message: new AIMessage(options.stop[0]),
            text: options.stop[0]
          }
        ]
      };
    }
    const text = messages.map((m) => {
      if (typeof m.content === "string") {
        return m.content;
      }
      return JSON.stringify(m.content, null, 2);
    }).join("\n");
    await (runManager == null ? void 0 : runManager.handleLLMNewToken(text));
    return {
      generations: [
        {
          message: new AIMessage(text),
          text
        }
      ],
      llmOutput: {}
    };
  }
};
var FakeStreamingChatModel = class _FakeStreamingChatModel extends BaseChatModel {
  constructor({ sleep = 50, responses = [], chunks = [], toolStyle = "openai", thrownErrorString, ...rest }) {
    super(rest);
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 50
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "chunks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "toolStyle", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "openai"
    });
    Object.defineProperty(this, "thrownErrorString", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tools", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.sleep = sleep;
    this.responses = responses;
    this.chunks = chunks;
    this.toolStyle = toolStyle;
    this.thrownErrorString = thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  bindTools(tools) {
    const merged = [...this.tools, ...tools];
    const toolDicts = merged.map((t) => {
      switch (this.toolStyle) {
        case "openai":
          return {
            type: "function",
            function: {
              name: t.name,
              description: t.description,
              parameters: toJsonSchema(t.schema)
            }
          };
        case "anthropic":
          return {
            name: t.name,
            description: t.description,
            input_schema: toJsonSchema(t.schema)
          };
        case "bedrock":
          return {
            toolSpec: {
              name: t.name,
              description: t.description,
              inputSchema: toJsonSchema(t.schema)
            }
          };
        case "google":
          return {
            name: t.name,
            description: t.description,
            parameters: toJsonSchema(t.schema)
          };
        default:
          throw new Error(`Unsupported tool style: ${this.toolStyle}`);
      }
    });
    const wrapped = this.toolStyle === "google" ? [{ functionDeclarations: toolDicts }] : toolDicts;
    const next = new _FakeStreamingChatModel({
      sleep: this.sleep,
      responses: this.responses,
      chunks: this.chunks,
      toolStyle: this.toolStyle,
      thrownErrorString: this.thrownErrorString
    });
    next.tools = merged;
    return next.withConfig({ tools: wrapped });
  }
  async _generate(messages, _options, _runManager) {
    var _a2, _b, _c, _d;
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    const content = ((_b = (_a2 = this.responses) == null ? void 0 : _a2[0]) == null ? void 0 : _b.content) ?? messages[0].content ?? "";
    const generation = {
      generations: [
        {
          text: "",
          message: new AIMessage({
            content,
            tool_calls: (_d = (_c = this.chunks) == null ? void 0 : _c[0]) == null ? void 0 : _d.tool_calls
          })
        }
      ]
    };
    return generation;
  }
  async *_streamResponseChunks(_messages, _options, runManager) {
    var _a2, _b, _c;
    if (this.thrownErrorString) {
      throw new Error(this.thrownErrorString);
    }
    if ((_a2 = this.chunks) == null ? void 0 : _a2.length) {
      for (const msgChunk of this.chunks) {
        const cg = new ChatGenerationChunk({
          message: new AIMessageChunk({
            content: msgChunk.content,
            tool_calls: msgChunk.tool_calls,
            additional_kwargs: msgChunk.additional_kwargs ?? {}
          }),
          text: ((_b = msgChunk.content) == null ? void 0 : _b.toString()) ?? ""
        });
        yield cg;
        await (runManager == null ? void 0 : runManager.handleLLMNewToken(msgChunk.content, void 0, void 0, void 0, void 0, { chunk: cg }));
      }
      return;
    }
    const fallback = ((_c = this.responses) == null ? void 0 : _c[0]) ?? new AIMessage(typeof _messages[0].content === "string" ? _messages[0].content : "");
    const text = typeof fallback.content === "string" ? fallback.content : "";
    for (const ch of text) {
      await new Promise((r) => setTimeout(r, this.sleep));
      const cg = new ChatGenerationChunk({
        message: new AIMessageChunk({ content: ch }),
        text: ch
      });
      yield cg;
      await (runManager == null ? void 0 : runManager.handleLLMNewToken(ch, void 0, void 0, void 0, void 0, { chunk: cg }));
    }
  }
};
var FakeRetriever = class extends BaseRetriever {
  constructor(fields) {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["test", "fake"]
    });
    Object.defineProperty(this, "output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: [
        new Document({ pageContent: "foo" }),
        new Document({ pageContent: "bar" })
      ]
    });
    this.output = (fields == null ? void 0 : fields.output) ?? this.output;
  }
  async _getRelevantDocuments(_query) {
    return this.output;
  }
};
var FakeListChatModel = class extends BaseChatModel {
  static lc_name() {
    return "FakeListChatModel";
  }
  constructor(params) {
    super(params);
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "responses", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "i", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 0
    });
    Object.defineProperty(this, "sleep", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "emitCustomEvent", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    const { responses, sleep, emitCustomEvent } = params;
    this.responses = responses;
    this.sleep = sleep;
    this.emitCustomEvent = emitCustomEvent ?? this.emitCustomEvent;
  }
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake-list";
  }
  async _generate(_messages, options, runManager) {
    var _a2;
    await this._sleepIfRequested();
    if (options == null ? void 0 : options.thrownErrorString) {
      throw new Error(options.thrownErrorString);
    }
    if (this.emitCustomEvent) {
      await (runManager == null ? void 0 : runManager.handleCustomEvent("some_test_event", {
        someval: true
      }));
    }
    if ((_a2 = options == null ? void 0 : options.stop) == null ? void 0 : _a2.length) {
      return {
        generations: [this._formatGeneration(options.stop[0])]
      };
    } else {
      const response = this._currentResponse();
      this._incrementResponse();
      return {
        generations: [this._formatGeneration(response)],
        llmOutput: {}
      };
    }
  }
  _formatGeneration(text) {
    return {
      message: new AIMessage(text),
      text
    };
  }
  async *_streamResponseChunks(_messages, options, runManager) {
    const response = this._currentResponse();
    this._incrementResponse();
    if (this.emitCustomEvent) {
      await (runManager == null ? void 0 : runManager.handleCustomEvent("some_test_event", {
        someval: true
      }));
    }
    for await (const text of response) {
      await this._sleepIfRequested();
      if (options == null ? void 0 : options.thrownErrorString) {
        throw new Error(options.thrownErrorString);
      }
      const chunk = this._createResponseChunk(text);
      yield chunk;
      void (runManager == null ? void 0 : runManager.handleLLMNewToken(text));
    }
  }
  async _sleepIfRequested() {
    if (this.sleep !== void 0) {
      await this._sleep();
    }
  }
  async _sleep() {
    return new Promise((resolve) => {
      setTimeout(() => resolve(), this.sleep);
    });
  }
  _createResponseChunk(text) {
    return new ChatGenerationChunk({
      message: new AIMessageChunk({ content: text }),
      text
    });
  }
  _currentResponse() {
    return this.responses[this.i];
  }
  _incrementResponse() {
    if (this.i < this.responses.length - 1) {
      this.i += 1;
    } else {
      this.i = 0;
    }
  }
  withStructuredOutput(_params, _config) {
    return RunnableLambda.from(async (input) => {
      var _a2, _b;
      const message = await this.invoke(input);
      if ((_b = (_a2 = message.tool_calls) == null ? void 0 : _a2[0]) == null ? void 0 : _b.args) {
        return message.tool_calls[0].args;
      }
      if (typeof message.content === "string") {
        return JSON.parse(message.content);
      }
      throw new Error("No structured output found");
    });
  }
};
var FakeChatMessageHistory = class extends BaseChatMessageHistory {
  constructor() {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "message", "fake"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  async getMessages() {
    return this.messages;
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async addUserMessage(message) {
    this.messages.push(new HumanMessage(message));
  }
  async addAIChatMessage(message) {
    this.messages.push(new AIMessage(message));
  }
  async clear() {
    this.messages = [];
  }
};
var FakeListChatMessageHistory = class extends BaseListChatMessageHistory {
  constructor() {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langchain_core", "message", "fake"]
    });
    Object.defineProperty(this, "messages", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async getMessages() {
    return this.messages;
  }
};
var FakeTracer = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "fake_tracer"
    });
    Object.defineProperty(this, "runs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  persistRun(run) {
    this.runs.push(run);
    return Promise.resolve();
  }
};
var FakeTool = class extends StructuredTool {
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "schema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.name = fields.name;
    this.description = fields.description;
    this.schema = fields.schema;
  }
  async _call(arg, _runManager) {
    return JSON.stringify(arg);
  }
};
var FakeEmbeddings = class extends Embeddings {
  constructor(params) {
    super(params ?? {});
  }
  /**
   * Generates fixed embeddings for a list of documents.
   * @param documents List of documents to generate embeddings for.
   * @returns A promise that resolves with a list of fixed embeddings for each document.
   */
  embedDocuments(documents) {
    return Promise.resolve(documents.map(() => [0.1, 0.2, 0.3, 0.4]));
  }
  /**
   * Generates a fixed embedding for a query.
   * @param _ The query to generate an embedding for.
   * @returns A promise that resolves with a fixed embedding for the query.
   */
  embedQuery(_) {
    return Promise.resolve([0.1, 0.2, 0.3, 0.4]);
  }
};
var SyntheticEmbeddings = class extends Embeddings {
  constructor(params) {
    super(params ?? {});
    Object.defineProperty(this, "vectorSize", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.vectorSize = (params == null ? void 0 : params.vectorSize) ?? 4;
  }
  /**
   * Generates synthetic embeddings for a list of documents.
   * @param documents List of documents to generate embeddings for.
   * @returns A promise that resolves with a list of synthetic embeddings for each document.
   */
  async embedDocuments(documents) {
    return Promise.all(documents.map((doc) => this.embedQuery(doc)));
  }
  /**
   * Generates a synthetic embedding for a document. The document is
   * converted into chunks, a numerical value is calculated for each chunk,
   * and an array of these values is returned as the embedding.
   * @param document The document to generate an embedding for.
   * @returns A promise that resolves with a synthetic embedding for the document.
   */
  async embedQuery(document) {
    let doc = document;
    doc = doc.toLowerCase().replaceAll(/[^a-z ]/g, "");
    const padMod = doc.length % this.vectorSize;
    const padGapSize = padMod === 0 ? 0 : this.vectorSize - padMod;
    const padSize = doc.length + padGapSize;
    doc = doc.padEnd(padSize, " ");
    const chunkSize = doc.length / this.vectorSize;
    const docChunk = [];
    for (let co = 0; co < doc.length; co += chunkSize) {
      docChunk.push(doc.slice(co, co + chunkSize));
    }
    const ret = docChunk.map((s) => {
      let sum = 0;
      for (let co = 0; co < s.length; co += 1) {
        sum += s === " " ? 0 : s.charCodeAt(co);
      }
      const ret2 = sum % 26 / 26;
      return ret2;
    });
    return ret;
  }
};
var SingleRunExtractor = class extends BaseTracer {
  constructor() {
    super();
    Object.defineProperty(this, "runPromiseResolver", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "runPromise", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "single_run_extractor"
    });
    this.runPromise = new Promise((extract) => {
      this.runPromiseResolver = extract;
    });
  }
  async persistRun(run) {
    this.runPromiseResolver(run);
  }
  async extract() {
    return this.runPromise;
  }
};
var FakeVectorStore = class _FakeVectorStore extends VectorStore {
  _vectorstoreType() {
    return "memory";
  }
  constructor(embeddings, { similarity, ...rest } = {}) {
    super(embeddings, rest);
    Object.defineProperty(this, "memoryVectors", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "similarity", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.similarity = similarity ?? cosine;
  }
  /**
   * Method to add documents to the memory vector store. It extracts the
   * text from each document, generates embeddings for them, and adds the
   * resulting vectors to the store.
   * @param documents Array of `Document` instances to be added to the store.
   * @returns Promise that resolves when all documents have been added.
   */
  async addDocuments(documents) {
    const texts = documents.map(({ pageContent }) => pageContent);
    return this.addVectors(await this.embeddings.embedDocuments(texts), documents);
  }
  /**
   * Method to add vectors to the memory vector store. It creates
   * `MemoryVector` instances for each vector and document pair and adds
   * them to the store.
   * @param vectors Array of vectors to be added to the store.
   * @param documents Array of `Document` instances corresponding to the vectors.
   * @returns Promise that resolves when all vectors have been added.
   */
  async addVectors(vectors, documents) {
    const memoryVectors = vectors.map((embedding, idx) => ({
      content: documents[idx].pageContent,
      embedding,
      metadata: documents[idx].metadata
    }));
    this.memoryVectors = this.memoryVectors.concat(memoryVectors);
  }
  /**
   * Method to perform a similarity search in the memory vector store. It
   * calculates the similarity between the query vector and each vector in
   * the store, sorts the results by similarity, and returns the top `k`
   * results along with their scores.
   * @param query Query vector to compare against the vectors in the store.
   * @param k Number of top results to return.
   * @param filter Optional filter function to apply to the vectors before performing the search.
   * @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.
   */
  async similaritySearchVectorWithScore(query, k, filter) {
    const filterFunction = (memoryVector) => {
      if (!filter) {
        return true;
      }
      const doc = new Document({
        metadata: memoryVector.metadata,
        pageContent: memoryVector.content
      });
      return filter(doc);
    };
    const filteredMemoryVectors = this.memoryVectors.filter(filterFunction);
    const searches = filteredMemoryVectors.map((vector, index) => ({
      similarity: this.similarity(query, vector.embedding),
      index
    })).sort((a, b) => a.similarity > b.similarity ? -1 : 0).slice(0, k);
    const result = searches.map((search) => [
      new Document({
        metadata: filteredMemoryVectors[search.index].metadata,
        pageContent: filteredMemoryVectors[search.index].content
      }),
      search.similarity
    ]);
    return result;
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an array of
   * texts. It creates a `Document` for each text and metadata pair, and
   * adds them to the store.
   * @param texts Array of texts to be added to the store.
   * @param metadatas Array or single object of metadata corresponding to the texts.
   * @param embeddings `Embeddings` instance used to generate embeddings for the texts.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromTexts(texts, metadatas, embeddings, dbConfig) {
    const docs = [];
    for (let i = 0; i < texts.length; i += 1) {
      const metadata = Array.isArray(metadatas) ? metadatas[i] : metadatas;
      const newDoc = new Document({
        pageContent: texts[i],
        metadata
      });
      docs.push(newDoc);
    }
    return _FakeVectorStore.fromDocuments(docs, embeddings, dbConfig);
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an array of
   * `Document` instances. It adds the documents to the store.
   * @param docs Array of `Document` instances to be added to the store.
   * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromDocuments(docs, embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    await instance.addDocuments(docs);
    return instance;
  }
  /**
   * Static method to create a `FakeVectorStore` instance from an existing
   * index. It creates a new `FakeVectorStore` instance without adding any
   * documents or vectors.
   * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
   * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
   * @returns Promise that resolves with a new `FakeVectorStore` instance.
   */
  static async fromExistingIndex(embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    return instance;
  }
};

// node_modules/@langchain/core/dist/utils/types/index.js
var types_exports = {};
__export(types_exports, {
  extendInteropZodObject: () => extendInteropZodObject,
  getInteropZodDefaultGetter: () => getInteropZodDefaultGetter,
  getInteropZodObjectShape: () => getInteropZodObjectShape,
  getSchemaDescription: () => getSchemaDescription,
  interopParse: () => interopParse,
  interopParseAsync: () => interopParseAsync,
  interopSafeParse: () => interopSafeParse,
  interopSafeParseAsync: () => interopSafeParseAsync,
  interopZodObjectPartial: () => interopZodObjectPartial,
  interopZodObjectPassthrough: () => interopZodObjectPassthrough,
  interopZodObjectStrict: () => interopZodObjectStrict,
  interopZodTransformInputSchema: () => interopZodTransformInputSchema,
  isInteropZodObject: () => isInteropZodObject,
  isInteropZodSchema: () => isInteropZodSchema,
  isShapelessZodSchema: () => isShapelessZodSchema,
  isSimpleStringZodSchema: () => isSimpleStringZodSchema,
  isZodArrayV4: () => isZodArrayV4,
  isZodObjectV3: () => isZodObjectV3,
  isZodObjectV4: () => isZodObjectV4,
  isZodSchema: () => isZodSchema,
  isZodSchemaV3: () => isZodSchemaV3,
  isZodSchemaV4: () => isZodSchemaV4
});

// node_modules/@langchain/core/dist/load/index.js
function combineAliasesAndInvert(constructor) {
  const aliases = {};
  for (let current = constructor; current && current.prototype; current = Object.getPrototypeOf(current)) {
    Object.assign(aliases, Reflect.get(current.prototype, "lc_aliases"));
  }
  return Object.entries(aliases).reduce((acc, [key, value]) => {
    acc[value] = key;
    return acc;
  }, {});
}
async function reviver(value) {
  const { optionalImportsMap = {}, optionalImportEntrypoints: optionalImportEntrypoints2 = [], importMap = {}, secretsMap = {}, path = ["$"] } = this;
  const pathStr = path.join(".");
  if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && value.lc === 1 && value.type === "secret") {
    const serialized = value;
    const [key] = serialized.id;
    if (key in secretsMap) {
      return secretsMap[key];
    } else {
      const secretValueInEnv = getEnvironmentVariable(key);
      if (secretValueInEnv) {
        return secretValueInEnv;
      } else {
        throw new Error(`Missing key "${key}" for ${pathStr} in load(secretsMap={})`);
      }
    }
  } else if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && value.lc === 1 && value.type === "not_implemented") {
    const serialized = value;
    const str = JSON.stringify(serialized);
    throw new Error(`Trying to load an object that doesn't implement serialization: ${pathStr} -> ${str}`);
  } else if (typeof value === "object" && value !== null && !Array.isArray(value) && "lc" in value && "type" in value && "id" in value && "kwargs" in value && value.lc === 1) {
    const serialized = value;
    const str = JSON.stringify(serialized);
    const [name, ...namespaceReverse] = serialized.id.slice().reverse();
    const namespace = namespaceReverse.reverse();
    const importMaps = { langchain_core: import_map_exports, langchain: importMap };
    let module = null;
    const optionalImportNamespaceAliases = [namespace.join("/")];
    if (namespace[0] === "langchain_community") {
      optionalImportNamespaceAliases.push(["langchain", ...namespace.slice(1)].join("/"));
    }
    const matchingNamespaceAlias = optionalImportNamespaceAliases.find((alias) => alias in optionalImportsMap);
    if (optionalImportEntrypoints.concat(optionalImportEntrypoints2).includes(namespace.join("/")) || matchingNamespaceAlias) {
      if (matchingNamespaceAlias !== void 0) {
        module = await optionalImportsMap[matchingNamespaceAlias];
      } else {
        throw new Error(`Missing key "${namespace.join("/")}" for ${pathStr} in load(optionalImportsMap={})`);
      }
    } else {
      let finalImportMap;
      if (namespace[0] === "langchain" || namespace[0] === "langchain_core") {
        finalImportMap = importMaps[namespace[0]];
        namespace.shift();
      } else {
        throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      }
      if (namespace.length === 0) {
        throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      }
      let importMapKey;
      do {
        importMapKey = namespace.join("__");
        if (importMapKey in finalImportMap) {
          break;
        } else {
          namespace.pop();
        }
      } while (namespace.length > 0);
      if (importMapKey in finalImportMap) {
        module = finalImportMap[importMapKey];
      }
    }
    if (typeof module !== "object" || module === null) {
      throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
    }
    const builder = (
      // look for a named export with the same name as the class
      module[name] ?? // look for an export with a lc_name property matching the class name
      // this is necessary for classes that are minified
      Object.values(module).find((v) => typeof v === "function" && get_lc_unique_name(v) === name)
    );
    if (typeof builder !== "function") {
      throw new Error(`Invalid identifer: ${pathStr} -> ${str}`);
    }
    const kwargs = await reviver.call({ ...this, path: [...path, "kwargs"] }, serialized.kwargs);
    if (serialized.type === "constructor") {
      const instance = new builder(mapKeys(kwargs, keyFromJson, combineAliasesAndInvert(builder)));
      Object.defineProperty(instance.constructor, "name", { value: name });
      return instance;
    } else {
      throw new Error(`Invalid type: ${pathStr} -> ${str}`);
    }
  } else if (typeof value === "object" && value !== null) {
    if (Array.isArray(value)) {
      return Promise.all(value.map((v, i) => reviver.call({ ...this, path: [...path, `${i}`] }, v)));
    } else {
      return Object.fromEntries(await Promise.all(Object.entries(value).map(async ([key, value2]) => [
        key,
        await reviver.call({ ...this, path: [...path, key] }, value2)
      ])));
    }
  }
  return value;
}
async function load(text, mappings) {
  const json = JSON.parse(text);
  return reviver.call({ ...mappings }, json);
}

// node_modules/@langchain/langgraph-checkpoint/dist/serde/utils/fast-safe-stringify/index.js
var LIMIT_REPLACE_NODE = "[...]";
var CIRCULAR_REPLACE_NODE = "[Circular]";
var arr = [];
var replacerStack = [];
function defaultOptions() {
  return {
    depthLimit: Number.MAX_SAFE_INTEGER,
    edgesLimit: Number.MAX_SAFE_INTEGER
  };
}
function stringify(obj, replacer, spacer, options) {
  if (typeof options === "undefined") {
    options = defaultOptions();
  }
  decirc(obj, "", 0, [], void 0, 0, options);
  var res;
  try {
    if (replacerStack.length === 0) {
      res = JSON.stringify(obj, replacer, spacer);
    } else {
      res = JSON.stringify(obj, replaceGetterValues(replacer), spacer);
    }
  } catch (_) {
    return JSON.stringify("[unable to serialize, circular reference is too complex to analyze]");
  } finally {
    while (arr.length !== 0) {
      var part = arr.pop();
      if (part.length === 4) {
        Object.defineProperty(part[0], part[1], part[3]);
      } else {
        part[0][part[1]] = part[2];
      }
    }
  }
  return res;
}
function setReplace(replace, val, k, parent) {
  var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k);
  if (propertyDescriptor.get !== void 0) {
    if (propertyDescriptor.configurable) {
      Object.defineProperty(parent, k, { value: replace });
      arr.push([parent, k, val, propertyDescriptor]);
    } else {
      replacerStack.push([val, k, replace]);
    }
  } else {
    parent[k] = replace;
    arr.push([parent, k, val]);
  }
}
function decirc(val, k, edgeIndex, stack, parent, depth, options) {
  depth += 1;
  var i;
  if (typeof val === "object" && val !== null) {
    for (i = 0; i < stack.length; i++) {
      if (stack[i] === val) {
        setReplace(CIRCULAR_REPLACE_NODE, val, k, parent);
        return;
      }
    }
    if (typeof options.depthLimit !== "undefined" && depth > options.depthLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k, parent);
      return;
    }
    if (typeof options.edgesLimit !== "undefined" && edgeIndex + 1 > options.edgesLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k, parent);
      return;
    }
    stack.push(val);
    if (Array.isArray(val)) {
      for (i = 0; i < val.length; i++) {
        decirc(val[i], i, i, stack, val, depth, options);
      }
    } else {
      var keys = Object.keys(val);
      for (i = 0; i < keys.length; i++) {
        var key = keys[i];
        decirc(val[key], key, i, stack, val, depth, options);
      }
    }
    stack.pop();
  }
}
function replaceGetterValues(replacer) {
  replacer = typeof replacer !== "undefined" ? replacer : function(k, v) {
    return v;
  };
  return function(key, val) {
    if (replacerStack.length > 0) {
      for (var i = 0; i < replacerStack.length; i++) {
        var part = replacerStack[i];
        if (part[1] === key && part[0] === val) {
          val = part[2];
          replacerStack.splice(i, 1);
          break;
        }
      }
    }
    return replacer.call(this, key, val);
  };
}

// node_modules/@langchain/langgraph-checkpoint/dist/serde/jsonplus.js
function isLangChainSerializedObject(value) {
  return value !== null && value.lc === 1 && value.type === "constructor" && Array.isArray(value.id);
}
async function _reviver(value) {
  if (value && typeof value === "object") {
    if (Array.isArray(value)) {
      const revivedArray = await Promise.all(value.map((item) => _reviver(item)));
      return revivedArray;
    } else {
      const revivedObj = {};
      for (const [k, v] of Object.entries(value)) {
        revivedObj[k] = await _reviver(v);
      }
      if (revivedObj.lc === 2 && revivedObj.type === "undefined") {
        return void 0;
      } else if (revivedObj.lc === 2 && revivedObj.type === "constructor" && Array.isArray(revivedObj.id)) {
        try {
          const constructorName = revivedObj.id[revivedObj.id.length - 1];
          let constructor;
          switch (constructorName) {
            case "Set":
              constructor = Set;
              break;
            case "Map":
              constructor = Map;
              break;
            case "RegExp":
              constructor = RegExp;
              break;
            case "Error":
              constructor = Error;
              break;
            default:
              return revivedObj;
          }
          if (revivedObj.method) {
            return constructor[revivedObj.method](...revivedObj.args || []);
          } else {
            return new constructor(...revivedObj.args || []);
          }
        } catch (error) {
          return revivedObj;
        }
      } else if (isLangChainSerializedObject(revivedObj)) {
        return load(JSON.stringify(revivedObj));
      }
      return revivedObj;
    }
  }
  return value;
}
function _encodeConstructorArgs(constructor, method, args, kwargs) {
  return {
    lc: 2,
    type: "constructor",
    id: [constructor.name],
    method: method ?? null,
    args: args ?? [],
    kwargs: kwargs ?? {}
  };
}
function _default(obj) {
  if (obj === void 0) {
    return {
      lc: 2,
      type: "undefined"
    };
  } else if (obj instanceof Set || obj instanceof Map) {
    return _encodeConstructorArgs(obj.constructor, void 0, [
      Array.from(obj)
    ]);
  } else if (obj instanceof RegExp) {
    return _encodeConstructorArgs(RegExp, void 0, [obj.source, obj.flags]);
  } else if (obj instanceof Error) {
    return _encodeConstructorArgs(obj.constructor, void 0, [obj.message]);
  } else if ((obj == null ? void 0 : obj.lg_name) === "Send") {
    return {
      node: obj.node,
      args: obj.args
    };
  } else {
    return obj;
  }
}
var JsonPlusSerializer = class {
  _dumps(obj) {
    const encoder = new TextEncoder();
    return encoder.encode(stringify(obj, (_, value) => {
      return _default(value);
    }));
  }
  async dumpsTyped(obj) {
    if (obj instanceof Uint8Array) {
      return ["bytes", obj];
    } else {
      return ["json", this._dumps(obj)];
    }
  }
  async _loads(data) {
    const parsed = JSON.parse(data);
    return _reviver(parsed);
  }
  async loadsTyped(type, data) {
    if (type === "bytes") {
      return typeof data === "string" ? new TextEncoder().encode(data) : data;
    } else if (type === "json") {
      return this._loads(typeof data === "string" ? data : new TextDecoder().decode(data));
    } else {
      throw new Error(`Unknown serialization type: ${type}`);
    }
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/base.js
function deepCopy(obj) {
  if (typeof obj !== "object" || obj === null) {
    return obj;
  }
  const newObj = Array.isArray(obj) ? [] : {};
  for (const key in obj) {
    if (Object.prototype.hasOwnProperty.call(obj, key)) {
      newObj[key] = deepCopy(obj[key]);
    }
  }
  return newObj;
}
function emptyCheckpoint() {
  return {
    v: 4,
    id: uuid6(-2),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: {},
    channel_versions: {},
    versions_seen: {}
  };
}
function copyCheckpoint(checkpoint) {
  return {
    v: checkpoint.v,
    id: checkpoint.id,
    ts: checkpoint.ts,
    channel_values: { ...checkpoint.channel_values },
    channel_versions: { ...checkpoint.channel_versions },
    versions_seen: deepCopy(checkpoint.versions_seen)
  };
}
var BaseCheckpointSaver = class {
  constructor(serde) {
    Object.defineProperty(this, "serde", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new JsonPlusSerializer()
    });
    this.serde = serde || this.serde;
  }
  async get(config) {
    const value = await this.getTuple(config);
    return value ? value.checkpoint : void 0;
  }
  /**
   * Generate the next version ID for a channel.
   *
   * Default is to use integer versions, incrementing by 1. If you override, you can use str/int/float versions,
   * as long as they are monotonically increasing.
   */
  getNextVersion(current) {
    if (typeof current === "string") {
      throw new Error("Please override this method to use string versions.");
    }
    return current !== void 0 && typeof current === "number" ? current + 1 : 1;
  }
};
function compareChannelVersions(a, b) {
  if (typeof a === "number" && typeof b === "number") {
    return Math.sign(a - b);
  }
  return String(a).localeCompare(String(b));
}
function maxChannelVersion(...versions) {
  return versions.reduce((max, version, idx) => {
    if (idx === 0)
      return version;
    return compareChannelVersions(max, version) >= 0 ? max : version;
  });
}
var WRITES_IDX_MAP = {
  [ERROR2]: -1,
  [SCHEDULED]: -2,
  [INTERRUPT]: -3,
  [RESUME]: -4
};
function getCheckpointId(config) {
  var _a2, _b;
  return ((_a2 = config.configurable) == null ? void 0 : _a2.checkpoint_id) || ((_b = config.configurable) == null ? void 0 : _b.thread_ts) || "";
}

// node_modules/@langchain/langgraph-checkpoint/dist/memory.js
function _generateKey(threadId, checkpointNamespace, checkpointId) {
  return JSON.stringify([threadId, checkpointNamespace, checkpointId]);
}
function _parseKey(key) {
  const [threadId, checkpointNamespace, checkpointId] = JSON.parse(key);
  return { threadId, checkpointNamespace, checkpointId };
}
var MemorySaver = class extends BaseCheckpointSaver {
  constructor(serde) {
    super(serde);
    Object.defineProperty(this, "storage", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "writes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
  }
  async _migratePendingSends(mutableCheckpoint, threadId, checkpointNs, parentCheckpointId) {
    const deseriablizableCheckpoint = mutableCheckpoint;
    const parentKey = _generateKey(threadId, checkpointNs, parentCheckpointId);
    const pendingSends = await Promise.all(Object.values(this.writes[parentKey] ?? {}).filter(([_taskId, channel]) => channel === TASKS).map(async ([_taskId, _channel, writes]) => await this.serde.loadsTyped("json", writes)));
    deseriablizableCheckpoint.channel_values ?? (deseriablizableCheckpoint.channel_values = {});
    deseriablizableCheckpoint.channel_values[TASKS] = pendingSends;
    deseriablizableCheckpoint.channel_versions ?? (deseriablizableCheckpoint.channel_versions = {});
    deseriablizableCheckpoint.channel_versions[TASKS] = Object.keys(deseriablizableCheckpoint.channel_versions).length > 0 ? maxChannelVersion(...Object.values(deseriablizableCheckpoint.channel_versions)) : this.getNextVersion(void 0);
  }
  async getTuple(config) {
    var _a2, _b, _c, _d, _e;
    const thread_id = (_a2 = config.configurable) == null ? void 0 : _a2.thread_id;
    const checkpoint_ns = ((_b = config.configurable) == null ? void 0 : _b.checkpoint_ns) ?? "";
    let checkpoint_id = getCheckpointId(config);
    if (checkpoint_id) {
      const saved = (_d = (_c = this.storage[thread_id]) == null ? void 0 : _c[checkpoint_ns]) == null ? void 0 : _d[checkpoint_id];
      if (saved !== void 0) {
        const [checkpoint, metadata, parentCheckpointId] = saved;
        const key = _generateKey(thread_id, checkpoint_ns, checkpoint_id);
        const deserializedCheckpoint = await this.serde.loadsTyped("json", checkpoint);
        if (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) {
          await this._migratePendingSends(deserializedCheckpoint, thread_id, checkpoint_ns, parentCheckpointId);
        }
        const pendingWrites = await Promise.all(Object.values(this.writes[key] || {}).map(async ([taskId, channel, value]) => {
          return [
            taskId,
            channel,
            await this.serde.loadsTyped("json", value)
          ];
        }));
        const checkpointTuple = {
          config,
          checkpoint: deserializedCheckpoint,
          metadata: await this.serde.loadsTyped("json", metadata),
          pendingWrites
        };
        if (parentCheckpointId !== void 0) {
          checkpointTuple.parentConfig = {
            configurable: {
              thread_id,
              checkpoint_ns,
              checkpoint_id: parentCheckpointId
            }
          };
        }
        return checkpointTuple;
      }
    } else {
      const checkpoints = (_e = this.storage[thread_id]) == null ? void 0 : _e[checkpoint_ns];
      if (checkpoints !== void 0) {
        checkpoint_id = Object.keys(checkpoints).sort((a, b) => b.localeCompare(a))[0];
        const saved = checkpoints[checkpoint_id];
        const [checkpoint, metadata, parentCheckpointId] = saved;
        const key = _generateKey(thread_id, checkpoint_ns, checkpoint_id);
        const deserializedCheckpoint = await this.serde.loadsTyped("json", checkpoint);
        if (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) {
          await this._migratePendingSends(deserializedCheckpoint, thread_id, checkpoint_ns, parentCheckpointId);
        }
        const pendingWrites = await Promise.all(Object.values(this.writes[key] || {}).map(async ([taskId, channel, value]) => {
          return [
            taskId,
            channel,
            await this.serde.loadsTyped("json", value)
          ];
        }));
        const checkpointTuple = {
          config: {
            configurable: {
              thread_id,
              checkpoint_id,
              checkpoint_ns
            }
          },
          checkpoint: deserializedCheckpoint,
          metadata: await this.serde.loadsTyped("json", metadata),
          pendingWrites
        };
        if (parentCheckpointId !== void 0) {
          checkpointTuple.parentConfig = {
            configurable: {
              thread_id,
              checkpoint_ns,
              checkpoint_id: parentCheckpointId
            }
          };
        }
        return checkpointTuple;
      }
    }
    return void 0;
  }
  async *list(config, options) {
    var _a2, _b, _c, _d, _e, _f;
    let { before, limit, filter } = options ?? {};
    const threadIds = ((_a2 = config.configurable) == null ? void 0 : _a2.thread_id) ? [(_b = config.configurable) == null ? void 0 : _b.thread_id] : Object.keys(this.storage);
    const configCheckpointNamespace = (_c = config.configurable) == null ? void 0 : _c.checkpoint_ns;
    const configCheckpointId = (_d = config.configurable) == null ? void 0 : _d.checkpoint_id;
    for (const threadId of threadIds) {
      for (const checkpointNamespace of Object.keys(this.storage[threadId] ?? {})) {
        if (configCheckpointNamespace !== void 0 && checkpointNamespace !== configCheckpointNamespace) {
          continue;
        }
        const checkpoints = ((_e = this.storage[threadId]) == null ? void 0 : _e[checkpointNamespace]) ?? {};
        const sortedCheckpoints = Object.entries(checkpoints).sort((a, b) => b[0].localeCompare(a[0]));
        for (const [checkpointId, [checkpoint, metadataStr, parentCheckpointId]] of sortedCheckpoints) {
          if (configCheckpointId && checkpointId !== configCheckpointId) {
            continue;
          }
          if (before && ((_f = before.configurable) == null ? void 0 : _f.checkpoint_id) && checkpointId >= before.configurable.checkpoint_id) {
            continue;
          }
          const metadata = await this.serde.loadsTyped("json", metadataStr);
          if (filter && !Object.entries(filter).every(([key2, value]) => metadata[key2] === value)) {
            continue;
          }
          if (limit !== void 0) {
            if (limit <= 0)
              break;
            limit -= 1;
          }
          const key = _generateKey(threadId, checkpointNamespace, checkpointId);
          const writes = Object.values(this.writes[key] || {});
          const pendingWrites = await Promise.all(writes.map(async ([taskId, channel, value]) => {
            return [
              taskId,
              channel,
              await this.serde.loadsTyped("json", value)
            ];
          }));
          const deserializedCheckpoint = await this.serde.loadsTyped("json", checkpoint);
          if (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) {
            await this._migratePendingSends(deserializedCheckpoint, threadId, checkpointNamespace, parentCheckpointId);
          }
          const checkpointTuple = {
            config: {
              configurable: {
                thread_id: threadId,
                checkpoint_ns: checkpointNamespace,
                checkpoint_id: checkpointId
              }
            },
            checkpoint: deserializedCheckpoint,
            metadata,
            pendingWrites
          };
          if (parentCheckpointId !== void 0) {
            checkpointTuple.parentConfig = {
              configurable: {
                thread_id: threadId,
                checkpoint_ns: checkpointNamespace,
                checkpoint_id: parentCheckpointId
              }
            };
          }
          yield checkpointTuple;
        }
      }
    }
  }
  async put(config, checkpoint, metadata) {
    var _a2, _b, _c;
    const preparedCheckpoint = copyCheckpoint(checkpoint);
    const threadId = (_a2 = config.configurable) == null ? void 0 : _a2.thread_id;
    const checkpointNamespace = ((_b = config.configurable) == null ? void 0 : _b.checkpoint_ns) ?? "";
    if (threadId === void 0) {
      throw new Error(`Failed to put checkpoint. The passed RunnableConfig is missing a required "thread_id" field in its "configurable" property.`);
    }
    if (!this.storage[threadId]) {
      this.storage[threadId] = {};
    }
    if (!this.storage[threadId][checkpointNamespace]) {
      this.storage[threadId][checkpointNamespace] = {};
    }
    const [[, serializedCheckpoint], [, serializedMetadata]] = await Promise.all([
      this.serde.dumpsTyped(preparedCheckpoint),
      this.serde.dumpsTyped(metadata)
    ]);
    this.storage[threadId][checkpointNamespace][checkpoint.id] = [
      serializedCheckpoint,
      serializedMetadata,
      (_c = config.configurable) == null ? void 0 : _c.checkpoint_id
      // parent
    ];
    return {
      configurable: {
        thread_id: threadId,
        checkpoint_ns: checkpointNamespace,
        checkpoint_id: checkpoint.id
      }
    };
  }
  async putWrites(config, writes, taskId) {
    var _a2, _b, _c;
    const threadId = (_a2 = config.configurable) == null ? void 0 : _a2.thread_id;
    const checkpointNamespace = (_b = config.configurable) == null ? void 0 : _b.checkpoint_ns;
    const checkpointId = (_c = config.configurable) == null ? void 0 : _c.checkpoint_id;
    if (threadId === void 0) {
      throw new Error(`Failed to put writes. The passed RunnableConfig is missing a required "thread_id" field in its "configurable" property`);
    }
    if (checkpointId === void 0) {
      throw new Error(`Failed to put writes. The passed RunnableConfig is missing a required "checkpoint_id" field in its "configurable" property.`);
    }
    const outerKey = _generateKey(threadId, checkpointNamespace, checkpointId);
    const outerWrites_ = this.writes[outerKey];
    if (this.writes[outerKey] === void 0) {
      this.writes[outerKey] = {};
    }
    await Promise.all(writes.map(async ([channel, value], idx) => {
      const [, serializedValue] = await this.serde.dumpsTyped(value);
      const innerKey = [
        taskId,
        WRITES_IDX_MAP[channel] || idx
      ];
      const innerKeyStr = `${innerKey[0]},${innerKey[1]}`;
      if (innerKey[1] >= 0 && outerWrites_ && innerKeyStr in outerWrites_) {
        return;
      }
      this.writes[outerKey][innerKeyStr] = [taskId, channel, serializedValue];
    }));
  }
  async deleteThread(threadId) {
    delete this.storage[threadId];
    for (const key of Object.keys(this.writes)) {
      if (_parseKey(key).threadId === threadId)
        delete this.writes[key];
    }
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/store/base.js
var InvalidNamespaceError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "InvalidNamespaceError";
  }
};
function validateNamespace(namespace) {
  if (namespace.length === 0) {
    throw new InvalidNamespaceError("Namespace cannot be empty.");
  }
  for (const label of namespace) {
    if (typeof label !== "string") {
      throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels must be strings, but got ${typeof label}.`);
    }
    if (label.includes(".")) {
      throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels cannot contain periods ('.').`);
    }
    if (label === "") {
      throw new InvalidNamespaceError(`Namespace labels cannot be empty strings. Got ${label} in ${namespace}`);
    }
  }
  if (namespace[0] === "langgraph") {
    throw new InvalidNamespaceError(`Root label for namespace cannot be "langgraph". Got: ${namespace}`);
  }
}
var BaseStore2 = class {
  /**
   * Retrieve a single item by its namespace and key.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   * @returns Promise resolving to the item or null if not found
   */
  async get(namespace, key) {
    return (await this.batch([{ namespace, key }]))[0];
  }
  /**
   * Search for items within a namespace prefix.
   * Supports both metadata filtering and vector similarity search.
   *
   * @param namespacePrefix Hierarchical path prefix to search within
   * @param options Search options for filtering and pagination
   * @returns Promise resolving to list of matching items with relevance scores
   *
   * @example
   * // Search with filters
   * await store.search(["documents"], {
   *   filter: { type: "report", status: "active" },
   *   limit: 5,
   *   offset: 10
   * });
   *
   * // Vector similarity search
   * await store.search(["users", "content"], {
   *   query: "technical documentation about APIs",
   *   limit: 20
   * });
   */
  async search(namespacePrefix, options = {}) {
    const { filter, limit = 10, offset = 0, query } = options;
    return (await this.batch([
      {
        namespacePrefix,
        filter,
        limit,
        offset,
        query
      }
    ]))[0];
  }
  /**
   * Store or update an item.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   * @param value Object containing the item's data
   * @param index Optional indexing configuration
   *
   * @example
   * // Simple storage
   * await store.put(["docs"], "report", { title: "Annual Report" });
   *
   * // With specific field indexing
   * await store.put(
   *   ["docs"],
   *   "report",
   *   {
   *     title: "Q4 Report",
   *     chapters: [{ content: "..." }, { content: "..." }]
   *   },
   *   ["title", "chapters[*].content"]
   * );
   */
  async put(namespace, key, value, index) {
    validateNamespace(namespace);
    await this.batch([{ namespace, key, value, index }]);
  }
  /**
   * Delete an item from the store.
   *
   * @param namespace Hierarchical path for the item
   * @param key Unique identifier within the namespace
   */
  async delete(namespace, key) {
    await this.batch([{ namespace, key, value: null }]);
  }
  /**
   * List and filter namespaces in the store.
   * Used to explore data organization and navigate the namespace hierarchy.
   *
   * @param options Options for listing namespaces
   * @returns Promise resolving to list of namespace paths
   *
   * @example
   * // List all namespaces under "documents"
   * await store.listNamespaces({
   *   prefix: ["documents"],
   *   maxDepth: 2
   * });
   *
   * // List namespaces ending with "v1"
   * await store.listNamespaces({
   *   suffix: ["v1"],
   *   limit: 50
   * });
   */
  async listNamespaces(options = {}) {
    const { prefix, suffix, maxDepth, limit = 100, offset = 0 } = options;
    const matchConditions = [];
    if (prefix) {
      matchConditions.push({ matchType: "prefix", path: prefix });
    }
    if (suffix) {
      matchConditions.push({ matchType: "suffix", path: suffix });
    }
    return (await this.batch([
      {
        matchConditions: matchConditions.length ? matchConditions : void 0,
        maxDepth,
        limit,
        offset
      }
    ]))[0];
  }
  /**
   * Start the store. Override if initialization is needed.
   */
  start() {
  }
  /**
   * Stop the store. Override if cleanup is needed.
   */
  stop() {
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/store/batch.js
var extractStore = (input) => {
  if ("lg_name" in input && input.lg_name === "AsyncBatchedStore") {
    return input.store;
  }
  return input;
};
var AsyncBatchedStore = class extends BaseStore2 {
  constructor(store) {
    super();
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "AsyncBatchedStore"
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "queue", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "nextKey", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: 0
    });
    Object.defineProperty(this, "running", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "processingTask", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: null
    });
    this.store = extractStore(store);
  }
  get isRunning() {
    return this.running;
  }
  /**
   * @ignore
   * Batch is not implemented here as we're only extending `BaseStore`
   * to allow it to be passed where `BaseStore` is expected, and implement
   * the convenience methods (get, search, put, delete).
   */
  async batch(_operations) {
    throw new Error("The `batch` method is not implemented on `AsyncBatchedStore`.\n Instead, it calls the `batch` method on the wrapped store.\n If you are seeing this error, something is wrong.");
  }
  async get(namespace, key) {
    return this.enqueueOperation({ namespace, key });
  }
  async search(namespacePrefix, options) {
    const { filter, limit = 10, offset = 0, query } = options || {};
    return this.enqueueOperation({
      namespacePrefix,
      filter,
      limit,
      offset,
      query
    });
  }
  async put(namespace, key, value) {
    return this.enqueueOperation({ namespace, key, value });
  }
  async delete(namespace, key) {
    return this.enqueueOperation({
      namespace,
      key,
      value: null
    });
  }
  start() {
    if (!this.running) {
      this.running = true;
      this.processingTask = this.processBatchQueue();
    }
  }
  async stop() {
    this.running = false;
    if (this.processingTask) {
      await this.processingTask;
    }
  }
  enqueueOperation(operation) {
    return new Promise((resolve, reject) => {
      const key = this.nextKey;
      this.nextKey += 1;
      this.queue.set(key, { operation, resolve, reject });
    });
  }
  async processBatchQueue() {
    while (this.running) {
      await new Promise((resolve) => {
        setTimeout(resolve, 0);
      });
      if (this.queue.size === 0)
        continue;
      const batch = new Map(this.queue);
      this.queue.clear();
      try {
        const operations = Array.from(batch.values()).map(({ operation }) => operation);
        const results = await this.store.batch(operations);
        batch.forEach(({ resolve }, key) => {
          const index = Array.from(batch.keys()).indexOf(key);
          resolve(results[index]);
        });
      } catch (e) {
        batch.forEach(({ reject }) => {
          reject(e);
        });
      }
    }
  }
  // AsyncBatchedStore is internal and gets passed as args into traced tasks
  // some BaseStores contain circular references so just serialize without it
  // as this causes warnings when tracing with LangSmith.
  toJSON() {
    return {
      queue: this.queue,
      nextKey: this.nextKey,
      running: this.running,
      store: "[LangGraphStore]"
    };
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/store/utils.js
function tokenizePath(path) {
  if (!path) {
    return [];
  }
  const tokens = [];
  let current = [];
  let i = 0;
  while (i < path.length) {
    const char = path[i];
    if (char === "[") {
      if (current.length) {
        tokens.push(current.join(""));
        current = [];
      }
      let bracketCount = 1;
      const indexChars = ["["];
      i += 1;
      while (i < path.length && bracketCount > 0) {
        if (path[i] === "[") {
          bracketCount += 1;
        } else if (path[i] === "]") {
          bracketCount -= 1;
        }
        indexChars.push(path[i]);
        i += 1;
      }
      tokens.push(indexChars.join(""));
      continue;
    } else if (char === "{") {
      if (current.length) {
        tokens.push(current.join(""));
        current = [];
      }
      let braceCount = 1;
      const fieldChars = ["{"];
      i += 1;
      while (i < path.length && braceCount > 0) {
        if (path[i] === "{") {
          braceCount += 1;
        } else if (path[i] === "}") {
          braceCount -= 1;
        }
        fieldChars.push(path[i]);
        i += 1;
      }
      tokens.push(fieldChars.join(""));
      continue;
    } else if (char === ".") {
      if (current.length) {
        tokens.push(current.join(""));
        current = [];
      }
    } else {
      current.push(char);
    }
    i += 1;
  }
  if (current.length) {
    tokens.push(current.join(""));
  }
  return tokens;
}
function isFilterOperators(obj) {
  return typeof obj === "object" && obj !== null && Object.keys(obj).every((key) => key === "$eq" || key === "$ne" || key === "$gt" || key === "$gte" || key === "$lt" || key === "$lte" || key === "$in" || key === "$nin");
}
function compareValues(itemValue, filterValue) {
  if (isFilterOperators(filterValue)) {
    const operators = Object.keys(filterValue).filter((k) => k.startsWith("$"));
    return operators.every((op) => {
      const value = filterValue[op];
      switch (op) {
        case "$eq":
          return itemValue === value;
        case "$ne":
          return itemValue !== value;
        case "$gt":
          return Number(itemValue) > Number(value);
        case "$gte":
          return Number(itemValue) >= Number(value);
        case "$lt":
          return Number(itemValue) < Number(value);
        case "$lte":
          return Number(itemValue) <= Number(value);
        case "$in":
          return Array.isArray(value) ? value.includes(itemValue) : false;
        case "$nin":
          return Array.isArray(value) ? !value.includes(itemValue) : true;
        default:
          return false;
      }
    });
  }
  return itemValue === filterValue;
}
function getTextAtPath(obj, path) {
  if (!path || path === "$") {
    return [JSON.stringify(obj, null, 2)];
  }
  const tokens = Array.isArray(path) ? path : tokenizePath(path);
  function extractFromObj(obj2, tokens2, pos) {
    if (pos >= tokens2.length) {
      if (typeof obj2 === "string" || typeof obj2 === "number" || typeof obj2 === "boolean") {
        return [String(obj2)];
      }
      if (obj2 === null || obj2 === void 0) {
        return [];
      }
      if (Array.isArray(obj2) || typeof obj2 === "object") {
        return [JSON.stringify(obj2, null, 2)];
      }
      return [];
    }
    const token = tokens2[pos];
    const results = [];
    if (pos === 0 && token === "$") {
      results.push(JSON.stringify(obj2, null, 2));
    }
    if (token.startsWith("[") && token.endsWith("]")) {
      if (!Array.isArray(obj2))
        return [];
      const index = token.slice(1, -1);
      if (index === "*") {
        for (const item of obj2) {
          results.push(...extractFromObj(item, tokens2, pos + 1));
        }
      } else {
        try {
          let idx = parseInt(index, 10);
          if (idx < 0) {
            idx = obj2.length + idx;
          }
          if (idx >= 0 && idx < obj2.length) {
            results.push(...extractFromObj(obj2[idx], tokens2, pos + 1));
          }
        } catch {
          return [];
        }
      }
    } else if (token.startsWith("{") && token.endsWith("}")) {
      if (typeof obj2 !== "object" || obj2 === null)
        return [];
      const fields = token.slice(1, -1).split(",").map((f3) => f3.trim());
      for (const field of fields) {
        const nestedTokens = tokenizePath(field);
        if (nestedTokens.length) {
          let currentObj = obj2;
          for (const nestedToken of nestedTokens) {
            if (currentObj && typeof currentObj === "object" && nestedToken in currentObj) {
              currentObj = currentObj[nestedToken];
            } else {
              currentObj = void 0;
              break;
            }
          }
          if (currentObj !== void 0) {
            if (typeof currentObj === "string" || typeof currentObj === "number" || typeof currentObj === "boolean") {
              results.push(String(currentObj));
            } else if (Array.isArray(currentObj) || typeof currentObj === "object") {
              results.push(JSON.stringify(currentObj, null, 2));
            }
          }
        }
      }
    } else if (token === "*") {
      if (Array.isArray(obj2)) {
        for (const item of obj2) {
          results.push(...extractFromObj(item, tokens2, pos + 1));
        }
      } else if (typeof obj2 === "object" && obj2 !== null) {
        for (const value of Object.values(obj2)) {
          results.push(...extractFromObj(value, tokens2, pos + 1));
        }
      }
    } else {
      if (typeof obj2 === "object" && obj2 !== null && token in obj2) {
        results.push(...extractFromObj(obj2[token], tokens2, pos + 1));
      }
    }
    return results;
  }
  return extractFromObj(obj, tokens, 0);
}

// node_modules/@langchain/langgraph-checkpoint/dist/store/memory.js
var InMemoryStore2 = class extends BaseStore2 {
  constructor(options) {
    super();
    Object.defineProperty(this, "data", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "vectors", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "_indexConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (options == null ? void 0 : options.index) {
      this._indexConfig = {
        ...options.index,
        __tokenizedFields: (options.index.fields ?? ["$"]).map((p) => [
          p,
          p === "$" ? [p] : tokenizePath(p)
        ])
      };
    }
  }
  async batch(operations) {
    var _a2, _b;
    const results = [];
    const putOps = /* @__PURE__ */ new Map();
    const searchOps = /* @__PURE__ */ new Map();
    for (let i = 0; i < operations.length; i += 1) {
      const op = operations[i];
      if ("key" in op && "namespace" in op && !("value" in op)) {
        results.push(this.getOperation(op));
      } else if ("namespacePrefix" in op) {
        const candidates = this.filterItems(op);
        searchOps.set(i, [op, candidates]);
        results.push(null);
      } else if ("value" in op) {
        const key = `${op.namespace.join(":")}:${op.key}`;
        putOps.set(key, op);
        results.push(null);
      } else if ("matchConditions" in op) {
        results.push(this.listNamespacesOperation(op));
      }
    }
    if (searchOps.size > 0) {
      if ((_a2 = this._indexConfig) == null ? void 0 : _a2.embeddings) {
        const queries = /* @__PURE__ */ new Set();
        for (const [op] of searchOps.values()) {
          if (op.query)
            queries.add(op.query);
        }
        const queryEmbeddings = queries.size > 0 ? await Promise.all(Array.from(queries).map((q) => this._indexConfig.embeddings.embedQuery(q))) : [];
        const queryVectors = Object.fromEntries(Array.from(queries).map((q, i) => [q, queryEmbeddings[i]]));
        for (const [i, [op, candidates]] of searchOps.entries()) {
          if (op.query && queryVectors[op.query]) {
            const queryVector = queryVectors[op.query];
            const scoredResults = this.scoreResults(candidates, queryVector, op.offset ?? 0, op.limit ?? 10);
            results[i] = scoredResults;
          } else {
            results[i] = this.paginateResults(candidates.map((item) => ({ ...item, score: void 0 })), op.offset ?? 0, op.limit ?? 10);
          }
        }
      } else {
        for (const [i, [op, candidates]] of searchOps.entries()) {
          results[i] = this.paginateResults(candidates.map((item) => ({ ...item, score: void 0 })), op.offset ?? 0, op.limit ?? 10);
        }
      }
    }
    if (putOps.size > 0 && ((_b = this._indexConfig) == null ? void 0 : _b.embeddings)) {
      const toEmbed = this.extractTexts(Array.from(putOps.values()));
      if (Object.keys(toEmbed).length > 0) {
        const embeddings = await this._indexConfig.embeddings.embedDocuments(Object.keys(toEmbed));
        this.insertVectors(toEmbed, embeddings);
      }
    }
    for (const op of putOps.values()) {
      this.putOperation(op);
    }
    return results;
  }
  getOperation(op) {
    var _a2;
    const namespaceKey = op.namespace.join(":");
    const item = (_a2 = this.data.get(namespaceKey)) == null ? void 0 : _a2.get(op.key);
    return item ?? null;
  }
  putOperation(op) {
    const namespaceKey = op.namespace.join(":");
    if (!this.data.has(namespaceKey)) {
      this.data.set(namespaceKey, /* @__PURE__ */ new Map());
    }
    const namespaceMap = this.data.get(namespaceKey);
    if (op.value === null) {
      namespaceMap.delete(op.key);
    } else {
      const now = /* @__PURE__ */ new Date();
      if (namespaceMap.has(op.key)) {
        const item = namespaceMap.get(op.key);
        item.value = op.value;
        item.updatedAt = now;
      } else {
        namespaceMap.set(op.key, {
          value: op.value,
          key: op.key,
          namespace: op.namespace,
          createdAt: now,
          updatedAt: now
        });
      }
    }
  }
  listNamespacesOperation(op) {
    const allNamespaces = Array.from(this.data.keys()).map((ns) => ns.split(":"));
    let namespaces = allNamespaces;
    if (op.matchConditions && op.matchConditions.length > 0) {
      namespaces = namespaces.filter((ns) => op.matchConditions.every((condition) => this.doesMatch(condition, ns)));
    }
    if (op.maxDepth !== void 0) {
      namespaces = Array.from(new Set(namespaces.map((ns) => ns.slice(0, op.maxDepth).join(":")))).map((ns) => ns.split(":"));
    }
    namespaces.sort((a, b) => a.join(":").localeCompare(b.join(":")));
    return namespaces.slice(op.offset ?? 0, (op.offset ?? 0) + (op.limit ?? namespaces.length));
  }
  doesMatch(matchCondition, key) {
    const { matchType, path } = matchCondition;
    if (matchType === "prefix") {
      if (path.length > key.length)
        return false;
      return path.every((pElem, index) => {
        const kElem = key[index];
        return pElem === "*" || kElem === pElem;
      });
    } else if (matchType === "suffix") {
      if (path.length > key.length)
        return false;
      return path.every((pElem, index) => {
        const kElem = key[key.length - path.length + index];
        return pElem === "*" || kElem === pElem;
      });
    }
    throw new Error(`Unsupported match type: ${matchType}`);
  }
  filterItems(op) {
    const candidates = [];
    for (const [namespace, items] of this.data.entries()) {
      if (namespace.startsWith(op.namespacePrefix.join(":"))) {
        candidates.push(...items.values());
      }
    }
    let filteredCandidates = candidates;
    if (op.filter) {
      filteredCandidates = candidates.filter((item) => Object.entries(op.filter).every(([key, value]) => compareValues(item.value[key], value)));
    }
    return filteredCandidates;
  }
  scoreResults(candidates, queryVector, offset = 0, limit = 10) {
    const flatItems = [];
    const flatVectors = [];
    const scoreless = [];
    for (const item of candidates) {
      const vectors = this.getVectors(item);
      if (vectors.length) {
        for (const vector of vectors) {
          flatItems.push(item);
          flatVectors.push(vector);
        }
      } else {
        scoreless.push(item);
      }
    }
    const scores = this.cosineSimilarity(queryVector, flatVectors);
    const sortedResults = scores.map((score, i) => [score, flatItems[i]]).sort((a, b) => b[0] - a[0]);
    const seen = /* @__PURE__ */ new Set();
    const kept = [];
    for (const [score, item] of sortedResults) {
      const key = `${item.namespace.join(":")}:${item.key}`;
      if (seen.has(key))
        continue;
      const ix = seen.size;
      if (ix >= offset + limit)
        break;
      if (ix < offset) {
        seen.add(key);
        continue;
      }
      seen.add(key);
      kept.push([score, item]);
    }
    if (scoreless.length && kept.length < limit) {
      for (const item of scoreless.slice(0, limit - kept.length)) {
        const key = `${item.namespace.join(":")}:${item.key}`;
        if (!seen.has(key)) {
          seen.add(key);
          kept.push([void 0, item]);
        }
      }
    }
    return kept.map(([score, item]) => ({
      ...item,
      score
    }));
  }
  paginateResults(results, offset, limit) {
    return results.slice(offset, offset + limit);
  }
  extractTexts(ops) {
    if (!ops.length || !this._indexConfig) {
      return {};
    }
    const toEmbed = {};
    for (const op of ops) {
      if (op.value !== null && op.index !== false) {
        const paths = op.index === null || op.index === void 0 ? this._indexConfig.__tokenizedFields ?? [] : op.index.map((ix) => [ix, tokenizePath(ix)]);
        for (const [path, field] of paths) {
          const texts = getTextAtPath(op.value, field);
          if (texts.length) {
            if (texts.length > 1) {
              texts.forEach((text, i) => {
                if (!toEmbed[text])
                  toEmbed[text] = [];
                toEmbed[text].push([op.namespace, op.key, `${path}.${i}`]);
              });
            } else {
              if (!toEmbed[texts[0]])
                toEmbed[texts[0]] = [];
              toEmbed[texts[0]].push([op.namespace, op.key, path]);
            }
          }
        }
      }
    }
    return toEmbed;
  }
  insertVectors(texts, embeddings) {
    for (const [text, metadata] of Object.entries(texts)) {
      const embedding = embeddings.shift();
      if (!embedding) {
        throw new Error(`No embedding found for text: ${text}`);
      }
      for (const [namespace, key, field] of metadata) {
        const namespaceKey = namespace.join(":");
        if (!this.vectors.has(namespaceKey)) {
          this.vectors.set(namespaceKey, /* @__PURE__ */ new Map());
        }
        const namespaceMap = this.vectors.get(namespaceKey);
        if (!namespaceMap.has(key)) {
          namespaceMap.set(key, /* @__PURE__ */ new Map());
        }
        const itemMap = namespaceMap.get(key);
        itemMap.set(field, embedding);
      }
    }
  }
  getVectors(item) {
    const namespaceKey = item.namespace.join(":");
    const itemKey = item.key;
    if (!this.vectors.has(namespaceKey)) {
      return [];
    }
    const namespaceMap = this.vectors.get(namespaceKey);
    if (!namespaceMap.has(itemKey)) {
      return [];
    }
    const itemMap = namespaceMap.get(itemKey);
    const vectors = Array.from(itemMap.values());
    if (!vectors.length) {
      return [];
    }
    return vectors;
  }
  cosineSimilarity(X, Y) {
    if (!Y.length)
      return [];
    const dotProducts = Y.map((vector) => vector.reduce((acc, val, i) => acc + val * X[i], 0));
    const magnitude1 = Math.sqrt(X.reduce((acc, val) => acc + val * val, 0));
    const magnitudes2 = Y.map((vector) => Math.sqrt(vector.reduce((acc, val) => acc + val * val, 0)));
    return dotProducts.map((dot, i) => {
      const magnitude2 = magnitudes2[i];
      return magnitude1 && magnitude2 ? dot / (magnitude1 * magnitude2) : 0;
    });
  }
  get indexConfig() {
    return this._indexConfig;
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/cache/base.js
var BaseCache2 = class {
  /**
   * Initialize the cache with a serializer.
   *
   * @param serde - The serializer to use.
   */
  constructor(serde) {
    Object.defineProperty(this, "serde", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new JsonPlusSerializer()
    });
    this.serde = serde || this.serde;
  }
};

// node_modules/@langchain/langgraph/dist/channels/base.js
function isBaseChannel(obj) {
  return obj != null && obj.lg_is_channel === true;
}
var BaseChannel = class {
  constructor() {
    Object.defineProperty(this, "ValueType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "UpdateType", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "lg_is_channel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
  }
  /**
   * Mark the current value of the channel as consumed. By default, no-op.
   * A channel can use this method to modify its state, preventing the value
   * from being consumed again.
   *
   * Returns True if the channel was updated, False otherwise.
   */
  consume() {
    return false;
  }
  /**
   * Notify the channel that the Pregel run is finishing. By default, no-op.
   * A channel can use this method to modify its state, preventing finish.
   *
   * Returns True if the channel was updated, False otherwise.
   */
  finish() {
    return false;
  }
  /**
   * Return True if the channel is available (not empty), False otherwise.
   * Subclasses should override this method to provide a more efficient
   * implementation than calling get() and catching EmptyChannelError.
   */
  isAvailable() {
    try {
      this.get();
      return true;
    } catch (error) {
      if (error.name === EmptyChannelError.unminifiable_name) {
        return false;
      }
      throw error;
    }
  }
};
var IS_ONLY_BASE_CHANNEL = Symbol.for("LG_IS_ONLY_BASE_CHANNEL");
function getOnlyChannels(channels) {
  if (channels[IS_ONLY_BASE_CHANNEL] === true)
    return channels;
  const newChannels = {};
  for (const k in channels) {
    if (!Object.prototype.hasOwnProperty.call(channels, k))
      continue;
    const value = channels[k];
    if (isBaseChannel(value))
      newChannels[k] = value;
  }
  Object.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });
  return newChannels;
}
function emptyChannels(channels, checkpoint) {
  const filteredChannels = getOnlyChannels(channels);
  const newChannels = {};
  for (const k in filteredChannels) {
    if (!Object.prototype.hasOwnProperty.call(filteredChannels, k))
      continue;
    const channelValue = checkpoint.channel_values[k];
    newChannels[k] = filteredChannels[k].fromCheckpoint(channelValue);
  }
  Object.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });
  return newChannels;
}
function createCheckpoint(checkpoint, channels, step, options) {
  let values;
  if (channels === void 0) {
    values = checkpoint.channel_values;
  } else {
    values = {};
    for (const k in channels) {
      if (!Object.prototype.hasOwnProperty.call(channels, k))
        continue;
      try {
        values[k] = channels[k].checkpoint();
      } catch (error) {
        if (error.name === EmptyChannelError.unminifiable_name) {
        } else {
          throw error;
        }
      }
    }
  }
  const newVersionsSeen = {};
  for (const k in checkpoint.versions_seen) {
    if (!Object.prototype.hasOwnProperty.call(checkpoint.versions_seen, k))
      continue;
    newVersionsSeen[k] = { ...checkpoint.versions_seen[k] };
  }
  return {
    v: 4,
    id: (options == null ? void 0 : options.id) ?? uuid6(step),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: values,
    channel_versions: { ...checkpoint.channel_versions },
    versions_seen: newVersionsSeen
  };
}

// node_modules/@langchain/langgraph/dist/channels/binop.js
var BinaryOperatorAggregate = class _BinaryOperatorAggregate extends BaseChannel {
  constructor(operator, initialValueFactory) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "BinaryOperatorAggregate"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "operator", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "initialValueFactory", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.operator = operator;
    this.initialValueFactory = initialValueFactory;
    this.value = initialValueFactory == null ? void 0 : initialValueFactory();
  }
  fromCheckpoint(checkpoint) {
    const empty = new _BinaryOperatorAggregate(this.operator, this.initialValueFactory);
    if (typeof checkpoint !== "undefined") {
      empty.value = checkpoint;
    }
    return empty;
  }
  update(values) {
    let newValues = values;
    if (!newValues.length)
      return false;
    if (this.value === void 0) {
      [this.value] = newValues;
      newValues = newValues.slice(1);
    }
    for (const value of newValues) {
      if (this.value !== void 0) {
        this.value = this.operator(this.value, value);
      }
    }
    return true;
  }
  get() {
    if (this.value === void 0) {
      throw new EmptyChannelError();
    }
    return this.value;
  }
  checkpoint() {
    if (this.value === void 0) {
      throw new EmptyChannelError();
    }
    return this.value;
  }
  isAvailable() {
    return this.value !== void 0;
  }
};

// node_modules/@langchain/langgraph/dist/channels/last_value.js
var LastValue = class _LastValue extends BaseChannel {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "LastValue"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
  }
  fromCheckpoint(checkpoint) {
    const empty = new _LastValue();
    if (typeof checkpoint !== "undefined") {
      empty.value = [checkpoint];
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      return false;
    }
    if (values.length !== 1) {
      throw new InvalidUpdateError("LastValue can only receive one value per step.", { lc_error_code: "INVALID_CONCURRENT_GRAPH_UPDATE" });
    }
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};
var LastValueAfterFinish = class _LastValueAfterFinish extends BaseChannel {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "LastValueAfterFinish"
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "finished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
  }
  fromCheckpoint(checkpoint) {
    const empty = new _LastValueAfterFinish();
    if (typeof checkpoint !== "undefined") {
      const [value, finished] = checkpoint;
      empty.value = [value];
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      return false;
    }
    this.finished = false;
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0 || !this.finished) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0)
      return void 0;
    return [this.value[0], this.finished];
  }
  consume() {
    if (this.finished) {
      this.finished = false;
      this.value = [];
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && this.value.length > 0) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.value.length !== 0 && this.finished;
  }
};

// node_modules/@langchain/langgraph/dist/graph/annotation.js
var AnnotationRoot = class {
  constructor(s) {
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "AnnotationRoot"
    });
    Object.defineProperty(this, "spec", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.spec = s;
  }
};
var Annotation = function(annotation) {
  if (annotation) {
    return getChannel(annotation);
  } else {
    return new LastValue();
  }
};
Annotation.Root = (sd) => new AnnotationRoot(sd);
function getChannel(reducer) {
  if (typeof reducer === "object" && reducer && "reducer" in reducer && reducer.reducer) {
    return new BinaryOperatorAggregate(reducer.reducer, reducer.default);
  }
  if (typeof reducer === "object" && reducer && "value" in reducer && reducer.value) {
    return new BinaryOperatorAggregate(reducer.value, reducer.default);
  }
  return new LastValue();
}

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/regex.js
var regex_default2 = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/validate.js
function validate3(uuid) {
  return typeof uuid === "string" && regex_default2.test(uuid);
}
var validate_default2 = validate3;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/parse.js
function parse2(uuid) {
  if (!validate_default2(uuid)) {
    throw TypeError("Invalid UUID");
  }
  var v;
  var arr2 = new Uint8Array(16);
  arr2[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;
  arr2[1] = v >>> 16 & 255;
  arr2[2] = v >>> 8 & 255;
  arr2[3] = v & 255;
  arr2[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;
  arr2[5] = v & 255;
  arr2[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;
  arr2[7] = v & 255;
  arr2[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;
  arr2[9] = v & 255;
  arr2[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 1099511627776 & 255;
  arr2[11] = v / 4294967296 & 255;
  arr2[12] = v >>> 24 & 255;
  arr2[13] = v >>> 16 & 255;
  arr2[14] = v >>> 8 & 255;
  arr2[15] = v & 255;
  return arr2;
}
var parse_default2 = parse2;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/stringify.js
var byteToHex2 = [];
for (i = 0; i < 256; ++i) {
  byteToHex2.push((i + 256).toString(16).slice(1));
}
var i;
function unsafeStringify2(arr2, offset = 0) {
  return (byteToHex2[arr2[offset + 0]] + byteToHex2[arr2[offset + 1]] + byteToHex2[arr2[offset + 2]] + byteToHex2[arr2[offset + 3]] + "-" + byteToHex2[arr2[offset + 4]] + byteToHex2[arr2[offset + 5]] + "-" + byteToHex2[arr2[offset + 6]] + byteToHex2[arr2[offset + 7]] + "-" + byteToHex2[arr2[offset + 8]] + byteToHex2[arr2[offset + 9]] + "-" + byteToHex2[arr2[offset + 10]] + byteToHex2[arr2[offset + 11]] + byteToHex2[arr2[offset + 12]] + byteToHex2[arr2[offset + 13]] + byteToHex2[arr2[offset + 14]] + byteToHex2[arr2[offset + 15]]).toLowerCase();
}

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/rng.js
var getRandomValues2;
var rnds82 = new Uint8Array(16);
function rng2() {
  if (!getRandomValues2) {
    getRandomValues2 = typeof crypto !== "undefined" && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);
    if (!getRandomValues2) {
      throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");
    }
  }
  return getRandomValues2(rnds82);
}

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/v35.js
function stringToBytes2(str) {
  str = unescape(encodeURIComponent(str));
  var bytes = [];
  for (var i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }
  return bytes;
}
var DNS2 = "6ba7b810-9dad-11d1-80b4-00c04fd430c8";
var URL2 = "6ba7b811-9dad-11d1-80b4-00c04fd430c8";
function v352(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    var _namespace;
    if (typeof value === "string") {
      value = stringToBytes2(value);
    }
    if (typeof namespace === "string") {
      namespace = parse_default2(namespace);
    }
    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {
      throw TypeError("Namespace must be array-like (16 iterable integer values, 0-255)");
    }
    var bytes = new Uint8Array(16 + value.length);
    bytes.set(namespace);
    bytes.set(value, namespace.length);
    bytes = hashfunc(bytes);
    bytes[6] = bytes[6] & 15 | version;
    bytes[8] = bytes[8] & 63 | 128;
    if (buf) {
      offset = offset || 0;
      for (var i = 0; i < 16; ++i) {
        buf[offset + i] = bytes[i];
      }
      return buf;
    }
    return unsafeStringify2(bytes);
  }
  try {
    generateUUID.name = name;
  } catch (err) {
  }
  generateUUID.DNS = DNS2;
  generateUUID.URL = URL2;
  return generateUUID;
}

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/md5.js
function md52(bytes) {
  if (typeof bytes === "string") {
    var msg = unescape(encodeURIComponent(bytes));
    bytes = new Uint8Array(msg.length);
    for (var i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }
  return md5ToHexEncodedArray2(wordsToMd52(bytesToWords2(bytes), bytes.length * 8));
}
function md5ToHexEncodedArray2(input) {
  var output = [];
  var length32 = input.length * 32;
  var hexTab = "0123456789abcdef";
  for (var i = 0; i < length32; i += 8) {
    var x = input[i >> 5] >>> i % 32 & 255;
    var hex = parseInt(hexTab.charAt(x >>> 4 & 15) + hexTab.charAt(x & 15), 16);
    output.push(hex);
  }
  return output;
}
function getOutputLength2(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
function wordsToMd52(x, len) {
  x[len >> 5] |= 128 << len % 32;
  x[getOutputLength2(len) - 1] = len;
  var a = 1732584193;
  var b = -271733879;
  var c = -1732584194;
  var d = 271733878;
  for (var i = 0; i < x.length; i += 16) {
    var olda = a;
    var oldb = b;
    var oldc = c;
    var oldd = d;
    a = md5ff2(a, b, c, d, x[i], 7, -680876936);
    d = md5ff2(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff2(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff2(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff2(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff2(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff2(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff2(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff2(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff2(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff2(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff2(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff2(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff2(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff2(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff2(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg2(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg2(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg2(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg2(b, c, d, a, x[i], 20, -373897302);
    a = md5gg2(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg2(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg2(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg2(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg2(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg2(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg2(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg2(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg2(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg2(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg2(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg2(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh2(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh2(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh2(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh2(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh2(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh2(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh2(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh2(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh2(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh2(d, a, b, c, x[i], 11, -358537222);
    c = md5hh2(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh2(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh2(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh2(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh2(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh2(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii2(a, b, c, d, x[i], 6, -198630844);
    d = md5ii2(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii2(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii2(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii2(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii2(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii2(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii2(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii2(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii2(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii2(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii2(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii2(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii2(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii2(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii2(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd2(a, olda);
    b = safeAdd2(b, oldb);
    c = safeAdd2(c, oldc);
    d = safeAdd2(d, oldd);
  }
  return [a, b, c, d];
}
function bytesToWords2(input) {
  if (input.length === 0) {
    return [];
  }
  var length8 = input.length * 8;
  var output = new Uint32Array(getOutputLength2(length8));
  for (var i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 255) << i % 32;
  }
  return output;
}
function safeAdd2(x, y) {
  var lsw = (x & 65535) + (y & 65535);
  var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 65535;
}
function bitRotateLeft2(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
function md5cmn2(q, a, b, x, s, t) {
  return safeAdd2(bitRotateLeft2(safeAdd2(safeAdd2(a, q), safeAdd2(x, t)), s), b);
}
function md5ff2(a, b, c, d, x, s, t) {
  return md5cmn2(b & c | ~b & d, a, b, x, s, t);
}
function md5gg2(a, b, c, d, x, s, t) {
  return md5cmn2(b & d | c & ~d, a, b, x, s, t);
}
function md5hh2(a, b, c, d, x, s, t) {
  return md5cmn2(b ^ c ^ d, a, b, x, s, t);
}
function md5ii2(a, b, c, d, x, s, t) {
  return md5cmn2(c ^ (b | ~d), a, b, x, s, t);
}
var md5_default2 = md52;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/v3.js
var v32 = v352("v3", 48, md5_default2);

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/native.js
var randomUUID2 = typeof crypto !== "undefined" && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native_default2 = {
  randomUUID: randomUUID2
};

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/v4.js
function v4(options, buf, offset) {
  if (native_default2.randomUUID && !buf && !options) {
    return native_default2.randomUUID();
  }
  options = options || {};
  var rnds = options.random || (options.rng || rng2)();
  rnds[6] = rnds[6] & 15 | 64;
  rnds[8] = rnds[8] & 63 | 128;
  if (buf) {
    offset = offset || 0;
    for (var i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }
    return buf;
  }
  return unsafeStringify2(rnds);
}
var v4_default2 = v4;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/sha1.js
function f2(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;
    case 1:
      return x ^ y ^ z;
    case 2:
      return x & y ^ x & z ^ y & z;
    case 3:
      return x ^ y ^ z;
  }
}
function ROTL2(x, n2) {
  return x << n2 | x >>> 32 - n2;
}
function sha12(bytes) {
  var K2 = [1518500249, 1859775393, 2400959708, 3395469782];
  var H = [1732584193, 4023233417, 2562383102, 271733878, 3285377520];
  if (typeof bytes === "string") {
    var msg = unescape(encodeURIComponent(bytes));
    bytes = [];
    for (var i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  } else if (!Array.isArray(bytes)) {
    bytes = Array.prototype.slice.call(bytes);
  }
  bytes.push(128);
  var l = bytes.length / 4 + 2;
  var N = Math.ceil(l / 16);
  var M = new Array(N);
  for (var _i = 0; _i < N; ++_i) {
    var arr2 = new Uint32Array(16);
    for (var j = 0; j < 16; ++j) {
      arr2[j] = bytes[_i * 64 + j * 4] << 24 | bytes[_i * 64 + j * 4 + 1] << 16 | bytes[_i * 64 + j * 4 + 2] << 8 | bytes[_i * 64 + j * 4 + 3];
    }
    M[_i] = arr2;
  }
  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 4294967295;
  for (var _i2 = 0; _i2 < N; ++_i2) {
    var W = new Uint32Array(80);
    for (var t = 0; t < 16; ++t) {
      W[t] = M[_i2][t];
    }
    for (var _t = 16; _t < 80; ++_t) {
      W[_t] = ROTL2(W[_t - 3] ^ W[_t - 8] ^ W[_t - 14] ^ W[_t - 16], 1);
    }
    var a = H[0];
    var b = H[1];
    var c = H[2];
    var d = H[3];
    var e = H[4];
    for (var _t2 = 0; _t2 < 80; ++_t2) {
      var s = Math.floor(_t2 / 20);
      var T = ROTL2(a, 5) + f2(s, b, c, d) + e + K2[s] + W[_t2] >>> 0;
      e = d;
      d = c;
      c = ROTL2(b, 30) >>> 0;
      b = a;
      a = T;
    }
    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }
  return [H[0] >> 24 & 255, H[0] >> 16 & 255, H[0] >> 8 & 255, H[0] & 255, H[1] >> 24 & 255, H[1] >> 16 & 255, H[1] >> 8 & 255, H[1] & 255, H[2] >> 24 & 255, H[2] >> 16 & 255, H[2] >> 8 & 255, H[2] & 255, H[3] >> 24 & 255, H[3] >> 16 & 255, H[3] >> 8 & 255, H[3] & 255, H[4] >> 24 & 255, H[4] >> 16 & 255, H[4] >> 8 & 255, H[4] & 255];
}
var sha1_default2 = sha12;

// node_modules/@langchain/langgraph/node_modules/uuid/dist/esm-browser/v5.js
var v52 = v352("v5", 80, sha1_default2);

// node_modules/@langchain/langgraph/dist/constants.js
var _a;
var START = "__start__";
var END = "__end__";
var INPUT = "__input__";
var COPY = "__copy__";
var ERROR3 = "__error__";
var CACHE_NS_WRITES = "__pregel_ns_writes";
var CONFIG_KEY_SEND = "__pregel_send";
var CONFIG_KEY_CALL = "__pregel_call";
var CONFIG_KEY_READ = "__pregel_read";
var CONFIG_KEY_CHECKPOINTER = "__pregel_checkpointer";
var CONFIG_KEY_RESUMING = "__pregel_resuming";
var CONFIG_KEY_TASK_ID = "__pregel_task_id";
var CONFIG_KEY_STREAM = "__pregel_stream";
var CONFIG_KEY_RESUME_VALUE = "__pregel_resume_value";
var CONFIG_KEY_RESUME_MAP = "__pregel_resume_map";
var CONFIG_KEY_SCRATCHPAD = "__pregel_scratchpad";
var CONFIG_KEY_PREVIOUS_STATE = "__pregel_previous";
var CONFIG_KEY_DURABILITY = "__pregel_durability";
var CONFIG_KEY_CHECKPOINT_ID = "checkpoint_id";
var CONFIG_KEY_CHECKPOINT_NS = "checkpoint_ns";
var CONFIG_KEY_NODE_FINISHED = "__pregel_node_finished";
var CONFIG_KEY_CHECKPOINT_MAP = "checkpoint_map";
var CONFIG_KEY_ABORT_SIGNALS = "__pregel_abort_signals";
var INTERRUPT2 = "__interrupt__";
var RESUME2 = "__resume__";
var NO_WRITES = "__no_writes__";
var RETURN = "__return__";
var PREVIOUS = "__previous__";
var TAG_HIDDEN = "langsmith:hidden";
var TAG_NOSTREAM = "langsmith:nostream";
var SELF = "__self__";
var TASKS2 = "__pregel_tasks";
var PUSH = "__pregel_push";
var PULL = "__pregel_pull";
var NULL_TASK_ID = "00000000-0000-0000-0000-000000000000";
var RESERVED = [
  TAG_HIDDEN,
  INPUT,
  INTERRUPT2,
  RESUME2,
  ERROR3,
  NO_WRITES,
  // reserved config.configurable keys
  CONFIG_KEY_SEND,
  CONFIG_KEY_READ,
  CONFIG_KEY_CHECKPOINTER,
  CONFIG_KEY_DURABILITY,
  CONFIG_KEY_STREAM,
  CONFIG_KEY_RESUMING,
  CONFIG_KEY_TASK_ID,
  CONFIG_KEY_CALL,
  CONFIG_KEY_RESUME_VALUE,
  CONFIG_KEY_SCRATCHPAD,
  CONFIG_KEY_PREVIOUS_STATE,
  CONFIG_KEY_CHECKPOINT_MAP,
  CONFIG_KEY_CHECKPOINT_NS,
  CONFIG_KEY_CHECKPOINT_ID
];
var CHECKPOINT_NAMESPACE_SEPARATOR = "|";
var CHECKPOINT_NAMESPACE_END = ":";
var COMMAND_SYMBOL = Symbol.for("langgraph.command");
var CommandInstance = class {
  constructor() {
    Object.defineProperty(this, _a, {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
  }
};
_a = COMMAND_SYMBOL;
function _isSendInterface(x) {
  const operation = x;
  return operation !== null && operation !== void 0 && typeof operation.node === "string" && operation.args !== void 0;
}
var Send = class {
  constructor(node, args) {
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "Send"
    });
    Object.defineProperty(this, "node", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "args", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.node = node;
    this.args = _deserializeCommandSendObjectGraph(args);
  }
  toJSON() {
    return { lg_name: this.lg_name, node: this.node, args: this.args };
  }
};
function _isSend(x) {
  return x instanceof Send;
}
function isInterrupted(values) {
  if (!values || typeof values !== "object")
    return false;
  if (!(INTERRUPT2 in values))
    return false;
  return Array.isArray(values[INTERRUPT2]);
}
var Command = class extends CommandInstance {
  constructor(args) {
    super();
    Object.defineProperty(this, "lg_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "Command"
    });
    Object.defineProperty(this, "lc_direct_tool_output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "graph", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "update", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "resume", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "goto", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.resume = args.resume;
    this.graph = args.graph;
    this.update = args.update;
    if (args.goto) {
      this.goto = Array.isArray(args.goto) ? _deserializeCommandSendObjectGraph(args.goto) : [_deserializeCommandSendObjectGraph(args.goto)];
    }
  }
  /**
   * Convert the update field to a list of {@link PendingWrite} tuples
   * @returns List of {@link PendingWrite} tuples of the form `[channelKey, value]`.
   * @internal
   */
  _updateAsTuples() {
    if (this.update && typeof this.update === "object" && !Array.isArray(this.update)) {
      return Object.entries(this.update);
    } else if (Array.isArray(this.update) && this.update.every((t) => Array.isArray(t) && t.length === 2 && typeof t[0] === "string")) {
      return this.update;
    } else {
      return [["__root__", this.update]];
    }
  }
  toJSON() {
    var _a2;
    let serializedGoto;
    if (typeof this.goto === "string") {
      serializedGoto = this.goto;
    } else if (_isSend(this.goto)) {
      serializedGoto = this.goto.toJSON();
    } else {
      serializedGoto = (_a2 = this.goto) == null ? void 0 : _a2.map((innerGoto) => {
        if (typeof innerGoto === "string") {
          return innerGoto;
        } else {
          return innerGoto.toJSON();
        }
      });
    }
    return {
      lg_name: this.lg_name,
      update: this.update,
      resume: this.resume,
      goto: serializedGoto
    };
  }
};
Object.defineProperty(Command, "PARENT", {
  enumerable: true,
  configurable: true,
  writable: true,
  value: "__parent__"
});
function isCommand(x) {
  if (typeof x !== "object") {
    return false;
  }
  if (x === null || x === void 0) {
    return false;
  }
  if ("lg_name" in x && x.lg_name === "Command") {
    return true;
  }
  return false;
}
function _deserializeCommandSendObjectGraph(x, seen = /* @__PURE__ */ new Map()) {
  if (x !== void 0 && x !== null && typeof x === "object") {
    if (seen.has(x)) {
      return seen.get(x);
    }
    let result;
    if (Array.isArray(x)) {
      result = [];
      seen.set(x, result);
      x.forEach((item, index) => {
        result[index] = _deserializeCommandSendObjectGraph(item, seen);
      });
    } else if (isCommand(x) && !(x instanceof Command)) {
      result = new Command(x);
      seen.set(x, result);
    } else if (_isSendInterface(x) && !(x instanceof Send)) {
      result = new Send(x.node, x.args);
      seen.set(x, result);
    } else if (isCommand(x) || _isSend(x)) {
      result = x;
      seen.set(x, result);
    } else if ("lc_serializable" in x && x.lc_serializable) {
      result = x;
      seen.set(x, result);
    } else {
      result = {};
      seen.set(x, result);
      for (const [key, value] of Object.entries(x)) {
        result[key] = _deserializeCommandSendObjectGraph(value, seen);
      }
    }
    return result;
  }
  return x;
}

// node_modules/@langchain/langgraph/dist/pregel/utils/config.js
var COPIABLE_KEYS = ["tags", "metadata", "callbacks", "configurable"];
var CONFIG_KEYS = [
  "tags",
  "metadata",
  "callbacks",
  "runName",
  "maxConcurrency",
  "recursionLimit",
  "configurable",
  "runId",
  "outputKeys",
  "streamMode",
  "store",
  "writer",
  "context",
  "interruptBefore",
  "interruptAfter",
  "checkpointDuring",
  "durability",
  "signal"
];
var DEFAULT_RECURSION_LIMIT = 25;
function ensureLangGraphConfig(...configs) {
  const empty = {
    tags: [],
    metadata: {},
    callbacks: void 0,
    recursionLimit: DEFAULT_RECURSION_LIMIT,
    configurable: {}
  };
  const implicitConfig = AsyncLocalStorageProviderSingleton.getRunnableConfig();
  if (implicitConfig !== void 0) {
    for (const [k, v] of Object.entries(implicitConfig)) {
      if (v !== void 0) {
        if (COPIABLE_KEYS.includes(k)) {
          let copiedValue;
          if (Array.isArray(v)) {
            copiedValue = [...v];
          } else if (typeof v === "object") {
            if (k === "callbacks" && "copy" in v && typeof v.copy === "function") {
              copiedValue = v.copy();
            } else {
              copiedValue = { ...v };
            }
          } else {
            copiedValue = v;
          }
          empty[k] = copiedValue;
        } else {
          empty[k] = v;
        }
      }
    }
  }
  for (const config of configs) {
    if (config === void 0) {
      continue;
    }
    for (const [k, v] of Object.entries(config)) {
      if (v !== void 0 && CONFIG_KEYS.includes(k)) {
        empty[k] = v;
      }
    }
  }
  for (const [key, value] of Object.entries(empty.configurable)) {
    empty.metadata = empty.metadata ?? {};
    if (!key.startsWith("__") && (typeof value === "string" || typeof value === "number" || typeof value === "boolean") && !(key in empty.metadata)) {
      empty.metadata[key] = value;
    }
  }
  return empty;
}
function getConfig() {
  return AsyncLocalStorageProviderSingleton.getRunnableConfig();
}
function recastCheckpointNamespace(namespace) {
  return namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR).filter((part) => !part.match(/^\d+$/)).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}
function getParentCheckpointNamespace(namespace) {
  const parts = namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR);
  while (parts.length > 1 && parts[parts.length - 1].match(/^\d+$/)) {
    parts.pop();
  }
  return parts.slice(0, -1).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}

// node_modules/@langchain/langgraph/dist/utils.js
var RunnableCallable = class extends Runnable {
  constructor(fields) {
    super();
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph"]
    });
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "trace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "recurse", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.name = fields.name ?? fields.func.name;
    this.func = fields.func;
    this.config = fields.tags ? { tags: fields.tags } : void 0;
    this.trace = fields.trace ?? this.trace;
    this.recurse = fields.recurse ?? this.recurse;
  }
  async _tracedInvoke(input, config, runManager) {
    return new Promise((resolve, reject) => {
      const childConfig = patchConfig(config, {
        callbacks: runManager == null ? void 0 : runManager.getChild()
      });
      void AsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async () => {
        try {
          const output = await this.func(input, childConfig);
          resolve(output);
        } catch (e) {
          reject(e);
        }
      });
    });
  }
  async invoke(input, options) {
    let returnValue;
    const config = ensureLangGraphConfig(options);
    const mergedConfig = mergeConfigs(this.config, config);
    if (this.trace) {
      returnValue = await this._callWithConfig(this._tracedInvoke, input, mergedConfig);
    } else {
      returnValue = await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => this.func(input, mergedConfig));
    }
    if (Runnable.isRunnable(returnValue) && this.recurse) {
      return await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => returnValue.invoke(input, mergedConfig));
    }
    return returnValue;
  }
};
function* prefixGenerator(generator, prefix) {
  if (prefix === void 0) {
    yield* generator;
  } else {
    for (const value of generator) {
      yield [prefix, value];
    }
  }
}
async function gatherIterator(i) {
  const out = [];
  for await (const item of await i) {
    out.push(item);
  }
  return out;
}
function gatherIteratorSync(i) {
  const out = [];
  for (const item of i) {
    out.push(item);
  }
  return out;
}
function patchConfigurable(config, patch) {
  if (!config) {
    return {
      configurable: patch
    };
  } else if (!("configurable" in config)) {
    return {
      ...config,
      configurable: patch
    };
  } else {
    return {
      ...config,
      configurable: {
        ...config.configurable,
        ...patch
      }
    };
  }
}
function isAsyncGeneratorFunction(val) {
  return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
  val instanceof Object.getPrototypeOf(async function* () {
  }).constructor;
}
function isGeneratorFunction(val) {
  return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
  val instanceof Object.getPrototypeOf(function* () {
  }).constructor;
}

// node_modules/@langchain/langgraph/dist/pregel/write.js
var SKIP_WRITE = {
  [Symbol.for("LG_SKIP_WRITE")]: true
};
function _isSkipWrite(x) {
  return typeof x === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  (x == null ? void 0 : x[Symbol.for("LG_SKIP_WRITE")]) !== void 0;
}
var PASSTHROUGH = {
  [Symbol.for("LG_PASSTHROUGH")]: true
};
function _isPassthrough(x) {
  return typeof x === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  (x == null ? void 0 : x[Symbol.for("LG_PASSTHROUGH")]) !== void 0;
}
var IS_WRITER = Symbol("IS_WRITER");
var ChannelWrite = class _ChannelWrite extends RunnableCallable {
  constructor(writes, tags) {
    const name = `ChannelWrite<${writes.map((packet) => {
      if (_isSend(packet)) {
        return packet.node;
      } else if ("channel" in packet) {
        return packet.channel;
      }
      return "...";
    }).join(",")}>`;
    super({
      ...{ writes, name, tags },
      func: async (input, config) => {
        return this._write(input, config ?? {});
      }
    });
    Object.defineProperty(this, "writes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.writes = writes;
  }
  async _write(input, config) {
    const writes = this.writes.map((write) => {
      if (_isChannelWriteTupleEntry(write) && _isPassthrough(write.value)) {
        return {
          mapper: write.mapper,
          value: input
        };
      } else if (_isChannelWriteEntry(write) && _isPassthrough(write.value)) {
        return {
          channel: write.channel,
          value: input,
          skipNone: write.skipNone,
          mapper: write.mapper
        };
      } else {
        return write;
      }
    });
    await _ChannelWrite.doWrite(config, writes);
    return input;
  }
  // TODO: Support requireAtLeastOneOf
  static async doWrite(config, writes) {
    var _a2;
    for (const w of writes) {
      if (_isChannelWriteEntry(w)) {
        if (w.channel === TASKS2) {
          throw new InvalidUpdateError("Cannot write to the reserved channel TASKS");
        }
        if (_isPassthrough(w.value)) {
          throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
        }
      }
      if (_isChannelWriteTupleEntry(w)) {
        if (_isPassthrough(w.value)) {
          throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
        }
      }
    }
    const writeEntries = [];
    for (const w of writes) {
      if (_isSend(w)) {
        writeEntries.push([TASKS2, w]);
      } else if (_isChannelWriteTupleEntry(w)) {
        const mappedResult = await w.mapper.invoke(w.value, config);
        if (mappedResult != null && mappedResult.length > 0) {
          writeEntries.push(...mappedResult);
        }
      } else if (_isChannelWriteEntry(w)) {
        const mappedValue = w.mapper !== void 0 ? await w.mapper.invoke(w.value, config) : w.value;
        if (_isSkipWrite(mappedValue)) {
          continue;
        }
        if (w.skipNone && mappedValue === void 0) {
          continue;
        }
        writeEntries.push([w.channel, mappedValue]);
      } else {
        throw new Error(`Invalid write entry: ${JSON.stringify(w)}`);
      }
    }
    const write = (_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_SEND];
    write(writeEntries);
  }
  static isWriter(runnable) {
    return (
      // eslint-disable-next-line no-instanceof/no-instanceof
      runnable instanceof _ChannelWrite || IS_WRITER in runnable && !!runnable[IS_WRITER]
    );
  }
  static registerWriter(runnable) {
    return Object.defineProperty(runnable, IS_WRITER, { value: true });
  }
};
function _isChannelWriteEntry(x) {
  return x !== void 0 && typeof x.channel === "string";
}
function _isChannelWriteTupleEntry(x) {
  return x !== void 0 && !_isChannelWriteEntry(x) && Runnable.isRunnable(x.mapper);
}

// node_modules/@langchain/langgraph/dist/pregel/read.js
var ChannelRead = class _ChannelRead extends RunnableCallable {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  constructor(channel, mapper, fresh = false) {
    super({
      func: (_, config) => _ChannelRead.doRead(config, this.channel, this.fresh, this.mapper)
    });
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "ChannelRead"
    });
    Object.defineProperty(this, "channel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "fresh", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "mapper", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.fresh = fresh;
    this.mapper = mapper;
    this.channel = channel;
    this.name = Array.isArray(channel) ? `ChannelRead<${channel.join(",")}>` : `ChannelRead<${channel}>`;
  }
  static doRead(config, channel, fresh, mapper) {
    var _a2;
    const read = (_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_READ];
    if (!read) {
      throw new Error("Runnable is not configured with a read function. Make sure to call in the context of a Pregel process");
    }
    if (mapper) {
      return mapper(read(channel, fresh));
    } else {
      return read(channel, fresh);
    }
  }
};
var defaultRunnableBound = new RunnablePassthrough();
var PregelNode = class _PregelNode extends RunnableBinding {
  constructor(fields) {
    var _a2;
    const { channels, triggers, mapper, writers, bound, kwargs, metadata, retryPolicy, cachePolicy, tags, subgraphs, ends } = fields;
    const mergedTags = [
      ...((_a2 = fields.config) == null ? void 0 : _a2.tags) ? fields.config.tags : [],
      ...tags ?? []
    ];
    super({
      ...fields,
      bound: fields.bound ?? defaultRunnableBound,
      config: {
        ...fields.config ? fields.config : {},
        tags: mergedTags
      }
    });
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "PregelNode"
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "triggers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "mapper", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "writers", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "bound", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: defaultRunnableBound
    });
    Object.defineProperty(this, "kwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "metadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "tags", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "retryPolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cachePolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "subgraphs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "ends", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.channels = channels;
    this.triggers = triggers;
    this.mapper = mapper;
    this.writers = writers ?? this.writers;
    this.bound = bound ?? this.bound;
    this.kwargs = kwargs ?? this.kwargs;
    this.metadata = metadata ?? this.metadata;
    this.tags = mergedTags;
    this.retryPolicy = retryPolicy;
    this.cachePolicy = cachePolicy;
    this.subgraphs = subgraphs;
    this.ends = ends;
  }
  getWriters() {
    var _a2;
    const newWriters = [...this.writers];
    while (newWriters.length > 1 && // eslint-disable-next-line no-instanceof/no-instanceof
    newWriters[newWriters.length - 1] instanceof ChannelWrite && // eslint-disable-next-line no-instanceof/no-instanceof
    newWriters[newWriters.length - 2] instanceof ChannelWrite) {
      const endWriters = newWriters.slice(-2);
      const combinedWrites = endWriters[0].writes.concat(endWriters[1].writes);
      newWriters[newWriters.length - 2] = new ChannelWrite(combinedWrites, (_a2 = endWriters[0].config) == null ? void 0 : _a2.tags);
      newWriters.pop();
    }
    return newWriters;
  }
  getNode() {
    const writers = this.getWriters();
    if (this.bound === defaultRunnableBound && writers.length === 0) {
      return void 0;
    } else if (this.bound === defaultRunnableBound && writers.length === 1) {
      return writers[0];
    } else if (this.bound === defaultRunnableBound) {
      return new RunnableSequence({
        first: writers[0],
        middle: writers.slice(1, writers.length - 1),
        last: writers[writers.length - 1],
        omitSequenceTags: true
      });
    } else if (writers.length > 0) {
      return new RunnableSequence({
        first: this.bound,
        middle: writers.slice(0, writers.length - 1),
        last: writers[writers.length - 1],
        omitSequenceTags: true
      });
    } else {
      return this.bound;
    }
  }
  join(channels) {
    if (!Array.isArray(channels)) {
      throw new Error("channels must be a list");
    }
    if (typeof this.channels !== "object") {
      throw new Error("all channels must be named when using .join()");
    }
    return new _PregelNode({
      channels: {
        ...this.channels,
        ...Object.fromEntries(channels.map((chan) => [chan, chan]))
      },
      triggers: this.triggers,
      mapper: this.mapper,
      writers: this.writers,
      bound: this.bound,
      kwargs: this.kwargs,
      config: this.config,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
  }
  pipe(coerceable) {
    if (ChannelWrite.isWriter(coerceable)) {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: [...this.writers, coerceable],
        bound: this.bound,
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    } else if (this.bound === defaultRunnableBound) {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: this.writers,
        bound: _coerceToRunnable(coerceable),
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    } else {
      return new _PregelNode({
        channels: this.channels,
        triggers: this.triggers,
        mapper: this.mapper,
        writers: this.writers,
        bound: this.bound.pipe(coerceable),
        config: this.config,
        kwargs: this.kwargs,
        retryPolicy: this.retryPolicy,
        cachePolicy: this.cachePolicy
      });
    }
  }
};

// node_modules/@langchain/langgraph/dist/hash.js
var n = (n2) => BigInt(n2);
var view = (data, offset = 0) => new DataView(data.buffer, data.byteOffset + offset, data.byteLength - offset);
var PRIME32_1 = n("0x9E3779B1");
var PRIME32_2 = n("0x85EBCA77");
var PRIME32_3 = n("0xC2B2AE3D");
var PRIME64_1 = n("0x9E3779B185EBCA87");
var PRIME64_2 = n("0xC2B2AE3D27D4EB4F");
var PRIME64_3 = n("0x165667B19E3779F9");
var PRIME64_4 = n("0x85EBCA77C2B2AE63");
var PRIME64_5 = n("0x27D4EB2F165667C5");
var PRIME_MX1 = n("0x165667919E3779F9");
var PRIME_MX2 = n("0x9FB21C651E98DF25");
var hexToUint8Array = (hex) => {
  const strLen = hex.length;
  if (strLen % 2 !== 0) {
    throw new Error("String should have an even number of characters");
  }
  const maxLength = strLen / 2;
  const bytes = new Uint8Array(maxLength);
  let read = 0;
  let write = 0;
  while (write < maxLength) {
    const slice = hex.slice(read, read += 2);
    bytes[write] = Number.parseInt(slice, 16);
    write += 1;
  }
  return view(bytes);
};
var kkey = hexToUint8Array("b8fe6c3923a44bbe7c01812cf721ad1cded46de9839097db7240a4a4b7b3671fcb79e64eccc0e578825ad07dccff7221b8084674f743248ee03590e6813a264c3c2852bb91c300cb88d0658b1b532ea371644897a20df94e3819ef46a9deacd8a8fa763fe39c343ff9dcbbc7c70b4f1d8a51e04bcdb45931c89f7ec9d9787364eac5ac8334d3ebc3c581a0fffa1363eb170ddd51b7f0da49d316552629d4689e2b16be587d47a1fc8ff8b8d17ad031ce45cb3a8f95160428afd7fbcabb4b407e");
var mask128 = (n(1) << n(128)) - n(1);
var mask64 = (n(1) << n(64)) - n(1);
var mask32 = (n(1) << n(32)) - n(1);
var STRIPE_LEN = 64;
var ACC_NB = STRIPE_LEN / 8;
var _U64 = 8;
var _U32 = 4;
function assert(a) {
  if (!a)
    throw new Error("Assert failed");
}
function bswap64(a) {
  const scratchbuf = new DataView(new ArrayBuffer(8));
  scratchbuf.setBigUint64(0, a, true);
  return scratchbuf.getBigUint64(0, false);
}
function bswap32(input) {
  let a = input;
  a = (a & n(65535)) << n(16) | (a & n(4294901760)) >> n(16);
  a = (a & n(16711935)) << n(8) | (a & n(4278255360)) >> n(8);
  return a;
}
function XXH_mult32to64(a, b) {
  return (a & mask32) * (b & mask32) & mask64;
}
function rotl32(a, b) {
  return (a << b | a >> n(32) - b) & mask32;
}
function XXH3_accumulate_512(acc, dataView, keyView) {
  for (let i = 0; i < ACC_NB; i += 1) {
    const data_val = dataView.getBigUint64(i * 8, true);
    const data_key = data_val ^ keyView.getBigUint64(i * 8, true);
    acc[i ^ 1] += data_val;
    acc[i] += XXH_mult32to64(data_key, data_key >> n(32));
  }
  return acc;
}
function XXH3_accumulate(acc, dataView, keyView, nbStripes) {
  for (let n2 = 0; n2 < nbStripes; n2 += 1) {
    XXH3_accumulate_512(acc, view(dataView, n2 * STRIPE_LEN), view(keyView, n2 * 8));
  }
  return acc;
}
function XXH3_scrambleAcc(acc, key) {
  for (let i = 0; i < ACC_NB; i += 1) {
    const key64 = key.getBigUint64(i * 8, true);
    let acc64 = acc[i];
    acc64 = xorshift64(acc64, n(47));
    acc64 ^= key64;
    acc64 *= PRIME32_1;
    acc[i] = acc64 & mask64;
  }
  return acc;
}
function XXH3_mix2Accs(acc, key) {
  return XXH3_mul128_fold64(acc[0] ^ key.getBigUint64(0, true), acc[1] ^ key.getBigUint64(_U64, true));
}
function XXH3_mergeAccs(acc, key, start) {
  let result64 = start;
  result64 += XXH3_mix2Accs(acc.slice(0), view(key, 0 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(2), view(key, 4 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(4), view(key, 8 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(6), view(key, 12 * _U32));
  return XXH3_avalanche(result64 & mask64);
}
function XXH3_hashLong(input, data, secret, f_acc, f_scramble) {
  let acc = input;
  const nbStripesPerBlock = Math.floor((secret.byteLength - STRIPE_LEN) / 8);
  const block_len = STRIPE_LEN * nbStripesPerBlock;
  const nb_blocks = Math.floor((data.byteLength - 1) / block_len);
  for (let n2 = 0; n2 < nb_blocks; n2 += 1) {
    acc = XXH3_accumulate(acc, view(data, n2 * block_len), secret, nbStripesPerBlock);
    acc = f_scramble(acc, view(secret, secret.byteLength - STRIPE_LEN));
  }
  {
    const nbStripes = Math.floor((data.byteLength - 1 - block_len * nb_blocks) / STRIPE_LEN);
    acc = XXH3_accumulate(acc, view(data, nb_blocks * block_len), secret, nbStripes);
    acc = f_acc(acc, view(data, data.byteLength - STRIPE_LEN), view(secret, secret.byteLength - STRIPE_LEN - 7));
  }
  return acc;
}
function XXH3_hashLong_128b(data, secret) {
  let acc = new BigUint64Array([
    PRIME32_3,
    PRIME64_1,
    PRIME64_2,
    PRIME64_3,
    PRIME64_4,
    PRIME32_2,
    PRIME64_5,
    PRIME32_1
  ]);
  assert(data.byteLength > 128);
  acc = XXH3_hashLong(acc, data, secret, XXH3_accumulate_512, XXH3_scrambleAcc);
  assert(acc.length * 8 === 64);
  {
    const low64 = XXH3_mergeAccs(acc, view(secret, 11), n(data.byteLength) * PRIME64_1 & mask64);
    const high64 = XXH3_mergeAccs(acc, view(secret, secret.byteLength - STRIPE_LEN - 11), ~(n(data.byteLength) * PRIME64_2) & mask64);
    return high64 << n(64) | low64;
  }
}
function XXH3_mul128_fold64(a, b) {
  const lll = a * b & mask128;
  return lll & mask64 ^ lll >> n(64);
}
function XXH3_mix16B(dataView, keyView, seed) {
  return XXH3_mul128_fold64((dataView.getBigUint64(0, true) ^ keyView.getBigUint64(0, true) + seed) & mask64, (dataView.getBigUint64(8, true) ^ keyView.getBigUint64(8, true) - seed) & mask64);
}
function XXH3_mix32B(acc, data1, data2, key, seed) {
  let accl = acc & mask64;
  let acch = acc >> n(64) & mask64;
  accl += XXH3_mix16B(data1, key, seed);
  accl ^= data2.getBigUint64(0, true) + data2.getBigUint64(8, true);
  accl &= mask64;
  acch += XXH3_mix16B(data2, view(key, 16), seed);
  acch ^= data1.getBigUint64(0, true) + data1.getBigUint64(8, true);
  acch &= mask64;
  return acch << n(64) | accl;
}
function XXH3_avalanche(input) {
  let h64 = input;
  h64 ^= h64 >> n(37);
  h64 *= PRIME_MX1;
  h64 &= mask64;
  h64 ^= h64 >> n(32);
  return h64;
}
function XXH3_avalanche64(input) {
  let h64 = input;
  h64 ^= h64 >> n(33);
  h64 *= PRIME64_2;
  h64 &= mask64;
  h64 ^= h64 >> n(29);
  h64 *= PRIME64_3;
  h64 &= mask64;
  h64 ^= h64 >> n(32);
  return h64;
}
function XXH3_len_1to3_128b(data, key32, seed) {
  const len = data.byteLength;
  assert(len > 0 && len <= 3);
  const combined = n(data.getUint8(len - 1)) | n(len << 8) | n(data.getUint8(0) << 16) | n(data.getUint8(len >> 1) << 24);
  const blow = (n(key32.getUint32(0, true)) ^ n(key32.getUint32(4, true))) + seed;
  const low = (combined ^ blow) & mask64;
  const bhigh = (n(key32.getUint32(8, true)) ^ n(key32.getUint32(12, true))) - seed;
  const high = (rotl32(bswap32(combined), n(13)) ^ bhigh) & mask64;
  return (XXH3_avalanche64(high) & mask64) << n(64) | XXH3_avalanche64(low);
}
function xorshift64(b, shift) {
  return b ^ b >> shift;
}
function XXH3_len_4to8_128b(data, key32, seed) {
  const len = data.byteLength;
  assert(len >= 4 && len <= 8);
  {
    const l1 = data.getUint32(0, true);
    const l2 = data.getUint32(len - 4, true);
    const l64 = n(l1) | n(l2) << n(32);
    const bitflip = (key32.getBigUint64(16, true) ^ key32.getBigUint64(24, true)) + seed & mask64;
    const keyed = l64 ^ bitflip;
    let m128 = keyed * (PRIME64_1 + (n(len) << n(2))) & mask128;
    m128 += (m128 & mask64) << n(65);
    m128 &= mask128;
    m128 ^= m128 >> n(67);
    return xorshift64(xorshift64(m128 & mask64, n(35)) * PRIME_MX2 & mask64, n(28)) | XXH3_avalanche(m128 >> n(64)) << n(64);
  }
}
function XXH3_len_9to16_128b(data, key64, seed) {
  const len = data.byteLength;
  assert(len >= 9 && len <= 16);
  {
    const bitflipl = (key64.getBigUint64(32, true) ^ key64.getBigUint64(40, true)) + seed & mask64;
    const bitfliph = (key64.getBigUint64(48, true) ^ key64.getBigUint64(56, true)) - seed & mask64;
    const ll1 = data.getBigUint64(0, true);
    let ll2 = data.getBigUint64(len - 8, true);
    let m128 = (ll1 ^ ll2 ^ bitflipl) * PRIME64_1;
    const m128_l = (m128 & mask64) + (n(len - 1) << n(54));
    m128 = m128 & (mask128 ^ mask64) | m128_l;
    ll2 ^= bitfliph;
    m128 += ll2 + (ll2 & mask32) * (PRIME32_2 - n(1)) << n(64);
    m128 &= mask128;
    m128 ^= bswap64(m128 >> n(64));
    let h128 = (m128 & mask64) * PRIME64_2;
    h128 += (m128 >> n(64)) * PRIME64_2 << n(64);
    h128 &= mask128;
    return XXH3_avalanche(h128 & mask64) | XXH3_avalanche(h128 >> n(64)) << n(64);
  }
}
function XXH3_len_0to16_128b(data, seed) {
  const len = data.byteLength;
  assert(len <= 16);
  if (len > 8)
    return XXH3_len_9to16_128b(data, kkey, seed);
  if (len >= 4)
    return XXH3_len_4to8_128b(data, kkey, seed);
  if (len > 0)
    return XXH3_len_1to3_128b(data, kkey, seed);
  return XXH3_avalanche64(seed ^ kkey.getBigUint64(64, true) ^ kkey.getBigUint64(72, true)) | XXH3_avalanche64(seed ^ kkey.getBigUint64(80, true) ^ kkey.getBigUint64(88, true)) << n(64);
}
function inv64(x) {
  return ~x + n(1) & mask64;
}
function XXH3_len_17to128_128b(data, secret, seed) {
  let acc = n(data.byteLength) * PRIME64_1 & mask64;
  let i = n(data.byteLength - 1) / n(32);
  while (i >= 0) {
    const ni = Number(i);
    acc = XXH3_mix32B(acc, view(data, 16 * ni), view(data, data.byteLength - 16 * (ni + 1)), view(secret, 32 * ni), seed);
    i -= n(1);
  }
  let h128l = acc + (acc >> n(64)) & mask64;
  h128l = XXH3_avalanche(h128l);
  let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
  h128h &= mask64;
  h128h = inv64(XXH3_avalanche(h128h));
  return h128l | h128h << n(64);
}
function XXH3_len_129to240_128b(data, secret, seed) {
  let acc = n(data.byteLength) * PRIME64_1 & mask64;
  for (let i = 32; i < 160; i += 32) {
    acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, i - 32), seed);
  }
  acc = XXH3_avalanche(acc & mask64) | XXH3_avalanche(acc >> n(64)) << n(64);
  for (let i = 160; i <= data.byteLength; i += 32) {
    acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, 3 + i - 160), seed);
  }
  acc = XXH3_mix32B(acc, view(data, data.byteLength - 16), view(data, data.byteLength - 32), view(secret, 136 - 17 - 16), inv64(seed));
  let h128l = acc + (acc >> n(64)) & mask64;
  h128l = XXH3_avalanche(h128l);
  let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
  h128h &= mask64;
  h128h = inv64(XXH3_avalanche(h128h));
  return h128l | h128h << n(64);
}
function XXH3(input, seed = n(0)) {
  const encoder = new TextEncoder();
  const data = view(typeof input === "string" ? encoder.encode(input) : input);
  const len = data.byteLength;
  const hexDigest = (data2) => data2.toString(16).padStart(32, "0");
  if (len <= 16)
    return hexDigest(XXH3_len_0to16_128b(data, seed));
  if (len <= 128)
    return hexDigest(XXH3_len_17to128_128b(data, kkey, seed));
  if (len <= 240)
    return hexDigest(XXH3_len_129to240_128b(data, kkey, seed));
  return hexDigest(XXH3_hashLong_128b(data, kkey));
}
function isXXH3(value) {
  return /^[0-9a-f]{32}$/.test(value);
}

// node_modules/@langchain/langgraph/dist/pregel/io.js
function readChannel(channels, chan, catchErrors = true, returnException = false) {
  try {
    return channels[chan].get();
  } catch (e) {
    if (e.name === EmptyChannelError.unminifiable_name) {
      if (returnException) {
        return e;
      } else if (catchErrors) {
        return null;
      }
    }
    throw e;
  }
}
function readChannels(channels, select, skipEmpty = true) {
  if (Array.isArray(select)) {
    const values = {};
    for (const k of select) {
      try {
        values[k] = readChannel(channels, k, !skipEmpty);
      } catch (e) {
        if (e.name === EmptyChannelError.unminifiable_name) {
          continue;
        }
      }
    }
    return values;
  } else {
    return readChannel(channels, select);
  }
}
function* mapCommand(cmd, pendingWrites) {
  if (cmd.graph === Command.PARENT) {
    throw new InvalidUpdateError("There is no parent graph.");
  }
  if (cmd.goto) {
    let sends;
    if (Array.isArray(cmd.goto)) {
      sends = cmd.goto;
    } else {
      sends = [cmd.goto];
    }
    for (const send of sends) {
      if (_isSend(send)) {
        yield [NULL_TASK_ID, TASKS2, send];
      } else if (typeof send === "string") {
        yield [NULL_TASK_ID, `branch:to:${send}`, "__start__"];
      } else {
        throw new Error(`In Command.send, expected Send or string, got ${typeof send}`);
      }
    }
  }
  if (cmd.resume) {
    if (typeof cmd.resume === "object" && Object.keys(cmd.resume).length && Object.keys(cmd.resume).every(isXXH3)) {
      for (const [tid, resume] of Object.entries(cmd.resume)) {
        const existing = pendingWrites.filter((w) => w[0] === tid && w[1] === RESUME2).map((w) => w[2]).slice(0, 1) ?? [];
        existing.push(resume);
        yield [tid, RESUME2, existing];
      }
    } else {
      yield [NULL_TASK_ID, RESUME2, cmd.resume];
    }
  }
  if (cmd.update) {
    if (typeof cmd.update !== "object" || !cmd.update) {
      throw new Error("Expected cmd.update to be a dict mapping channel names to update values");
    }
    if (Array.isArray(cmd.update)) {
      for (const [k, v] of cmd.update) {
        yield [NULL_TASK_ID, k, v];
      }
    } else {
      for (const [k, v] of Object.entries(cmd.update)) {
        yield [NULL_TASK_ID, k, v];
      }
    }
  }
}
function* mapInput(inputChannels, chunk) {
  if (chunk !== void 0 && chunk !== null) {
    if (Array.isArray(inputChannels) && typeof chunk === "object" && !Array.isArray(chunk)) {
      for (const k in chunk) {
        if (inputChannels.includes(k)) {
          yield [k, chunk[k]];
        }
      }
    } else if (Array.isArray(inputChannels)) {
      throw new Error(`Input chunk must be an object when "inputChannels" is an array`);
    } else {
      yield [inputChannels, chunk];
    }
  }
}
function* mapOutputValues(outputChannels, pendingWrites, channels) {
  if (Array.isArray(outputChannels)) {
    if (pendingWrites === true || pendingWrites.find(([chan, _]) => outputChannels.includes(chan))) {
      yield readChannels(channels, outputChannels);
    }
  } else {
    if (pendingWrites === true || pendingWrites.some(([chan, _]) => chan === outputChannels)) {
      yield readChannel(channels, outputChannels);
    }
  }
}
function* mapOutputUpdates(outputChannels, tasks, cached) {
  const outputTasks = tasks.filter(([task2, ww]) => {
    var _a2;
    return (task2.config === void 0 || !((_a2 = task2.config.tags) == null ? void 0 : _a2.includes(TAG_HIDDEN))) && ww[0][0] !== ERROR3 && ww[0][0] !== INTERRUPT2;
  });
  if (!outputTasks.length) {
    return;
  }
  let updated;
  if (outputTasks.some(([task2]) => task2.writes.some(([chan, _]) => chan === RETURN))) {
    updated = outputTasks.flatMap(([task2]) => task2.writes.filter(([chan, _]) => chan === RETURN).map(([_, value]) => [task2.name, value]));
  } else if (!Array.isArray(outputChannels)) {
    updated = outputTasks.flatMap(([task2]) => task2.writes.filter(([chan, _]) => chan === outputChannels).map(([_, value]) => [task2.name, value]));
  } else {
    updated = outputTasks.flatMap(([task2]) => {
      const { writes } = task2;
      const counts = {};
      for (const [chan] of writes) {
        if (outputChannels.includes(chan)) {
          counts[chan] = (counts[chan] || 0) + 1;
        }
      }
      if (Object.values(counts).some((count) => count > 1)) {
        return writes.filter(([chan]) => outputChannels.includes(chan)).map(([chan, value]) => [task2.name, { [chan]: value }]);
      } else {
        return [
          [
            task2.name,
            Object.fromEntries(writes.filter(([chan]) => outputChannels.includes(chan)))
          ]
        ];
      }
    });
  }
  const grouped = {};
  for (const [node, value] of updated) {
    if (!(node in grouped)) {
      grouped[node] = [];
    }
    grouped[node].push(value);
  }
  const flattened = {};
  for (const node in grouped) {
    if (grouped[node].length === 1) {
      const [write] = grouped[node];
      flattened[node] = write;
    } else {
      flattened[node] = grouped[node];
    }
  }
  if (cached) {
    flattened["__metadata__"] = { cached };
  }
  yield flattened;
}

// node_modules/@langchain/langgraph/dist/pregel/types.js
var Call = class {
  constructor({ func, name, input, retry, cache: cache2, callbacks }) {
    Object.defineProperty(this, "func", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "input", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "retry", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "callbacks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "__lg_type", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "call"
    });
    this.func = func;
    this.name = name;
    this.input = input;
    this.retry = retry;
    this.cache = cache2;
    this.callbacks = callbacks;
  }
};
function isCall(value) {
  return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "call";
}

// node_modules/@langchain/langgraph/dist/pregel/utils/index.js
function getNullChannelVersion(currentVersions) {
  const startVersion = typeof currentVersions[START];
  if (startVersion === "number")
    return 0;
  if (startVersion === "string")
    return "";
  for (const key in currentVersions) {
    if (!Object.prototype.hasOwnProperty.call(currentVersions, key))
      continue;
    const versionType = typeof currentVersions[key];
    if (versionType === "number")
      return 0;
    if (versionType === "string")
      return "";
    break;
  }
  return void 0;
}
function getNewChannelVersions(previousVersions, currentVersions) {
  if (Object.keys(previousVersions).length > 0) {
    const nullVersion = getNullChannelVersion(currentVersions);
    return Object.fromEntries(Object.entries(currentVersions).filter(([k, v]) => v > (previousVersions[k] ?? nullVersion)));
  } else {
    return currentVersions;
  }
}
function _coerceToDict2(value, defaultKey) {
  return value && !Array.isArray(value) && // eslint-disable-next-line no-instanceof/no-instanceof
  !(value instanceof Date) && typeof value === "object" ? value : { [defaultKey]: value };
}
function patchConfigurable2(config, patch) {
  if (config === null) {
    return { configurable: patch };
  } else if ((config == null ? void 0 : config.configurable) === void 0) {
    return { ...config, configurable: patch };
  } else {
    return {
      ...config,
      configurable: { ...config.configurable, ...patch }
    };
  }
}
function patchCheckpointMap(config, metadata) {
  var _a2, _b;
  const parents = (metadata == null ? void 0 : metadata.parents) ?? {};
  if (Object.keys(parents).length > 0) {
    return patchConfigurable2(config, {
      [CONFIG_KEY_CHECKPOINT_MAP]: {
        ...parents,
        [((_a2 = config.configurable) == null ? void 0 : _a2.checkpoint_ns) ?? ""]: (_b = config.configurable) == null ? void 0 : _b.checkpoint_id
      }
    });
  } else {
    return config;
  }
}
function combineAbortSignals(...x) {
  const signals = [...new Set(x.filter(Boolean))];
  if (signals.length === 0) {
    return { signal: void 0, dispose: void 0 };
  }
  if (signals.length === 1) {
    return { signal: signals[0], dispose: void 0 };
  }
  const combinedController = new AbortController();
  const listener = () => {
    var _a2;
    const reason = (_a2 = signals.find((s) => s.aborted)) == null ? void 0 : _a2.reason;
    combinedController.abort(reason);
    signals.forEach((s) => s.removeEventListener("abort", listener));
  };
  signals.forEach((s) => s.addEventListener("abort", listener, { once: true }));
  const hasAlreadyAbortedSignal = signals.find((s) => s.aborted);
  if (hasAlreadyAbortedSignal) {
    combinedController.abort(hasAlreadyAbortedSignal.reason);
  }
  return {
    signal: combinedController.signal,
    dispose: () => {
      signals.forEach((s) => s.removeEventListener("abort", listener));
    }
  };
}
var combineCallbacks = (callback1, callback2) => {
  if (!callback1 && !callback2) {
    return void 0;
  }
  if (!callback1) {
    return callback2;
  }
  if (!callback2) {
    return callback1;
  }
  if (Array.isArray(callback1) && Array.isArray(callback2)) {
    return [...callback1, ...callback2];
  }
  if (Array.isArray(callback1)) {
    return [...callback1, callback2];
  }
  if (Array.isArray(callback2)) {
    return [callback1, ...callback2];
  }
  return [callback1, callback2];
};

// node_modules/@langchain/langgraph/dist/pregel/call.js
function getRunnableForFunc(name, func) {
  const run = new RunnableCallable({
    func: (input) => func(...input),
    name,
    trace: false,
    recurse: false
  });
  return new RunnableSequence({
    name,
    first: run,
    last: new ChannelWrite([{ channel: RETURN, value: PASSTHROUGH }], [TAG_HIDDEN])
  });
}
function getRunnableForEntrypoint(name, func) {
  const run = new RunnableCallable({
    func: (input, config) => {
      return func(input, config);
    },
    name,
    trace: false,
    recurse: false
  });
  return run;
}
function call({ func, name, cache: cache2, retry }, ...args) {
  var _a2;
  const config = AsyncLocalStorageProviderSingleton.getRunnableConfig();
  if (typeof ((_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_CALL]) === "function") {
    return config.configurable[CONFIG_KEY_CALL](func, name, args, {
      retry,
      cache: cache2,
      callbacks: config.callbacks
    });
  }
  throw new Error("Async local storage not initialized. Please call initializeAsyncLocalStorageSingleton() before using this function.");
}

// node_modules/@langchain/langgraph/dist/pregel/algo.js
var increment = (current) => {
  return current !== void 0 ? current + 1 : 1;
};
function maxChannelMapVersion(channelVersions) {
  let maxVersion;
  for (const chan in channelVersions) {
    if (!Object.prototype.hasOwnProperty.call(channelVersions, chan))
      continue;
    if (maxVersion == null) {
      maxVersion = channelVersions[chan];
    } else {
      maxVersion = maxChannelVersion(maxVersion, channelVersions[chan]);
    }
  }
  return maxVersion;
}
function shouldInterrupt(checkpoint, interruptNodes, tasks) {
  const nullVersion = getNullChannelVersion(checkpoint.channel_versions);
  const seen = checkpoint.versions_seen[INTERRUPT2] ?? {};
  let anyChannelUpdated = false;
  for (const chan in checkpoint.channel_versions) {
    if (!Object.prototype.hasOwnProperty.call(checkpoint.channel_versions, chan))
      continue;
    if (checkpoint.channel_versions[chan] > (seen[chan] ?? nullVersion)) {
      anyChannelUpdated = true;
      break;
    }
  }
  const anyTriggeredNodeInInterruptNodes = tasks.some((task2) => {
    var _a2, _b;
    return interruptNodes === "*" ? !((_b = (_a2 = task2.config) == null ? void 0 : _a2.tags) == null ? void 0 : _b.includes(TAG_HIDDEN)) : interruptNodes.includes(task2.name);
  });
  return anyChannelUpdated && anyTriggeredNodeInInterruptNodes;
}
function _localRead(checkpoint, channels, task2, select, fresh = false) {
  let updated = /* @__PURE__ */ new Set();
  if (!Array.isArray(select)) {
    for (const [c] of task2.writes) {
      if (c === select) {
        updated = /* @__PURE__ */ new Set([c]);
        break;
      }
    }
    updated = updated || /* @__PURE__ */ new Set();
  } else {
    updated = new Set(select.filter((c) => task2.writes.some(([key, _]) => key === c)));
  }
  let values;
  if (fresh && updated.size > 0) {
    const localChannels = Object.fromEntries(Object.entries(channels).filter(([k, _]) => updated.has(k)));
    const newCheckpoint = createCheckpoint(checkpoint, localChannels, -1);
    const newChannels = emptyChannels(localChannels, newCheckpoint);
    _applyWrites(copyCheckpoint(newCheckpoint), newChannels, [task2], void 0, void 0);
    values = readChannels({ ...channels, ...newChannels }, select);
  } else {
    values = readChannels(channels, select);
  }
  return values;
}
function _localWrite(commit, processes, writes) {
  for (const [chan, value] of writes) {
    if ([PUSH, TASKS2].includes(chan) && value != null) {
      if (!_isSend(value)) {
        throw new InvalidUpdateError(`Invalid packet type, expected SendProtocol, got ${JSON.stringify(value)}`);
      }
      if (!(value.node in processes)) {
        throw new InvalidUpdateError(`Invalid node name "${value.node}" in Send packet`);
      }
    }
  }
  commit(writes);
}
var IGNORE = /* @__PURE__ */ new Set([
  NO_WRITES,
  PUSH,
  RESUME2,
  INTERRUPT2,
  RETURN,
  ERROR3
]);
function _applyWrites(checkpoint, channels, tasks, getNextVersion, triggerToNodes) {
  var _a2, _b;
  tasks.sort((a, b) => {
    var _a3, _b2;
    const aPath = ((_a3 = a.path) == null ? void 0 : _a3.slice(0, 3)) || [];
    const bPath = ((_b2 = b.path) == null ? void 0 : _b2.slice(0, 3)) || [];
    for (let i = 0; i < Math.min(aPath.length, bPath.length); i += 1) {
      if (aPath[i] < bPath[i])
        return -1;
      if (aPath[i] > bPath[i])
        return 1;
    }
    return aPath.length - bPath.length;
  });
  const bumpStep = tasks.some((task2) => task2.triggers.length > 0);
  const onlyChannels = getOnlyChannels(channels);
  for (const task2 of tasks) {
    (_a2 = checkpoint.versions_seen)[_b = task2.name] ?? (_a2[_b] = {});
    for (const chan of task2.triggers) {
      if (chan in checkpoint.channel_versions) {
        checkpoint.versions_seen[task2.name][chan] = checkpoint.channel_versions[chan];
      }
    }
  }
  let maxVersion = maxChannelMapVersion(checkpoint.channel_versions);
  const channelsToConsume = new Set(tasks.flatMap((task2) => task2.triggers).filter((chan) => !RESERVED.includes(chan)));
  for (const chan of channelsToConsume) {
    if (chan in onlyChannels && onlyChannels[chan].consume()) {
      if (getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
      }
    }
  }
  const pendingWritesByChannel = {};
  for (const task2 of tasks) {
    for (const [chan, val] of task2.writes) {
      if (IGNORE.has(chan)) {
      } else if (chan in onlyChannels) {
        pendingWritesByChannel[chan] ?? (pendingWritesByChannel[chan] = []);
        pendingWritesByChannel[chan].push(val);
      }
    }
  }
  maxVersion = maxChannelMapVersion(checkpoint.channel_versions);
  const updatedChannels = /* @__PURE__ */ new Set();
  for (const [chan, vals] of Object.entries(pendingWritesByChannel)) {
    if (chan in onlyChannels) {
      const channel = onlyChannels[chan];
      let updated;
      try {
        updated = channel.update(vals);
      } catch (e) {
        if (e.name === InvalidUpdateError.unminifiable_name) {
          const wrappedError = new InvalidUpdateError(`Invalid update for channel "${chan}" with values ${JSON.stringify(vals)}: ${e.message}`);
          wrappedError.lc_error_code = e.lc_error_code;
          throw wrappedError;
        } else {
          throw e;
        }
      }
      if (updated && getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
        if (channel.isAvailable())
          updatedChannels.add(chan);
      }
    }
  }
  if (bumpStep) {
    for (const chan in onlyChannels) {
      if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan))
        continue;
      const channel = onlyChannels[chan];
      if (channel.isAvailable() && !updatedChannels.has(chan)) {
        const updated = channel.update([]);
        if (updated && getNextVersion !== void 0) {
          checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
          if (channel.isAvailable())
            updatedChannels.add(chan);
        }
      }
    }
  }
  if (bumpStep && !Object.keys(triggerToNodes ?? {}).some((channel) => updatedChannels.has(channel))) {
    for (const chan in onlyChannels) {
      if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan))
        continue;
      const channel = onlyChannels[chan];
      if (channel.finish() && getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
        if (channel.isAvailable())
          updatedChannels.add(chan);
      }
    }
  }
}
function _prepareNextTasks(checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {
  const tasks = {};
  const tasksChannel = channels[TASKS2];
  if (tasksChannel == null ? void 0 : tasksChannel.isAvailable()) {
    const len = tasksChannel.get().length;
    for (let i = 0; i < len; i += 1) {
      const task2 = _prepareSingleTask([PUSH, i], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);
      if (task2 !== void 0) {
        tasks[task2.id] = task2;
      }
    }
  }
  for (const name in processes) {
    if (!Object.prototype.hasOwnProperty.call(processes, name))
      continue;
    const task2 = _prepareSingleTask([PULL, name], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);
    if (task2 !== void 0) {
      tasks[task2.id] = task2;
    }
  }
  return tasks;
}
function _prepareSingleTask(taskPath, checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {
  var _a2, _b, _c, _d;
  const { step, checkpointer, manager } = extra;
  const configurable = config.configurable ?? {};
  const parentNamespace = configurable.checkpoint_ns ?? "";
  if (taskPath[0] === PUSH && isCall(taskPath[taskPath.length - 1])) {
    const call3 = taskPath[taskPath.length - 1];
    const proc = getRunnableForFunc(call3.name, call3.func);
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? call3.name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${call3.name}`;
    const id = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      call3.name,
      PUSH,
      taskPath[1],
      taskPath[2]
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${id}`;
    const outputTaskPath = [...taskPath.slice(0, 3), true];
    const metadata = {
      langgraph_step: step,
      langgraph_node: call3.name,
      langgraph_triggers: triggers,
      langgraph_path: outputTaskPath,
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const writes = [];
      const task2 = {
        name: call3.name,
        input: call3.input,
        proc,
        writes,
        config: patchConfig(mergeConfigs(config, {
          metadata,
          store: extra.store ?? config.store
        }), {
          runName: call3.name,
          callbacks: manager == null ? void 0 : manager.getChild(`graph:step:${step}`),
          configurable: {
            [CONFIG_KEY_TASK_ID]: id,
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),
            [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
              name: call3.name,
              writes,
              triggers,
              path: outputTaskPath
            }, select_, fresh_),
            [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
            [CONFIG_KEY_CHECKPOINT_MAP]: {
              ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
              [parentNamespace]: checkpoint.id
            },
            [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
              pendingWrites: pendingWrites ?? [],
              taskId: id,
              currentTaskInput: call3.input,
              resumeMap: (_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_RESUME_MAP],
              namespaceHash: XXH3(taskCheckpointNamespace)
            }),
            [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
            checkpoint_id: void 0,
            checkpoint_ns: taskCheckpointNamespace
          }
        }),
        triggers,
        retry_policy: call3.retry,
        cache_key: call3.cache ? {
          key: XXH3((call3.cache.keyFunc ?? JSON.stringify)([call3.input])),
          ns: [CACHE_NS_WRITES, call3.name ?? "__dynamic__"],
          ttl: call3.cache.ttl
        } : void 0,
        id,
        path: outputTaskPath,
        writers: []
      };
      return task2;
    } else {
      return {
        id,
        name: call3.name,
        interrupts: [],
        path: outputTaskPath
      };
    }
  } else if (taskPath[0] === PUSH) {
    const index = typeof taskPath[1] === "number" ? taskPath[1] : parseInt(taskPath[1], 10);
    if (!((_b = channels[TASKS2]) == null ? void 0 : _b.isAvailable())) {
      return void 0;
    }
    const sends = channels[TASKS2].get();
    if (index < 0 || index >= sends.length) {
      return void 0;
    }
    const packet = _isSendInterface(sends[index]) && !_isSend(sends[index]) ? new Send(sends[index].node, sends[index].args) : sends[index];
    if (!_isSendInterface(packet)) {
      console.warn(`Ignoring invalid packet ${JSON.stringify(packet)} in pending sends.`);
      return void 0;
    }
    if (!(packet.node in processes)) {
      console.warn(`Ignoring unknown node name ${packet.node} in pending sends.`);
      return void 0;
    }
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? packet.node : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${packet.node}`;
    const taskId = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      packet.node,
      PUSH,
      index.toString()
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
    let metadata = {
      langgraph_step: step,
      langgraph_node: packet.node,
      langgraph_triggers: triggers,
      langgraph_path: taskPath.slice(0, 3),
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const proc = processes[packet.node];
      const node = proc.getNode();
      if (node !== void 0) {
        if (proc.metadata !== void 0) {
          metadata = { ...metadata, ...proc.metadata };
        }
        const writes = [];
        return {
          name: packet.node,
          input: packet.args,
          proc: node,
          subgraphs: proc.subgraphs,
          writes,
          config: patchConfig(mergeConfigs(config, {
            metadata,
            tags: proc.tags,
            store: extra.store ?? config.store
          }), {
            runName: packet.node,
            callbacks: manager == null ? void 0 : manager.getChild(`graph:step:${step}`),
            configurable: {
              [CONFIG_KEY_TASK_ID]: taskId,
              // eslint-disable-next-line @typescript-eslint/no-explicit-any
              [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),
              [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
                name: packet.node,
                writes,
                triggers,
                path: taskPath
              }, select_, fresh_),
              [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
              [CONFIG_KEY_CHECKPOINT_MAP]: {
                ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                [parentNamespace]: checkpoint.id
              },
              [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                pendingWrites: pendingWrites ?? [],
                taskId,
                currentTaskInput: packet.args,
                resumeMap: (_c = config.configurable) == null ? void 0 : _c[CONFIG_KEY_RESUME_MAP],
                namespaceHash: XXH3(taskCheckpointNamespace)
              }),
              [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
              checkpoint_id: void 0,
              checkpoint_ns: taskCheckpointNamespace
            }
          }),
          triggers,
          retry_policy: proc.retryPolicy,
          cache_key: proc.cachePolicy ? {
            key: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([packet.args])),
            ns: [CACHE_NS_WRITES, proc.name ?? "__dynamic__", packet.node],
            ttl: proc.cachePolicy.ttl
          } : void 0,
          id: taskId,
          path: taskPath,
          writers: proc.getWriters()
        };
      }
    } else {
      return {
        id: taskId,
        name: packet.node,
        interrupts: [],
        path: taskPath
      };
    }
  } else if (taskPath[0] === PULL) {
    const name = taskPath[1].toString();
    const proc = processes[name];
    if (proc === void 0) {
      return void 0;
    }
    if (pendingWrites == null ? void 0 : pendingWrites.length) {
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        name
      ]), checkpoint.id);
      const hasSuccessfulWrites = pendingWrites.some((w) => w[0] === taskId && w[1] !== ERROR3);
      if (hasSuccessfulWrites) {
        return void 0;
      }
    }
    const nullVersion = getNullChannelVersion(checkpoint.channel_versions);
    if (nullVersion === void 0) {
      return void 0;
    }
    const seen = checkpoint.versions_seen[name] ?? {};
    const trigger = proc.triggers.find((chan) => {
      if (!channels[chan].isAvailable())
        return false;
      return (checkpoint.channel_versions[chan] ?? nullVersion) > (seen[chan] ?? nullVersion);
    });
    if (trigger !== void 0) {
      const val = _procInput(proc, channels, forExecution);
      if (val === void 0) {
        return void 0;
      }
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        [trigger]
      ]), checkpoint.id);
      const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
      let metadata = {
        langgraph_step: step,
        langgraph_node: name,
        langgraph_triggers: [trigger],
        langgraph_path: taskPath,
        langgraph_checkpoint_ns: taskCheckpointNamespace
      };
      if (forExecution) {
        const node = proc.getNode();
        if (node !== void 0) {
          if (proc.metadata !== void 0) {
            metadata = { ...metadata, ...proc.metadata };
          }
          const writes = [];
          return {
            name,
            input: val,
            proc: node,
            subgraphs: proc.subgraphs,
            writes,
            config: patchConfig(mergeConfigs(config, {
              metadata,
              tags: proc.tags,
              store: extra.store ?? config.store
            }), {
              runName: name,
              callbacks: manager == null ? void 0 : manager.getChild(`graph:step:${step}`),
              configurable: {
                [CONFIG_KEY_TASK_ID]: taskId,
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => {
                  writes.push(...items);
                }, processes, writes_),
                [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
                  name,
                  writes,
                  triggers: [trigger],
                  path: taskPath
                }, select_, fresh_),
                [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
                [CONFIG_KEY_CHECKPOINT_MAP]: {
                  ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                  [parentNamespace]: checkpoint.id
                },
                [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                  pendingWrites: pendingWrites ?? [],
                  taskId,
                  currentTaskInput: val,
                  resumeMap: (_d = config.configurable) == null ? void 0 : _d[CONFIG_KEY_RESUME_MAP],
                  namespaceHash: XXH3(taskCheckpointNamespace)
                }),
                [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
                checkpoint_id: void 0,
                checkpoint_ns: taskCheckpointNamespace
              }
            }),
            triggers: [trigger],
            retry_policy: proc.retryPolicy,
            cache_key: proc.cachePolicy ? {
              key: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([val])),
              ns: [CACHE_NS_WRITES, proc.name ?? "__dynamic__", name],
              ttl: proc.cachePolicy.ttl
            } : void 0,
            id: taskId,
            path: taskPath,
            writers: proc.getWriters()
          };
        }
      } else {
        return {
          id: taskId,
          name,
          interrupts: [],
          path: taskPath
        };
      }
    }
  }
  return void 0;
}
function _procInput(proc, channels, forExecution) {
  let val;
  if (typeof proc.channels === "object" && !Array.isArray(proc.channels)) {
    val = {};
    for (const [k, chan] of Object.entries(proc.channels)) {
      if (proc.triggers.includes(chan)) {
        try {
          val[k] = readChannel(channels, chan, false);
        } catch (e) {
          if (e.name === EmptyChannelError.unminifiable_name) {
            return void 0;
          } else {
            throw e;
          }
        }
      } else if (chan in channels) {
        try {
          val[k] = readChannel(channels, chan, false);
        } catch (e) {
          if (e.name === EmptyChannelError.unminifiable_name) {
            continue;
          } else {
            throw e;
          }
        }
      }
    }
  } else if (Array.isArray(proc.channels)) {
    let successfulRead = false;
    for (const chan of proc.channels) {
      try {
        val = readChannel(channels, chan, false);
        successfulRead = true;
        break;
      } catch (e) {
        if (e.name === EmptyChannelError.unminifiable_name) {
          continue;
        } else {
          throw e;
        }
      }
    }
    if (!successfulRead) {
      return void 0;
    }
  } else {
    throw new Error(`Invalid channels type, expected list or dict, got ${proc.channels}`);
  }
  if (forExecution && proc.mapper !== void 0) {
    val = proc.mapper(val);
  }
  return val;
}
function _scratchpad({ pendingWrites, taskId, currentTaskInput, resumeMap, namespaceHash }) {
  var _a2;
  const nullResume = (_a2 = pendingWrites.find(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2)) == null ? void 0 : _a2[2];
  const resume = (() => {
    const result = pendingWrites.filter(([writeTaskId, chan]) => writeTaskId === taskId && chan === RESUME2).flatMap(([_writeTaskId, _chan, resume2]) => resume2);
    if (resumeMap != null && namespaceHash in resumeMap) {
      const mappedResume = resumeMap[namespaceHash];
      result.push(mappedResume);
    }
    return result;
  })();
  const scratchpad = {
    callCounter: 0,
    interruptCounter: -1,
    resume,
    nullResume,
    subgraphCounter: 0,
    currentTaskInput,
    consumeNullResume: () => {
      if (scratchpad.nullResume) {
        delete scratchpad.nullResume;
        pendingWrites.splice(pendingWrites.findIndex(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2), 1);
        return nullResume;
      }
      return void 0;
    }
  };
  return scratchpad;
}

// node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.js
function isRunnableSequence(x) {
  return "steps" in x && Array.isArray(x.steps);
}
function isPregelLike(x) {
  return "lg_is_pregel" in x && x.lg_is_pregel === true;
}
function findSubgraphPregel(candidate) {
  const candidates = [candidate];
  for (const candidate2 of candidates) {
    if (isPregelLike(candidate2)) {
      return candidate2;
    } else if (isRunnableSequence(candidate2)) {
      candidates.push(...candidate2.steps);
    }
  }
  return void 0;
}

// node_modules/@langchain/langgraph/dist/pregel/debug.js
var COLORS_MAP = {
  blue: {
    start: "\x1B[34m",
    end: "\x1B[0m"
  },
  green: {
    start: "\x1B[32m",
    end: "\x1B[0m"
  },
  yellow: {
    start: "\x1B[33;1m",
    end: "\x1B[0m"
  }
};
var wrap = (color, text) => `${color.start}${text}${color.end}`;
function* mapDebugTasks(tasks) {
  var _a2;
  for (const { id, name, input, config, triggers, writes } of tasks) {
    if ((_a2 = config == null ? void 0 : config.tags) == null ? void 0 : _a2.includes(TAG_HIDDEN))
      continue;
    const interrupts = writes.filter(([writeId, n2]) => {
      return writeId === id && n2 === INTERRUPT2;
    }).map(([, v]) => {
      return v;
    });
    yield { id, name, input, triggers, interrupts };
  }
}
function isMultipleChannelWrite(value) {
  if (typeof value !== "object" || value === null)
    return false;
  return "$writes" in value && Array.isArray(value.$writes);
}
function mapTaskResultWrites(writes) {
  const result = {};
  for (const [channel, value] of writes) {
    const strChannel = String(channel);
    if (strChannel in result) {
      const channelWrites = isMultipleChannelWrite(result[strChannel]) ? result[strChannel].$writes : [result[strChannel]];
      channelWrites.push(value);
      result[strChannel] = { $writes: channelWrites };
    } else {
      result[strChannel] = value;
    }
  }
  return result;
}
function* mapDebugTaskResults(tasks, streamChannels) {
  var _a2;
  for (const [{ id, name, config }, writes] of tasks) {
    if ((_a2 = config == null ? void 0 : config.tags) == null ? void 0 : _a2.includes(TAG_HIDDEN))
      continue;
    yield {
      id,
      name,
      result: mapTaskResultWrites(writes.filter(([channel]) => {
        return Array.isArray(streamChannels) ? streamChannels.includes(channel) : channel === streamChannels;
      })),
      interrupts: writes.filter((w) => w[0] === INTERRUPT2).map((w) => w[1])
    };
  }
}
function* mapDebugCheckpoint(config, channels, streamChannels, metadata, tasks, pendingWrites, parentConfig, outputKeys) {
  var _a2, _b, _c;
  function formatConfig(config2) {
    const pyConfig = {};
    if (config2.callbacks != null)
      pyConfig.callbacks = config2.callbacks;
    if (config2.configurable != null)
      pyConfig.configurable = config2.configurable;
    if (config2.maxConcurrency != null)
      pyConfig.max_concurrency = config2.maxConcurrency;
    if (config2.metadata != null)
      pyConfig.metadata = config2.metadata;
    if (config2.recursionLimit != null)
      pyConfig.recursion_limit = config2.recursionLimit;
    if (config2.runId != null)
      pyConfig.run_id = config2.runId;
    if (config2.runName != null)
      pyConfig.run_name = config2.runName;
    if (config2.tags != null)
      pyConfig.tags = config2.tags;
    return pyConfig;
  }
  const parentNs = (_a2 = config.configurable) == null ? void 0 : _a2.checkpoint_ns;
  const taskStates = {};
  for (const task2 of tasks) {
    const candidates = ((_b = task2.subgraphs) == null ? void 0 : _b.length) ? task2.subgraphs : [task2.proc];
    if (!candidates.find(findSubgraphPregel))
      continue;
    let taskNs = `${task2.name}:${task2.id}`;
    if (parentNs)
      taskNs = `${parentNs}|${taskNs}`;
    taskStates[task2.id] = {
      configurable: {
        thread_id: (_c = config.configurable) == null ? void 0 : _c.thread_id,
        checkpoint_ns: taskNs
      }
    };
  }
  yield {
    config: formatConfig(config),
    values: readChannels(channels, streamChannels),
    metadata,
    next: tasks.map((task2) => task2.name),
    tasks: tasksWithWrites(tasks, pendingWrites, taskStates, outputKeys),
    parentConfig: parentConfig ? formatConfig(parentConfig) : void 0
  };
}
function tasksWithWrites(tasks, pendingWrites, states, outputKeys) {
  return tasks.map((task2) => {
    var _a2;
    const error = (_a2 = pendingWrites.find(([id, n2]) => id === task2.id && n2 === ERROR3)) == null ? void 0 : _a2[2];
    const interrupts = pendingWrites.filter(([id, n2]) => id === task2.id && n2 === INTERRUPT2).map(([, , v]) => v);
    const result = (() => {
      var _a3;
      if (error || interrupts.length || !pendingWrites.length)
        return void 0;
      const idx = pendingWrites.findIndex(([tid, n2]) => tid === task2.id && n2 === RETURN);
      if (idx >= 0)
        return pendingWrites[idx][2];
      if (typeof outputKeys === "string") {
        return (_a3 = pendingWrites.find(([tid, n2]) => tid === task2.id && n2 === outputKeys)) == null ? void 0 : _a3[2];
      }
      if (Array.isArray(outputKeys)) {
        const results = pendingWrites.filter(([tid, n2]) => tid === task2.id && outputKeys.includes(n2)).map(([, n2, v]) => [n2, v]);
        if (!results.length)
          return void 0;
        return mapTaskResultWrites(results);
      }
      return void 0;
    })();
    if (error) {
      return {
        id: task2.id,
        name: task2.name,
        path: task2.path,
        error,
        interrupts,
        result
      };
    }
    const taskState = states == null ? void 0 : states[task2.id];
    return {
      id: task2.id,
      name: task2.name,
      path: task2.path,
      interrupts,
      ...taskState !== void 0 ? { state: taskState } : {},
      result
    };
  });
}
function printStepCheckpoint(step, channels, whitelist) {
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:checkpoint]`)}`,
    `\x1B[1m State at the end of step ${step}:\x1B[0m
`,
    JSON.stringify(readChannels(channels, whitelist), null, 2)
  ].join(""));
}
function printStepTasks(step, nextTasks) {
  const nTasks = nextTasks.length;
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:tasks]`)}`,
    `\x1B[1m Starting step ${step} with ${nTasks} task${nTasks === 1 ? "" : "s"}:\x1B[0m
`,
    nextTasks.map((task2) => `- ${wrap(COLORS_MAP.green, String(task2.name))} -> ${JSON.stringify(task2.input, null, 2)}`).join("\n")
  ].join(""));
}
function printStepWrites(step, writes, whitelist) {
  const byChannel = {};
  for (const [channel, value] of writes) {
    if (whitelist.includes(channel)) {
      if (!byChannel[channel]) {
        byChannel[channel] = [];
      }
      byChannel[channel].push(value);
    }
  }
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:writes]`)}`,
    `\x1B[1m Finished step ${step} with writes to ${Object.keys(byChannel).length} channel${Object.keys(byChannel).length !== 1 ? "s" : ""}:\x1B[0m
`,
    Object.entries(byChannel).map(([name, vals]) => `- ${wrap(COLORS_MAP.yellow, name)} -> ${vals.map((v) => JSON.stringify(v)).join(", ")}`).join("\n")
  ].join(""));
}

// node_modules/@langchain/langgraph/dist/pregel/stream.js
var IterableReadableStreamWithAbortSignal = class extends IterableReadableStream {
  /**
   * @param readableStream - The stream to wrap.
   * @param abortController - The abort controller to use. Optional. One will be created if not provided.
   */
  constructor(readableStream, abortController) {
    const reader = readableStream.getReader();
    const ac = abortController ?? new AbortController();
    super({
      start(controller) {
        return pump();
        function pump() {
          return reader.read().then(({ done, value }) => {
            if (done) {
              controller.close();
              return;
            }
            controller.enqueue(value);
            return pump();
          });
        }
      }
    });
    Object.defineProperty(this, "_abortController", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_innerReader", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this._abortController = ac;
    this._innerReader = reader;
  }
  /**
   * Aborts the stream, abandoning any pending operations in progress. Calling this triggers an
   * {@link AbortSignal} that is propagated to the tasks that are producing the data for this stream.
   * @param reason - The reason for aborting the stream. Optional.
   */
  async cancel(reason) {
    this._abortController.abort(reason);
    this._innerReader.releaseLock();
  }
  /**
   * The {@link AbortSignal} for the stream. Aborted when {@link cancel} is called.
   */
  get signal() {
    return this._abortController.signal;
  }
};
var IterableReadableWritableStream = class extends IterableReadableStream {
  get closed() {
    return this._closed;
  }
  constructor(params) {
    let streamControllerPromiseResolver;
    const streamControllerPromise = new Promise((resolve) => {
      streamControllerPromiseResolver = resolve;
    });
    super({
      start: (controller) => {
        streamControllerPromiseResolver(controller);
      }
    });
    Object.defineProperty(this, "modes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "controller", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "passthroughFn", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_closed", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    void streamControllerPromise.then((controller) => {
      this.controller = controller;
    });
    this.passthroughFn = params.passthroughFn;
    this.modes = params.modes;
  }
  push(chunk) {
    var _a2;
    (_a2 = this.passthroughFn) == null ? void 0 : _a2.call(this, chunk);
    this.controller.enqueue(chunk);
  }
  close() {
    try {
      this.controller.close();
    } catch (e) {
    } finally {
      this._closed = true;
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  error(e) {
    this.controller.error(e);
  }
};

// node_modules/@langchain/langgraph/dist/pregel/loop.js
var INPUT_DONE = Symbol.for("INPUT_DONE");
var INPUT_RESUMING = Symbol.for("INPUT_RESUMING");
var DEFAULT_LOOP_LIMIT = 25;
function createDuplexStream(...streams) {
  return new IterableReadableWritableStream({
    passthroughFn: (value) => {
      for (const stream of streams) {
        if (stream.modes.has(value[1])) {
          stream.push(value);
        }
      }
    },
    modes: new Set(streams.flatMap((s) => Array.from(s.modes)))
  });
}
var AsyncBatchedCache = class extends BaseCache2 {
  constructor(cache2) {
    super();
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "queue", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: Promise.resolve()
    });
    this.cache = cache2;
  }
  async get(keys) {
    return this.enqueueOperation("get", keys);
  }
  async set(pairs) {
    return this.enqueueOperation("set", pairs);
  }
  async clear(namespaces) {
    return this.enqueueOperation("clear", namespaces);
  }
  async stop() {
    await this.queue;
  }
  enqueueOperation(type, ...args) {
    const newPromise = this.queue.then(() => {
      return this.cache[type](...args);
    });
    this.queue = newPromise.then(() => void 0, () => void 0);
    return newPromise;
  }
};
var PregelLoop = class _PregelLoop {
  get isResuming() {
    var _a2, _b, _c, _d, _e;
    let hasChannelVersions = false;
    if (START in this.checkpoint.channel_versions) {
      hasChannelVersions = true;
    } else {
      for (const chan in this.checkpoint.channel_versions) {
        if (Object.prototype.hasOwnProperty.call(this.checkpoint.channel_versions, chan)) {
          hasChannelVersions = true;
          break;
        }
      }
    }
    const configHasResumingFlag = ((_a2 = this.config.configurable) == null ? void 0 : _a2[CONFIG_KEY_RESUMING]) !== void 0;
    const configIsResuming = configHasResumingFlag && ((_b = this.config.configurable) == null ? void 0 : _b[CONFIG_KEY_RESUMING]);
    const inputIsNullOrUndefined = this.input === null || this.input === void 0;
    const inputIsCommandResuming = isCommand(this.input) && this.input.resume != null;
    const inputIsResuming = this.input === INPUT_RESUMING;
    const runIdMatchesPrevious = !this.isNested && ((_c = this.config.metadata) == null ? void 0 : _c.run_id) !== void 0 && ((_d = this.checkpointMetadata) == null ? void 0 : _d.run_id) !== void 0 && this.config.metadata.run_id === ((_e = this.checkpointMetadata) == null ? void 0 : _e.run_id);
    return hasChannelVersions && (configIsResuming || inputIsNullOrUndefined || inputIsCommandResuming || inputIsResuming || runIdMatchesPrevious);
  }
  constructor(params) {
    Object.defineProperty(this, "input", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "output", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointer", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointerGetNextVersion", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointIdSaved", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointMetadata", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointNamespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointPendingWrites", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "checkpointPreviousVersions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "step", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stop", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "durability", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "streamKeys", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "skipDoneTasks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "prevCheckpointConfig", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "status", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "pending"
    });
    Object.defineProperty(this, "tasks", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "stream", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "checkpointerPromises", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "isNested", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_checkpointerChainedPromise", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: Promise.resolve()
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "manager", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptAfter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptBefore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "toInterrupt", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    Object.defineProperty(this, "debug", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "triggerToNodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.input = params.input;
    this.checkpointer = params.checkpointer;
    if (this.checkpointer !== void 0) {
      this.checkpointerGetNextVersion = this.checkpointer.getNextVersion.bind(this.checkpointer);
    } else {
      this.checkpointerGetNextVersion = increment;
    }
    this.checkpoint = params.checkpoint;
    this.checkpointMetadata = params.checkpointMetadata;
    this.checkpointPreviousVersions = params.checkpointPreviousVersions;
    this.channels = params.channels;
    this.checkpointPendingWrites = params.checkpointPendingWrites;
    this.step = params.step;
    this.stop = params.stop;
    this.config = params.config;
    this.checkpointConfig = params.checkpointConfig;
    this.isNested = params.isNested;
    this.manager = params.manager;
    this.outputKeys = params.outputKeys;
    this.streamKeys = params.streamKeys;
    this.nodes = params.nodes;
    this.skipDoneTasks = params.skipDoneTasks;
    this.store = params.store;
    this.cache = params.cache ? new AsyncBatchedCache(params.cache) : void 0;
    this.stream = params.stream;
    this.checkpointNamespace = params.checkpointNamespace;
    this.prevCheckpointConfig = params.prevCheckpointConfig;
    this.interruptAfter = params.interruptAfter;
    this.interruptBefore = params.interruptBefore;
    this.durability = params.durability;
    this.debug = params.debug;
    this.triggerToNodes = params.triggerToNodes;
  }
  static async initialize(params) {
    var _a2, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l;
    let { config, stream } = params;
    if (stream !== void 0 && ((_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_STREAM]) !== void 0) {
      stream = createDuplexStream(stream, config.configurable[CONFIG_KEY_STREAM]);
    }
    const skipDoneTasks = config.configurable ? !("checkpoint_id" in config.configurable) : true;
    const scratchpad = (_b = config.configurable) == null ? void 0 : _b[CONFIG_KEY_SCRATCHPAD];
    if (config.configurable && scratchpad) {
      if (scratchpad.subgraphCounter > 0) {
        config = patchConfigurable2(config, {
          [CONFIG_KEY_CHECKPOINT_NS]: [
            config.configurable[CONFIG_KEY_CHECKPOINT_NS],
            scratchpad.subgraphCounter.toString()
          ].join(CHECKPOINT_NAMESPACE_SEPARATOR)
        });
      }
      scratchpad.subgraphCounter += 1;
    }
    const isNested = CONFIG_KEY_READ in (config.configurable ?? {});
    if (!isNested && ((_c = config.configurable) == null ? void 0 : _c.checkpoint_ns) !== void 0 && ((_d = config.configurable) == null ? void 0 : _d.checkpoint_ns) !== "") {
      config = patchConfigurable2(config, {
        checkpoint_ns: "",
        checkpoint_id: void 0
      });
    }
    let checkpointConfig = config;
    if (((_e = config.configurable) == null ? void 0 : _e[CONFIG_KEY_CHECKPOINT_MAP]) !== void 0 && ((_h = (_f = config.configurable) == null ? void 0 : _f[CONFIG_KEY_CHECKPOINT_MAP]) == null ? void 0 : _h[(_g = config.configurable) == null ? void 0 : _g.checkpoint_ns])) {
      checkpointConfig = patchConfigurable2(config, {
        checkpoint_id: config.configurable[CONFIG_KEY_CHECKPOINT_MAP][(_i = config.configurable) == null ? void 0 : _i.checkpoint_ns]
      });
    }
    const checkpointNamespace = ((_k = (_j = config.configurable) == null ? void 0 : _j.checkpoint_ns) == null ? void 0 : _k.split(CHECKPOINT_NAMESPACE_SEPARATOR)) ?? [];
    const saved = await ((_l = params.checkpointer) == null ? void 0 : _l.getTuple(checkpointConfig)) ?? {
      config,
      checkpoint: emptyCheckpoint(),
      metadata: { source: "input", step: -2, parents: {} },
      pendingWrites: []
    };
    checkpointConfig = {
      ...config,
      ...saved.config,
      configurable: {
        checkpoint_ns: "",
        ...config.configurable,
        ...saved.config.configurable
      }
    };
    const prevCheckpointConfig = saved.parentConfig;
    const checkpoint = copyCheckpoint(saved.checkpoint);
    const checkpointMetadata = { ...saved.metadata };
    const checkpointPendingWrites = saved.pendingWrites ?? [];
    const channels = emptyChannels(params.channelSpecs, checkpoint);
    const step = (checkpointMetadata.step ?? 0) + 1;
    const stop = step + (config.recursionLimit ?? DEFAULT_LOOP_LIMIT) + 1;
    const checkpointPreviousVersions = { ...checkpoint.channel_versions };
    const store = params.store ? new AsyncBatchedStore(params.store) : void 0;
    if (store) {
      await store.start();
    }
    return new _PregelLoop({
      input: params.input,
      config,
      checkpointer: params.checkpointer,
      checkpoint,
      checkpointMetadata,
      checkpointConfig,
      prevCheckpointConfig,
      checkpointNamespace,
      channels,
      isNested,
      manager: params.manager,
      skipDoneTasks,
      step,
      stop,
      checkpointPreviousVersions,
      checkpointPendingWrites,
      outputKeys: params.outputKeys ?? [],
      streamKeys: params.streamKeys ?? [],
      nodes: params.nodes,
      stream,
      store,
      cache: params.cache,
      interruptAfter: params.interruptAfter,
      interruptBefore: params.interruptBefore,
      durability: params.durability,
      debug: params.debug,
      triggerToNodes: params.triggerToNodes
    });
  }
  _checkpointerPutAfterPrevious(input) {
    this._checkpointerChainedPromise = this._checkpointerChainedPromise.then(() => {
      var _a2;
      return (_a2 = this.checkpointer) == null ? void 0 : _a2.put(input.config, input.checkpoint, input.metadata, input.newVersions);
    });
    this.checkpointerPromises.push(this._checkpointerChainedPromise);
  }
  /**
   * Put writes for a task, to be read by the next tick.
   * @param taskId
   * @param writes
   */
  putWrites(taskId, writes) {
    var _a2;
    let writesCopy = writes;
    if (writesCopy.length === 0)
      return;
    if (writesCopy.every(([key]) => key in WRITES_IDX_MAP)) {
      writesCopy = Array.from(new Map(writesCopy.map((w) => [w[0], w])).values());
    }
    this.checkpointPendingWrites = this.checkpointPendingWrites.filter((w) => w[0] !== taskId);
    for (const [c, v] of writesCopy) {
      this.checkpointPendingWrites.push([taskId, c, v]);
    }
    const config = patchConfigurable2(this.checkpointConfig, {
      [CONFIG_KEY_CHECKPOINT_NS]: ((_a2 = this.config.configurable) == null ? void 0 : _a2.checkpoint_ns) ?? "",
      [CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
    });
    if (this.durability !== "exit" && this.checkpointer != null) {
      this.checkpointerPromises.push(this.checkpointer.putWrites(config, writesCopy, taskId));
    }
    if (this.tasks) {
      this._outputWrites(taskId, writesCopy);
    }
    if (!writes.length || !this.cache || !this.tasks) {
      return;
    }
    const task2 = this.tasks[taskId];
    if (task2 == null || task2.cache_key == null) {
      return;
    }
    if (writes[0][0] === ERROR3 || writes[0][0] === INTERRUPT2) {
      return;
    }
    void this.cache.set([
      {
        key: [task2.cache_key.ns, task2.cache_key.key],
        value: task2.writes,
        ttl: task2.cache_key.ttl
      }
    ]);
  }
  _outputWrites(taskId, writes, cached = false) {
    var _a2, _b;
    const task2 = this.tasks[taskId];
    if (task2 !== void 0) {
      if (task2.config !== void 0 && (task2.config.tags ?? []).includes(TAG_HIDDEN)) {
        return;
      }
      if (writes.length > 0) {
        if (writes[0][0] === INTERRUPT2) {
          if (((_a2 = task2.path) == null ? void 0 : _a2[0]) === PUSH && ((_b = task2.path) == null ? void 0 : _b.at(-1)) === true)
            return;
          const interruptWrites = writes.filter((w) => w[0] === INTERRUPT2).flatMap((w) => w[1]);
          this._emit([
            ["updates", { [INTERRUPT2]: interruptWrites }],
            ["values", { [INTERRUPT2]: interruptWrites }]
          ]);
        } else if (writes[0][0] !== ERROR3) {
          this._emit(gatherIteratorSync(prefixGenerator(mapOutputUpdates(this.outputKeys, [[task2, writes]], cached), "updates")));
        }
      }
      if (!cached) {
        this._emit(gatherIteratorSync(prefixGenerator(mapDebugTaskResults([[task2, writes]], this.streamKeys), "tasks")));
      }
    }
  }
  async _matchCachedWrites() {
    if (!this.cache)
      return [];
    const matched = [];
    const serializeKey = ([ns, key]) => {
      return `ns:${ns.join(",")}|key:${key}`;
    };
    const keys = [];
    const keyMap = {};
    for (const task2 of Object.values(this.tasks)) {
      if (task2.cache_key != null && !task2.writes.length) {
        keys.push([task2.cache_key.ns, task2.cache_key.key]);
        keyMap[serializeKey([task2.cache_key.ns, task2.cache_key.key])] = task2;
      }
    }
    if (keys.length === 0)
      return [];
    const cache2 = await this.cache.get(keys);
    for (const { key, value } of cache2) {
      const task2 = keyMap[serializeKey(key)];
      if (task2 != null) {
        task2.writes.push(...value);
        matched.push({ task: task2, result: value });
      }
    }
    return matched;
  }
  /**
   * Execute a single iteration of the Pregel loop.
   * Returns true if more iterations are needed.
   * @param params
   */
  async tick(params) {
    var _a2, _b, _c;
    if (this.store && !this.store.isRunning) {
      await ((_a2 = this.store) == null ? void 0 : _a2.start());
    }
    const { inputKeys = [] } = params;
    if (this.status !== "pending") {
      throw new Error(`Cannot tick when status is no longer "pending". Current status: "${this.status}"`);
    }
    if (![INPUT_DONE, INPUT_RESUMING].includes(this.input)) {
      await this._first(inputKeys);
    } else if (this.toInterrupt.length > 0) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    } else if (Object.values(this.tasks).every((task2) => task2.writes.length > 0)) {
      const writes = Object.values(this.tasks).flatMap((t) => t.writes);
      _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, writes, this.channels), "values"));
      this._emit(valuesOutput);
      this.checkpointPendingWrites = [];
      await this._putCheckpoint({ source: "loop" });
      if (shouldInterrupt(this.checkpoint, this.interruptAfter, Object.values(this.tasks))) {
        this.status = "interrupt_after";
        throw new GraphInterrupt();
      }
      if (((_b = this.config.configurable) == null ? void 0 : _b[CONFIG_KEY_RESUMING]) !== void 0) {
        (_c = this.config.configurable) == null ? true : delete _c[CONFIG_KEY_RESUMING];
      }
    } else {
      return false;
    }
    if (this.step > this.stop) {
      this.status = "out_of_steps";
      return false;
    }
    const nextTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      isResuming: this.isResuming,
      manager: this.manager,
      store: this.store,
      stream: this.stream
    });
    this.tasks = nextTasks;
    if (this.checkpointer) {
      this._emit(await gatherIterator(prefixGenerator(mapDebugCheckpoint(this.checkpointConfig, this.channels, this.streamKeys, this.checkpointMetadata, Object.values(this.tasks), this.checkpointPendingWrites, this.prevCheckpointConfig, this.outputKeys), "checkpoints")));
    }
    if (Object.values(this.tasks).length === 0) {
      this.status = "done";
      return false;
    }
    if (this.skipDoneTasks && this.checkpointPendingWrites.length > 0) {
      for (const [tid, k, v] of this.checkpointPendingWrites) {
        if (k === ERROR3 || k === INTERRUPT2 || k === RESUME2) {
          continue;
        }
        const task2 = Object.values(this.tasks).find((t) => t.id === tid);
        if (task2) {
          task2.writes.push([k, v]);
        }
      }
      for (const task2 of Object.values(this.tasks)) {
        if (task2.writes.length > 0) {
          this._outputWrites(task2.id, task2.writes, true);
        }
      }
    }
    if (Object.values(this.tasks).every((task2) => task2.writes.length > 0)) {
      return this.tick({ inputKeys });
    }
    if (shouldInterrupt(this.checkpoint, this.interruptBefore, Object.values(this.tasks))) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    }
    const debugOutput = await gatherIterator(prefixGenerator(mapDebugTasks(Object.values(this.tasks)), "tasks"));
    this._emit(debugOutput);
    return true;
  }
  async finishAndHandleError(error) {
    if (this.durability === "exit" && // if it's a top graph
    (!this.isNested || // or a nested graph with error or interrupt
    typeof error !== "undefined" || // or a nested graph with checkpointer: true
    this.checkpointNamespace.every((part) => !part.includes(CHECKPOINT_NAMESPACE_END)))) {
      this._putCheckpoint(this.checkpointMetadata);
      this._flushPendingWrites();
    }
    const suppress = this._suppressInterrupt(error);
    if (suppress || error === void 0) {
      this.output = readChannels(this.channels, this.outputKeys);
    }
    if (suppress) {
      if (this.tasks !== void 0 && this.checkpointPendingWrites.length > 0 && Object.values(this.tasks).some((task2) => task2.writes.length > 0)) {
        _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
        this._emit(gatherIteratorSync(prefixGenerator(mapOutputValues(this.outputKeys, Object.values(this.tasks).flatMap((t) => t.writes), this.channels), "values")));
      }
      if (isGraphInterrupt(error) && !error.interrupts.length) {
        this._emit([
          ["updates", { [INTERRUPT2]: [] }],
          ["values", { [INTERRUPT2]: [] }]
        ]);
      }
    }
    return suppress;
  }
  async acceptPush(task2, writeIdx, call3) {
    var _a2, _b;
    if (((_a2 = this.interruptAfter) == null ? void 0 : _a2.length) > 0 && shouldInterrupt(this.checkpoint, this.interruptAfter, [task2])) {
      this.toInterrupt.push(task2);
      return;
    }
    const pushed = _prepareSingleTask([PUSH, task2.path ?? [], writeIdx, task2.id, call3], this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, task2.config ?? {}, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      manager: this.manager,
      store: this.store,
      stream: this.stream
    });
    if (!pushed)
      return;
    if (((_b = this.interruptBefore) == null ? void 0 : _b.length) > 0 && shouldInterrupt(this.checkpoint, this.interruptBefore, [pushed])) {
      this.toInterrupt.push(pushed);
      return;
    }
    this._emit(gatherIteratorSync(prefixGenerator(mapDebugTasks([pushed]), "tasks")));
    if (this.debug)
      printStepTasks(this.step, [pushed]);
    this.tasks[pushed.id] = pushed;
    if (this.skipDoneTasks)
      this._matchWrites({ [pushed.id]: pushed });
    const tasks = await this._matchCachedWrites();
    for (const { task: task3 } of tasks) {
      this._outputWrites(task3.id, task3.writes, true);
    }
    return pushed;
  }
  _suppressInterrupt(e) {
    return isGraphInterrupt(e) && !this.isNested;
  }
  async _first(inputKeys) {
    var _a2;
    const { configurable } = this.config;
    const scratchpad = configurable == null ? void 0 : configurable[CONFIG_KEY_SCRATCHPAD];
    if (scratchpad && scratchpad.nullResume !== void 0) {
      this.putWrites(NULL_TASK_ID, [[RESUME2, scratchpad.nullResume]]);
    }
    if (isCommand(this.input)) {
      const hasResume = this.input.resume != null;
      if (this.input.resume != null && typeof this.input.resume === "object" && Object.keys(this.input.resume).every(isXXH3)) {
        (_a2 = this.config).configurable ?? (_a2.configurable = {});
        this.config.configurable[CONFIG_KEY_RESUME_MAP] = this.input.resume;
      }
      if (hasResume && this.checkpointer == null) {
        throw new Error("Cannot use Command(resume=...) without checkpointer");
      }
      const writes = {};
      for (const [tid, key, value] of mapCommand(this.input, this.checkpointPendingWrites)) {
        writes[tid] ?? (writes[tid] = []);
        writes[tid].push([key, value]);
      }
      if (Object.keys(writes).length === 0) {
        throw new EmptyInputError("Received empty Command input");
      }
      for (const [tid, ws] of Object.entries(writes)) {
        this.putWrites(tid, ws);
      }
    }
    const nullWrites = (this.checkpointPendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
    if (nullWrites.length > 0) {
      _applyWrites(this.checkpoint, this.channels, [
        {
          name: INPUT,
          writes: nullWrites,
          triggers: []
        }
      ], this.checkpointerGetNextVersion, this.triggerToNodes);
    }
    const isCommandUpdateOrGoto = isCommand(this.input) && nullWrites.length > 0;
    if (this.isResuming || isCommandUpdateOrGoto) {
      for (const channelName in this.channels) {
        if (!Object.prototype.hasOwnProperty.call(this.channels, channelName))
          continue;
        if (this.checkpoint.channel_versions[channelName] !== void 0) {
          const version = this.checkpoint.channel_versions[channelName];
          this.checkpoint.versions_seen[INTERRUPT2] = {
            ...this.checkpoint.versions_seen[INTERRUPT2],
            [channelName]: version
          };
        }
      }
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, true, this.channels), "values"));
      this._emit(valuesOutput);
    }
    if (this.isResuming) {
      this.input = INPUT_RESUMING;
    } else if (isCommandUpdateOrGoto) {
      await this._putCheckpoint({ source: "input" });
      this.input = INPUT_DONE;
    } else {
      const inputWrites = await gatherIterator(mapInput(inputKeys, this.input));
      if (inputWrites.length > 0) {
        const discardTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, { step: this.step });
        _applyWrites(this.checkpoint, this.channels, Object.values(discardTasks).concat([
          {
            name: INPUT,
            writes: inputWrites,
            triggers: []
          }
        ]), this.checkpointerGetNextVersion, this.triggerToNodes);
        await this._putCheckpoint({ source: "input" });
        this.input = INPUT_DONE;
      } else if (!(CONFIG_KEY_RESUMING in (this.config.configurable ?? {}))) {
        throw new EmptyInputError(`Received no input writes for ${JSON.stringify(inputKeys, null, 2)}`);
      } else {
        this.input = INPUT_DONE;
      }
    }
    if (!this.isNested) {
      this.config = patchConfigurable2(this.config, {
        [CONFIG_KEY_RESUMING]: this.isResuming
      });
    }
  }
  _emit(values) {
    for (const [mode, payload] of values) {
      if (this.stream.modes.has(mode)) {
        this.stream.push([this.checkpointNamespace, mode, payload]);
      }
      if ((mode === "checkpoints" || mode === "tasks") && this.stream.modes.has("debug")) {
        const step = mode === "checkpoints" ? this.step - 1 : this.step;
        const timestamp = (/* @__PURE__ */ new Date()).toISOString();
        const type = (() => {
          if (mode === "checkpoints") {
            return "checkpoint";
          } else if (typeof payload === "object" && payload != null && "result" in payload) {
            return "task_result";
          } else {
            return "task";
          }
        })();
        this.stream.push([
          this.checkpointNamespace,
          "debug",
          { step, type, timestamp, payload }
        ]);
      }
    }
  }
  _putCheckpoint(inputMetadata) {
    var _a2;
    const exiting = this.checkpointMetadata === inputMetadata;
    const doCheckpoint = this.checkpointer != null && (this.durability !== "exit" || exiting);
    const storeCheckpoint = (checkpoint) => {
      var _a3, _b, _c;
      this.prevCheckpointConfig = ((_b = (_a3 = this.checkpointConfig) == null ? void 0 : _a3.configurable) == null ? void 0 : _b.checkpoint_id) ? this.checkpointConfig : void 0;
      this.checkpointConfig = patchConfigurable2(this.checkpointConfig, {
        [CONFIG_KEY_CHECKPOINT_NS]: ((_c = this.config.configurable) == null ? void 0 : _c.checkpoint_ns) ?? ""
      });
      const channelVersions = { ...this.checkpoint.channel_versions };
      const newVersions = getNewChannelVersions(this.checkpointPreviousVersions, channelVersions);
      this.checkpointPreviousVersions = channelVersions;
      void this._checkpointerPutAfterPrevious({
        config: { ...this.checkpointConfig },
        checkpoint: copyCheckpoint(checkpoint),
        metadata: { ...this.checkpointMetadata },
        newVersions
      });
      this.checkpointConfig = {
        ...this.checkpointConfig,
        configurable: {
          ...this.checkpointConfig.configurable,
          checkpoint_id: this.checkpoint.id
        }
      };
    };
    if (!exiting) {
      this.checkpointMetadata = {
        ...inputMetadata,
        step: this.step,
        parents: ((_a2 = this.config.configurable) == null ? void 0 : _a2[CONFIG_KEY_CHECKPOINT_MAP]) ?? {}
      };
    }
    this.checkpoint = createCheckpoint(this.checkpoint, doCheckpoint ? this.channels : void 0, this.step, exiting ? { id: this.checkpoint.id } : void 0);
    if (doCheckpoint)
      storeCheckpoint(this.checkpoint);
    if (!exiting) {
      this.step += 1;
    }
  }
  _flushPendingWrites() {
    var _a2;
    if (this.checkpointer == null)
      return;
    if (this.checkpointPendingWrites.length === 0)
      return;
    const config = patchConfigurable2(this.checkpointConfig, {
      [CONFIG_KEY_CHECKPOINT_NS]: ((_a2 = this.config.configurable) == null ? void 0 : _a2.checkpoint_ns) ?? "",
      [CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
    });
    const byTask = {};
    for (const [tid, key, value] of this.checkpointPendingWrites) {
      byTask[tid] ?? (byTask[tid] = []);
      byTask[tid].push([key, value]);
    }
    for (const [tid, ws] of Object.entries(byTask)) {
      this.checkpointerPromises.push(this.checkpointer.putWrites(config, ws, tid));
    }
  }
  _matchWrites(tasks) {
    for (const [tid, k, v] of this.checkpointPendingWrites) {
      if (k === ERROR3 || k === INTERRUPT2 || k === RESUME2) {
        continue;
      }
      const task2 = Object.values(tasks).find((t) => t.id === tid);
      if (task2) {
        task2.writes.push([k, v]);
      }
    }
    for (const task2 of Object.values(tasks)) {
      if (task2.writes.length > 0) {
        this._outputWrites(task2.id, task2.writes, true);
      }
    }
  }
};

// node_modules/@langchain/langgraph/dist/pregel/messages.js
function isChatGenerationChunk(x) {
  return isBaseMessage(x == null ? void 0 : x.message);
}
var StreamMessagesHandler = class extends BaseCallbackHandler {
  constructor(streamFn) {
    super();
    Object.defineProperty(this, "name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "StreamMessagesHandler"
    });
    Object.defineProperty(this, "streamFn", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "metadatas", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "emittedChatModelRunIds", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "stableMessageIdMap", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "lc_prefer_streaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.streamFn = streamFn;
  }
  _emit(meta, message, runId, dedupe = false) {
    var _a2;
    if (dedupe && message.id !== void 0 && this.seen[message.id] !== void 0) {
      return;
    }
    let messageId = message.id;
    if (runId != null) {
      if (isToolMessage(message)) {
        messageId ?? (messageId = `run-${runId}-tool-${message.tool_call_id}`);
      } else {
        if (messageId == null || messageId === `run-${runId}`) {
          messageId = this.stableMessageIdMap[runId] ?? messageId ?? `run-${runId}`;
        }
        (_a2 = this.stableMessageIdMap)[runId] ?? (_a2[runId] = messageId);
      }
    }
    if (messageId !== message.id) {
      message.id = messageId;
      message.lc_kwargs.id = messageId;
    }
    if (message.id != null)
      this.seen[message.id] = message;
    this.streamFn([meta[0], "messages", [message, meta[1]]]);
  }
  handleChatModelStart(_llm, _messages, runId, _parentRunId, _extraParams, tags, metadata, name) {
    if (metadata && // Include legacy LangGraph SDK tag
    (!tags || !tags.includes(TAG_NOSTREAM) && !tags.includes("nostream"))) {
      this.metadatas[runId] = [
        metadata.langgraph_checkpoint_ns.split("|"),
        { tags, name, ...metadata }
      ];
    }
  }
  handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, fields) {
    const chunk = fields == null ? void 0 : fields.chunk;
    this.emittedChatModelRunIds[runId] = true;
    if (this.metadatas[runId] !== void 0) {
      if (isChatGenerationChunk(chunk)) {
        this._emit(this.metadatas[runId], chunk.message, runId);
      } else {
        this._emit(this.metadatas[runId], new AIMessageChunk({ content: token }), runId);
      }
    }
  }
  handleLLMEnd(output, runId) {
    var _a2, _b;
    if (this.metadatas[runId] === void 0)
      return;
    if (!this.emittedChatModelRunIds[runId]) {
      const chatGeneration = (_b = (_a2 = output.generations) == null ? void 0 : _a2[0]) == null ? void 0 : _b[0];
      if (isBaseMessage(chatGeneration == null ? void 0 : chatGeneration.message)) {
        this._emit(this.metadatas[runId], chatGeneration == null ? void 0 : chatGeneration.message, runId, true);
      }
      delete this.emittedChatModelRunIds[runId];
    }
    delete this.metadatas[runId];
    delete this.stableMessageIdMap[runId];
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  handleLLMError(_err, runId) {
    delete this.metadatas[runId];
  }
  handleChainStart(_chain, inputs, runId, _parentRunId, tags, metadata, _runType, name) {
    if (metadata !== void 0 && name === metadata.langgraph_node && (tags === void 0 || !tags.includes(TAG_HIDDEN))) {
      this.metadatas[runId] = [
        metadata.langgraph_checkpoint_ns.split("|"),
        { tags, name, ...metadata }
      ];
      if (typeof inputs === "object") {
        for (const value of Object.values(inputs)) {
          if ((isBaseMessage(value) || isBaseMessageChunk(value)) && value.id !== void 0) {
            this.seen[value.id] = value;
          } else if (Array.isArray(value)) {
            for (const item of value) {
              if ((isBaseMessage(item) || isBaseMessageChunk(item)) && item.id !== void 0) {
                this.seen[item.id] = item;
              }
            }
          }
        }
      }
    }
  }
  handleChainEnd(outputs, runId) {
    const metadata = this.metadatas[runId];
    delete this.metadatas[runId];
    if (metadata !== void 0) {
      if (isBaseMessage(outputs)) {
        this._emit(metadata, outputs, runId, true);
      } else if (Array.isArray(outputs)) {
        for (const value of outputs) {
          if (isBaseMessage(value)) {
            this._emit(metadata, value, runId, true);
          }
        }
      } else if (outputs != null && typeof outputs === "object") {
        for (const value of Object.values(outputs)) {
          if (isBaseMessage(value)) {
            this._emit(metadata, value, runId, true);
          } else if (Array.isArray(value)) {
            for (const item of value) {
              if (isBaseMessage(item)) {
                this._emit(metadata, item, runId, true);
              }
            }
          }
        }
      }
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  handleChainError(_err, runId) {
    delete this.metadatas[runId];
  }
};

// node_modules/@langchain/langgraph/dist/pregel/retry.js
var DEFAULT_INITIAL_INTERVAL = 500;
var DEFAULT_BACKOFF_FACTOR = 2;
var DEFAULT_MAX_INTERVAL = 128e3;
var DEFAULT_MAX_RETRIES = 3;
var DEFAULT_STATUS_NO_RETRY = [
  400,
  // Bad Request
  401,
  // Unauthorized
  402,
  // Payment Required
  403,
  // Forbidden
  404,
  // Not Found
  405,
  // Method Not Allowed
  406,
  // Not Acceptable
  407,
  // Proxy Authentication Required
  409
  // Conflict
];
var DEFAULT_RETRY_ON_HANDLER = (error) => {
  var _a2, _b;
  if (error.message.startsWith("Cancel") || error.message.startsWith("AbortError") || error.name === "AbortError") {
    return false;
  }
  if (error.name === "GraphValueError") {
    return false;
  }
  if ((error == null ? void 0 : error.code) === "ECONNABORTED") {
    return false;
  }
  const status = (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    ((_a2 = error == null ? void 0 : error.response) == null ? void 0 : _a2.status) ?? (error == null ? void 0 : error.status)
  );
  if (status && DEFAULT_STATUS_NO_RETRY.includes(+status)) {
    return false;
  }
  if (((_b = error == null ? void 0 : error.error) == null ? void 0 : _b.code) === "insufficient_quota") {
    return false;
  }
  return true;
};
async function _runWithRetry(pregelTask, retryPolicy, configurable, signal) {
  var _a2;
  const resolvedRetryPolicy = pregelTask.retry_policy ?? retryPolicy;
  let interval = resolvedRetryPolicy !== void 0 ? resolvedRetryPolicy.initialInterval ?? DEFAULT_INITIAL_INTERVAL : 0;
  let attempts = 0;
  let error;
  let result;
  let { config } = pregelTask;
  if (configurable)
    config = patchConfigurable2(config, configurable);
  config = { ...config, signal };
  while (true) {
    if (signal == null ? void 0 : signal.aborted) {
      break;
    }
    pregelTask.writes.splice(0, pregelTask.writes.length);
    error = void 0;
    try {
      result = await pregelTask.proc.invoke(pregelTask.input, config);
      break;
    } catch (e) {
      error = e;
      error.pregelTaskId = pregelTask.id;
      if (isParentCommand(error)) {
        const ns = (_a2 = config == null ? void 0 : config.configurable) == null ? void 0 : _a2.checkpoint_ns;
        const cmd = error.command;
        if (cmd.graph === ns) {
          for (const writer of pregelTask.writers) {
            await writer.invoke(cmd, config);
          }
          error = void 0;
          break;
        } else if (cmd.graph === Command.PARENT) {
          const parentNs = getParentCheckpointNamespace(ns);
          error.command = new Command({
            ...error.command,
            graph: parentNs
          });
        }
      }
      if (isGraphBubbleUp(error)) {
        break;
      }
      if (resolvedRetryPolicy === void 0) {
        break;
      }
      attempts += 1;
      if (attempts >= (resolvedRetryPolicy.maxAttempts ?? DEFAULT_MAX_RETRIES)) {
        break;
      }
      const retryOn = resolvedRetryPolicy.retryOn ?? DEFAULT_RETRY_ON_HANDLER;
      if (!retryOn(error)) {
        break;
      }
      interval = Math.min(resolvedRetryPolicy.maxInterval ?? DEFAULT_MAX_INTERVAL, interval * (resolvedRetryPolicy.backoffFactor ?? DEFAULT_BACKOFF_FACTOR));
      const intervalWithJitter = resolvedRetryPolicy.jitter ? Math.floor(interval + Math.random() * 1e3) : interval;
      await new Promise((resolve) => setTimeout(resolve, intervalWithJitter));
      const errorName = error.name ?? // eslint-disable-next-line @typescript-eslint/no-explicit-any
      error.constructor.unminifiable_name ?? error.constructor.name;
      if ((resolvedRetryPolicy == null ? void 0 : resolvedRetryPolicy.logWarning) ?? true) {
        console.log(`Retrying task "${String(pregelTask.name)}" after ${interval.toFixed(2)}ms (attempt ${attempts}) after ${errorName}: ${error}`);
      }
      config = patchConfigurable2(config, { [CONFIG_KEY_RESUMING]: true });
    }
  }
  return {
    task: pregelTask,
    result,
    error,
    signalAborted: signal == null ? void 0 : signal.aborted
  };
}

// node_modules/@langchain/langgraph/dist/pregel/runner.js
var PROMISE_ADDED_SYMBOL = Symbol.for("promiseAdded");
function createPromiseBarrier() {
  const barrier = {
    next: () => void 0,
    wait: Promise.resolve(PROMISE_ADDED_SYMBOL)
  };
  function waitHandler(resolve) {
    barrier.next = () => {
      barrier.wait = new Promise(waitHandler);
      resolve(PROMISE_ADDED_SYMBOL);
    };
  }
  barrier.wait = new Promise(waitHandler);
  return barrier;
}
var PregelRunner = class {
  /**
   * Construct a new PregelRunner, which executes tasks from the provided PregelLoop.
   * @param loop - The PregelLoop that produces tasks for this runner to execute.
   */
  constructor({ loop, nodeFinished }) {
    Object.defineProperty(this, "nodeFinished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "loop", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.loop = loop;
    this.nodeFinished = nodeFinished;
  }
  /**
   * Execute tasks from the current step of the PregelLoop.
   *
   * Note: this method does NOT call {@link PregelLoop}#tick. That must be handled externally.
   * @param options - Options for the execution.
   */
  async tick(options = {}) {
    const { timeout, retryPolicy, onStepWrite, maxConcurrency } = options;
    const nodeErrors = /* @__PURE__ */ new Set();
    let graphBubbleUp;
    const exceptionSignalController = new AbortController();
    const exceptionSignal = exceptionSignalController.signal;
    const stepTimeoutSignal = timeout ? AbortSignal.timeout(timeout) : void 0;
    const pendingTasks = Object.values(this.loop.tasks).filter((t) => t.writes.length === 0);
    const { signals, disposeCombinedSignal } = this._initializeAbortSignals({
      exceptionSignal,
      stepTimeoutSignal,
      signal: options.signal
    });
    const taskStream = this._executeTasksWithRetry(pendingTasks, {
      signals,
      retryPolicy,
      maxConcurrency
    });
    for await (const { task: task2, error, signalAborted } of taskStream) {
      this._commit(task2, error);
      if (isGraphInterrupt(error)) {
        graphBubbleUp = error;
      } else if (isGraphBubbleUp(error) && !isGraphInterrupt(graphBubbleUp)) {
        graphBubbleUp = error;
      } else if (error && (nodeErrors.size === 0 || !signalAborted)) {
        exceptionSignalController.abort();
        nodeErrors.add(error);
      }
    }
    disposeCombinedSignal == null ? void 0 : disposeCombinedSignal();
    onStepWrite == null ? void 0 : onStepWrite(this.loop.step, Object.values(this.loop.tasks).map((task2) => task2.writes).flat());
    if (nodeErrors.size === 1) {
      throw Array.from(nodeErrors)[0];
    } else if (nodeErrors.size > 1) {
      throw new AggregateError(Array.from(nodeErrors), `Multiple errors occurred during superstep ${this.loop.step}. See the "errors" field of this exception for more details.`);
    }
    if (isGraphInterrupt(graphBubbleUp)) {
      throw graphBubbleUp;
    }
    if (isGraphBubbleUp(graphBubbleUp) && this.loop.isNested) {
      throw graphBubbleUp;
    }
  }
  /**
   * Initializes the current AbortSignals for the PregelRunner, handling the various ways that
   * AbortSignals must be chained together so that the PregelLoop can be interrupted if necessary
   * while still allowing nodes to gracefully exit.
   *
   * This method must only be called once per PregelRunner#tick. It has the side effect of updating
   * the PregelLoop#config with the new AbortSignals so they may be propagated correctly to future
   * ticks and subgraph calls.
   *
   * @param options - Options for the initialization.
   * @returns The current abort signals.
   * @internal
   */
  _initializeAbortSignals({ exceptionSignal, stepTimeoutSignal, signal }) {
    var _a2;
    const previousSignals = ((_a2 = this.loop.config.configurable) == null ? void 0 : _a2[CONFIG_KEY_ABORT_SIGNALS]) ?? {};
    const externalAbortSignal = previousSignals.externalAbortSignal ?? signal;
    const timeoutAbortSignal = stepTimeoutSignal ?? previousSignals.timeoutAbortSignal;
    const { signal: composedAbortSignal, dispose: disposeCombinedSignal } = combineAbortSignals(externalAbortSignal, timeoutAbortSignal, exceptionSignal);
    const signals = {
      externalAbortSignal,
      timeoutAbortSignal,
      composedAbortSignal
    };
    this.loop.config = patchConfigurable2(this.loop.config, {
      [CONFIG_KEY_ABORT_SIGNALS]: signals
    });
    return { signals, disposeCombinedSignal };
  }
  /**
   * Concurrently executes tasks with the requested retry policy, yielding a {@link SettledPregelTask} for each task as it completes.
   * @param tasks - The tasks to execute.
   * @param options - Options for the execution.
   */
  async *_executeTasksWithRetry(tasks, options) {
    var _a2, _b, _c;
    const { retryPolicy, maxConcurrency, signals } = options ?? {};
    const barrier = createPromiseBarrier();
    const executingTasksMap = {};
    const thisCall = {
      executingTasksMap,
      barrier,
      retryPolicy,
      scheduleTask: async (task2, writeIdx, call3) => this.loop.acceptPush(task2, writeIdx, call3)
    };
    if ((_a2 = signals == null ? void 0 : signals.composedAbortSignal) == null ? void 0 : _a2.aborted) {
      throw new Error("Abort");
    }
    let startedTasksCount = 0;
    let listener;
    const timeoutOrCancelSignal = combineAbortSignals(signals == null ? void 0 : signals.externalAbortSignal, signals == null ? void 0 : signals.timeoutAbortSignal);
    const abortPromise = timeoutOrCancelSignal.signal ? new Promise((_resolve, reject) => {
      var _a3;
      listener = () => reject(new Error("Abort"));
      (_a3 = timeoutOrCancelSignal.signal) == null ? void 0 : _a3.addEventListener("abort", listener, {
        once: true
      });
    }) : void 0;
    while ((startedTasksCount === 0 || Object.keys(executingTasksMap).length > 0) && tasks.length) {
      for (; Object.values(executingTasksMap).length < (maxConcurrency ?? tasks.length) && startedTasksCount < tasks.length; startedTasksCount += 1) {
        const task2 = tasks[startedTasksCount];
        executingTasksMap[task2.id] = _runWithRetry(task2, retryPolicy, { [CONFIG_KEY_CALL]: call2 == null ? void 0 : call2.bind(thisCall, this, task2) }, signals == null ? void 0 : signals.composedAbortSignal).catch((error) => {
          var _a3;
          return {
            task: task2,
            error,
            signalAborted: (_a3 = signals == null ? void 0 : signals.composedAbortSignal) == null ? void 0 : _a3.aborted
          };
        });
      }
      const settledTask = await Promise.race([
        ...Object.values(executingTasksMap),
        ...abortPromise ? [abortPromise] : [],
        barrier.wait
      ]);
      if (settledTask === PROMISE_ADDED_SYMBOL) {
        continue;
      }
      yield settledTask;
      if (listener != null) {
        (_b = timeoutOrCancelSignal.signal) == null ? void 0 : _b.removeEventListener("abort", listener);
        (_c = timeoutOrCancelSignal.dispose) == null ? void 0 : _c.call(timeoutOrCancelSignal);
      }
      delete executingTasksMap[settledTask.task.id];
    }
  }
  /**
   * Determines what writes to apply based on whether the task completed successfully, and what type of error occurred.
   *
   * Throws an error if the error is a {@link GraphBubbleUp} error and {@link PregelLoop}#isNested is true.
   *
   * @param task - The task to commit.
   * @param error - The error that occurred, if any.
   */
  _commit(task2, error) {
    var _a2;
    if (error !== void 0) {
      if (isGraphInterrupt(error)) {
        if (error.interrupts.length) {
          const interrupts = error.interrupts.map((interrupt) => [INTERRUPT2, interrupt]);
          const resumes = task2.writes.filter((w) => w[0] === RESUME2);
          if (resumes.length) {
            interrupts.push(...resumes);
          }
          this.loop.putWrites(task2.id, interrupts);
        }
      } else if (isGraphBubbleUp(error) && task2.writes.length) {
        this.loop.putWrites(task2.id, task2.writes);
      } else {
        this.loop.putWrites(task2.id, [
          [ERROR3, { message: error.message, name: error.name }]
        ]);
      }
    } else {
      if (this.nodeFinished && (((_a2 = task2.config) == null ? void 0 : _a2.tags) == null || !task2.config.tags.includes(TAG_HIDDEN))) {
        this.nodeFinished(String(task2.name));
      }
      if (task2.writes.length === 0) {
        task2.writes.push([NO_WRITES, null]);
      }
      this.loop.putWrites(task2.id, task2.writes);
    }
  }
};
async function call2(runner, task2, func, name, input, options = {}) {
  var _a2, _b;
  const scratchpad = (_b = (_a2 = task2.config) == null ? void 0 : _a2.configurable) == null ? void 0 : _b[CONFIG_KEY_SCRATCHPAD];
  if (!scratchpad) {
    throw new Error(`BUG: No scratchpad found on task ${task2.name}__${task2.id}`);
  }
  const cnt = scratchpad.callCounter;
  scratchpad.callCounter += 1;
  const wcall = new Call({
    func,
    name,
    input,
    cache: options.cache,
    retry: options.retry,
    callbacks: options.callbacks
  });
  const nextTask = await this.scheduleTask(task2, cnt, wcall);
  if (!nextTask)
    return void 0;
  const existingPromise = this.executingTasksMap[nextTask.id];
  if (existingPromise !== void 0) {
    return existingPromise;
  }
  if (nextTask.writes.length > 0) {
    const returns = nextTask.writes.filter(([c]) => c === RETURN);
    const errors = nextTask.writes.filter(([c]) => c === ERROR3);
    if (returns.length > 0) {
      if (returns.length === 1)
        return Promise.resolve(returns[0][1]);
      throw new Error(`BUG: multiple returns found for task ${nextTask.name}__${nextTask.id}`);
    }
    if (errors.length > 0) {
      if (errors.length === 1) {
        const errorValue = errors[0][1];
        const error = (
          // eslint-disable-next-line no-instanceof/no-instanceof
          errorValue instanceof Error ? errorValue : new Error(String(errorValue))
        );
        return Promise.reject(error);
      }
      throw new Error(`BUG: multiple errors found for task ${nextTask.name}__${nextTask.id}`);
    }
    return void 0;
  } else {
    const prom = _runWithRetry(nextTask, options.retry, {
      [CONFIG_KEY_CALL]: call2.bind(this, runner, nextTask)
    });
    this.executingTasksMap[nextTask.id] = prom;
    this.barrier.next();
    return prom.then(({ result, error }) => {
      if (error)
        return Promise.reject(error);
      return result;
    });
  }
}

// node_modules/@langchain/langgraph/dist/pregel/validate.js
var GraphValidationError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "GraphValidationError";
  }
};
function validateGraph({ nodes, channels, inputChannels, outputChannels, streamChannels, interruptAfterNodes, interruptBeforeNodes }) {
  if (!channels) {
    throw new GraphValidationError("Channels not provided");
  }
  const subscribedChannels = /* @__PURE__ */ new Set();
  const allOutputChannels = /* @__PURE__ */ new Set();
  for (const [name, node] of Object.entries(nodes)) {
    if (name === INTERRUPT2) {
      throw new GraphValidationError(`"Node name ${INTERRUPT2} is reserved"`);
    }
    if (node.constructor === PregelNode) {
      node.triggers.forEach((trigger) => subscribedChannels.add(trigger));
    } else {
      throw new GraphValidationError(`Invalid node type ${typeof node}, expected PregelNode`);
    }
  }
  for (const chan of subscribedChannels) {
    if (!(chan in channels)) {
      throw new GraphValidationError(`Subscribed channel '${String(chan)}' not in channels`);
    }
  }
  if (!Array.isArray(inputChannels)) {
    if (!subscribedChannels.has(inputChannels)) {
      throw new GraphValidationError(`Input channel ${String(inputChannels)} is not subscribed to by any node`);
    }
  } else {
    if (inputChannels.every((channel) => !subscribedChannels.has(channel))) {
      throw new GraphValidationError(`None of the input channels ${inputChannels} are subscribed to by any node`);
    }
  }
  if (!Array.isArray(outputChannels)) {
    allOutputChannels.add(outputChannels);
  } else {
    outputChannels.forEach((chan) => allOutputChannels.add(chan));
  }
  if (streamChannels && !Array.isArray(streamChannels)) {
    allOutputChannels.add(streamChannels);
  } else if (Array.isArray(streamChannels)) {
    streamChannels.forEach((chan) => allOutputChannels.add(chan));
  }
  for (const chan of allOutputChannels) {
    if (!(chan in channels)) {
      throw new GraphValidationError(`Output channel '${String(chan)}' not in channels`);
    }
  }
  if (interruptAfterNodes && interruptAfterNodes !== "*") {
    for (const node of interruptAfterNodes) {
      if (!(node in nodes)) {
        throw new GraphValidationError(`Node ${String(node)} not in nodes`);
      }
    }
  }
  if (interruptBeforeNodes && interruptBeforeNodes !== "*") {
    for (const node of interruptBeforeNodes) {
      if (!(node in nodes)) {
        throw new GraphValidationError(`Node ${String(node)} not in nodes`);
      }
    }
  }
}
function validateKeys(keys, channels) {
  if (Array.isArray(keys)) {
    for (const key of keys) {
      if (!(key in channels)) {
        throw new Error(`Key ${String(key)} not found in channels`);
      }
    }
  } else {
    if (!(keys in channels)) {
      throw new Error(`Key ${String(keys)} not found in channels`);
    }
  }
}

// node_modules/@langchain/langgraph/dist/channels/topic.js
var Topic = class _Topic extends BaseChannel {
  constructor(fields) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "Topic"
    });
    Object.defineProperty(this, "unique", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "accumulate", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "values", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.unique = (fields == null ? void 0 : fields.unique) ?? this.unique;
    this.accumulate = (fields == null ? void 0 : fields.accumulate) ?? this.accumulate;
    this.seen = /* @__PURE__ */ new Set();
    this.values = [];
  }
  fromCheckpoint(checkpoint) {
    const empty = new _Topic({
      unique: this.unique,
      accumulate: this.accumulate
    });
    if (typeof checkpoint !== "undefined") {
      empty.seen = new Set(checkpoint[0]);
      empty.values = checkpoint[1];
    }
    return empty;
  }
  update(values) {
    let updated = false;
    if (!this.accumulate) {
      updated = this.values.length > 0;
      this.values = [];
    }
    const flatValues = values.flat();
    if (flatValues.length > 0) {
      if (this.unique) {
        for (const value of flatValues) {
          if (!this.seen.has(value)) {
            updated = true;
            this.seen.add(value);
            this.values.push(value);
          }
        }
      } else {
        updated = true;
        this.values.push(...flatValues);
      }
    }
    return updated;
  }
  get() {
    if (this.values.length === 0) {
      throw new EmptyChannelError();
    }
    return this.values;
  }
  checkpoint() {
    return [[...this.seen], this.values];
  }
  isAvailable() {
    return this.values.length !== 0;
  }
};

// node_modules/@langchain/langgraph/dist/pregel/index.js
var Channel = class {
  static subscribeTo(channels, options) {
    const { key, tags } = {
      key: void 0,
      tags: void 0,
      ...options ?? {}
    };
    if (Array.isArray(channels) && key !== void 0) {
      throw new Error("Can't specify a key when subscribing to multiple channels");
    }
    let channelMappingOrArray;
    if (typeof channels === "string") {
      if (key) {
        channelMappingOrArray = { [key]: channels };
      } else {
        channelMappingOrArray = [channels];
      }
    } else {
      channelMappingOrArray = Object.fromEntries(channels.map((chan) => [chan, chan]));
    }
    const triggers = Array.isArray(channels) ? channels : [channels];
    return new PregelNode({
      channels: channelMappingOrArray,
      triggers,
      tags
    });
  }
  /**
   * Creates a ChannelWrite that specifies how to write values to channels.
   * This is used to define how nodes send output to channels.
   *
   * @example
   * ```typescript
   * // Write to multiple channels
   * const write = Channel.writeTo(["output", "state"]);
   *
   * // Write with specific values
   * const write = Channel.writeTo(["output"], {
   *   state: "completed",
   *   result: calculateResult()
   * });
   *
   * // Write with a transformation function
   * const write = Channel.writeTo(["output"], {
   *   result: (x) => processResult(x)
   * });
   * ```
   *
   * @param channels - Array of channel names to write to
   * @param writes - Optional map of channel names to values or transformations
   * @returns A ChannelWrite object that can be used to write to the specified channels
   */
  static writeTo(channels, writes) {
    const channelWriteEntries = [];
    for (const channel of channels) {
      channelWriteEntries.push({
        channel,
        value: PASSTHROUGH,
        skipNone: false
      });
    }
    for (const [key, value] of Object.entries(writes ?? {})) {
      if (Runnable.isRunnable(value) || typeof value === "function") {
        channelWriteEntries.push({
          channel: key,
          value: PASSTHROUGH,
          skipNone: true,
          mapper: _coerceToRunnable(value)
        });
      } else {
        channelWriteEntries.push({
          channel: key,
          value,
          skipNone: false
        });
      }
    }
    return new ChannelWrite(channelWriteEntries);
  }
};
var PartialRunnable = class extends Runnable {
  constructor() {
    super(...arguments);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph", "pregel"]
    });
  }
  invoke(_input, _options) {
    throw new Error("Not implemented");
  }
  // Overriden by `Pregel`
  withConfig(_config) {
    return super.withConfig(_config);
  }
  // Overriden by `Pregel`
  stream(input, options) {
    return super.stream(input, options);
  }
};
var Pregel = class extends PartialRunnable {
  /**
   * Name of the class when serialized
   * @internal
   */
  static lc_name() {
    return "LangGraph";
  }
  /**
   * Constructor for Pregel - meant for internal use only.
   *
   * @internal
   */
  constructor(fields) {
    super(fields);
    Object.defineProperty(this, "lc_namespace", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["langgraph", "pregel"]
    });
    Object.defineProperty(this, "lg_is_pregel", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "inputChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "outputChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "autoValidate", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    Object.defineProperty(this, "streamMode", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: ["values"]
    });
    Object.defineProperty(this, "streamChannels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptAfter", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "interruptBefore", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stepTimeout", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "debug", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "checkpointer", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "retryPolicy", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "config", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "store", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "triggerToNodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "cache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    let { streamMode } = fields;
    if (streamMode != null && !Array.isArray(streamMode)) {
      streamMode = [streamMode];
    }
    this.nodes = fields.nodes;
    this.channels = fields.channels;
    if (TASKS2 in this.channels && "lc_graph_name" in this.channels[TASKS2] && this.channels[TASKS2].lc_graph_name !== "Topic") {
      throw new Error(`Channel '${TASKS2}' is reserved and cannot be used in the graph.`);
    } else {
      this.channels[TASKS2] = new Topic({ accumulate: false });
    }
    this.autoValidate = fields.autoValidate ?? this.autoValidate;
    this.streamMode = streamMode ?? this.streamMode;
    this.inputChannels = fields.inputChannels;
    this.outputChannels = fields.outputChannels;
    this.streamChannels = fields.streamChannels ?? this.streamChannels;
    this.interruptAfter = fields.interruptAfter;
    this.interruptBefore = fields.interruptBefore;
    this.stepTimeout = fields.stepTimeout ?? this.stepTimeout;
    this.debug = fields.debug ?? this.debug;
    this.checkpointer = fields.checkpointer;
    this.retryPolicy = fields.retryPolicy;
    this.config = fields.config;
    this.store = fields.store;
    this.cache = fields.cache;
    this.name = fields.name;
    if (this.autoValidate) {
      this.validate();
    }
  }
  /**
   * Creates a new instance of the Pregel graph with updated configuration.
   * This method follows the immutable pattern - instead of modifying the current instance,
   * it returns a new instance with the merged configuration.
   *
   * @example
   * ```typescript
   * // Create a new instance with debug enabled
   * const debugGraph = graph.withConfig({ debug: true });
   *
   * // Create a new instance with a specific thread ID
   * const threadGraph = graph.withConfig({
   *   configurable: { thread_id: "123" }
   * });
   * ```
   *
   * @param config - The configuration to merge with the current configuration
   * @returns A new Pregel instance with the merged configuration
   */
  withConfig(config) {
    const mergedConfig = mergeConfigs(this.config, config);
    return new this.constructor({ ...this, config: mergedConfig });
  }
  /**
   * Validates the graph structure to ensure it is well-formed.
   * Checks for:
   * - No orphaned nodes
   * - Valid input/output channel configurations
   * - Valid interrupt configurations
   *
   * @returns this - The Pregel instance for method chaining
   * @throws {GraphValidationError} If the graph structure is invalid
   */
  validate() {
    var _a2;
    validateGraph({
      nodes: this.nodes,
      channels: this.channels,
      outputChannels: this.outputChannels,
      inputChannels: this.inputChannels,
      streamChannels: this.streamChannels,
      interruptAfterNodes: this.interruptAfter,
      interruptBeforeNodes: this.interruptBefore
    });
    for (const [name, node] of Object.entries(this.nodes)) {
      for (const trigger of node.triggers) {
        (_a2 = this.triggerToNodes)[trigger] ?? (_a2[trigger] = []);
        this.triggerToNodes[trigger].push(name);
      }
    }
    return this;
  }
  /**
   * Gets a list of all channels that should be streamed.
   * If streamChannels is specified, returns those channels.
   * Otherwise, returns all channels in the graph.
   *
   * @returns Array of channel keys to stream
   */
  get streamChannelsList() {
    if (Array.isArray(this.streamChannels)) {
      return this.streamChannels;
    } else if (this.streamChannels) {
      return [this.streamChannels];
    } else {
      return Object.keys(this.channels);
    }
  }
  /**
   * Gets the channels to stream in their original format.
   * If streamChannels is specified, returns it as-is (either single key or array).
   * Otherwise, returns all channels in the graph as an array.
   *
   * @returns Channel keys to stream, either as a single key or array
   */
  get streamChannelsAsIs() {
    if (this.streamChannels) {
      return this.streamChannels;
    } else {
      return Object.keys(this.channels);
    }
  }
  /**
   * Gets a drawable representation of the graph structure.
   * This is an async version of getGraph() and is the preferred method to use.
   *
   * @param config - Configuration for generating the graph visualization
   * @returns A representation of the graph that can be visualized
   */
  async getGraphAsync(config) {
    return this.getGraph(config);
  }
  /**
   * Gets all subgraphs within this graph.
   * A subgraph is a Pregel instance that is nested within a node of this graph.
   *
   * @deprecated Use getSubgraphsAsync instead. The async method will become the default in the next minor release.
   * @param namespace - Optional namespace to filter subgraphs
   * @param recurse - Whether to recursively get subgraphs of subgraphs
   * @returns Generator yielding tuples of [name, subgraph]
   */
  *getSubgraphs(namespace, recurse) {
    var _a2;
    for (const [name, node] of Object.entries(this.nodes)) {
      if (namespace !== void 0) {
        if (!namespace.startsWith(name)) {
          continue;
        }
      }
      const candidates = ((_a2 = node.subgraphs) == null ? void 0 : _a2.length) ? node.subgraphs : [node.bound];
      for (const candidate of candidates) {
        const graph = findSubgraphPregel(candidate);
        if (graph !== void 0) {
          if (name === namespace) {
            yield [name, graph];
            return;
          }
          if (namespace === void 0) {
            yield [name, graph];
          }
          if (recurse) {
            let newNamespace = namespace;
            if (namespace !== void 0) {
              newNamespace = namespace.slice(name.length + 1);
            }
            for (const [subgraphName, subgraph] of graph.getSubgraphs(newNamespace, recurse)) {
              yield [
                `${name}${CHECKPOINT_NAMESPACE_SEPARATOR}${subgraphName}`,
                subgraph
              ];
            }
          }
        }
      }
    }
  }
  /**
   * Gets all subgraphs within this graph asynchronously.
   * A subgraph is a Pregel instance that is nested within a node of this graph.
   *
   * @param namespace - Optional namespace to filter subgraphs
   * @param recurse - Whether to recursively get subgraphs of subgraphs
   * @returns AsyncGenerator yielding tuples of [name, subgraph]
   */
  async *getSubgraphsAsync(namespace, recurse) {
    yield* this.getSubgraphs(namespace, recurse);
  }
  /**
   * Prepares a state snapshot from saved checkpoint data.
   * This is an internal method used by getState and getStateHistory.
   *
   * @param config - Configuration for preparing the snapshot
   * @param saved - Optional saved checkpoint data
   * @param subgraphCheckpointer - Optional checkpointer for subgraphs
   * @param applyPendingWrites - Whether to apply pending writes to tasks and then to channels
   * @returns A snapshot of the graph state
   * @internal
   */
  async _prepareStateSnapshot({ config, saved, subgraphCheckpointer, applyPendingWrites = false }) {
    var _a2, _b, _c, _d, _e, _f, _g, _h;
    if (saved === void 0) {
      return {
        values: {},
        next: [],
        config,
        tasks: []
      };
    }
    const channels = emptyChannels(this.channels, saved.checkpoint);
    if ((_a2 = saved.pendingWrites) == null ? void 0 : _a2.length) {
      const nullWrites = saved.pendingWrites.filter(([taskId, _]) => taskId === NULL_TASK_ID).map(([_, channel, value]) => [String(channel), value]);
      if (nullWrites.length > 0) {
        _applyWrites(saved.checkpoint, channels, [
          {
            name: INPUT,
            writes: nullWrites,
            triggers: []
          }
        ], void 0, this.triggerToNodes);
      }
    }
    const nextTasks = Object.values(_prepareNextTasks(saved.checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, { step: (((_b = saved.metadata) == null ? void 0 : _b.step) ?? -1) + 1, store: this.store }));
    const subgraphs = await gatherIterator(this.getSubgraphsAsync());
    const parentNamespace = ((_c = saved.config.configurable) == null ? void 0 : _c.checkpoint_ns) ?? "";
    const taskStates = {};
    for (const task2 of nextTasks) {
      const matchingSubgraph = subgraphs.find(([name]) => name === task2.name);
      if (!matchingSubgraph) {
        continue;
      }
      let taskNs = `${String(task2.name)}${CHECKPOINT_NAMESPACE_END}${task2.id}`;
      if (parentNamespace) {
        taskNs = `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${taskNs}`;
      }
      if (subgraphCheckpointer === void 0) {
        const config2 = {
          configurable: {
            thread_id: (_d = saved.config.configurable) == null ? void 0 : _d.thread_id,
            checkpoint_ns: taskNs
          }
        };
        taskStates[task2.id] = config2;
      } else {
        const subgraphConfig = {
          configurable: {
            [CONFIG_KEY_CHECKPOINTER]: subgraphCheckpointer,
            thread_id: (_e = saved.config.configurable) == null ? void 0 : _e.thread_id,
            checkpoint_ns: taskNs
          }
        };
        const pregel = matchingSubgraph[1];
        taskStates[task2.id] = await pregel.getState(subgraphConfig, {
          subgraphs: true
        });
      }
    }
    if (applyPendingWrites && ((_f = saved.pendingWrites) == null ? void 0 : _f.length)) {
      const nextTaskById = Object.fromEntries(nextTasks.map((task2) => [task2.id, task2]));
      for (const [taskId, channel, value] of saved.pendingWrites) {
        if ([ERROR3, INTERRUPT2, SCHEDULED].includes(channel)) {
          continue;
        }
        if (!(taskId in nextTaskById)) {
          continue;
        }
        nextTaskById[taskId].writes.push([String(channel), value]);
      }
      const tasksWithWrites2 = nextTasks.filter((task2) => task2.writes.length > 0);
      if (tasksWithWrites2.length > 0) {
        _applyWrites(saved.checkpoint, channels, tasksWithWrites2, void 0, this.triggerToNodes);
      }
    }
    let metadata = saved == null ? void 0 : saved.metadata;
    if (metadata && ((_h = (_g = saved == null ? void 0 : saved.config) == null ? void 0 : _g.configurable) == null ? void 0 : _h.thread_id)) {
      metadata = {
        ...metadata,
        thread_id: saved.config.configurable.thread_id
      };
    }
    const nextList = nextTasks.filter((task2) => task2.writes.length === 0).map((task2) => task2.name);
    return {
      values: readChannels(channels, this.streamChannelsAsIs),
      next: nextList,
      tasks: tasksWithWrites(nextTasks, (saved == null ? void 0 : saved.pendingWrites) ?? [], taskStates, this.streamChannelsAsIs),
      metadata,
      config: patchCheckpointMap(saved.config, saved.metadata),
      createdAt: saved.checkpoint.ts,
      parentConfig: saved.parentConfig
    };
  }
  /**
   * Gets the current state of the graph.
   * Requires a checkpointer to be configured.
   *
   * @param config - Configuration for retrieving the state
   * @param options - Additional options
   * @returns A snapshot of the current graph state
   * @throws {GraphValueError} If no checkpointer is configured
   */
  async getState(config, options) {
    var _a2, _b, _c, _d;
    const checkpointer = ((_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_CHECKPOINTER]) ?? this.checkpointer;
    if (!checkpointer) {
      throw new GraphValueError("No checkpointer set");
    }
    const checkpointNamespace = ((_b = config.configurable) == null ? void 0 : _b.checkpoint_ns) ?? "";
    if (checkpointNamespace !== "" && ((_c = config.configurable) == null ? void 0 : _c[CONFIG_KEY_CHECKPOINTER]) === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, subgraph] of this.getSubgraphsAsync(recastNamespace, true)) {
        if (name === recastNamespace) {
          return await subgraph.getState(patchConfigurable(config, {
            [CONFIG_KEY_CHECKPOINTER]: checkpointer
          }), { subgraphs: options == null ? void 0 : options.subgraphs });
        }
      }
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config);
    const saved = await checkpointer.getTuple(config);
    const snapshot = await this._prepareStateSnapshot({
      config: mergedConfig,
      saved,
      subgraphCheckpointer: (options == null ? void 0 : options.subgraphs) ? checkpointer : void 0,
      applyPendingWrites: !((_d = config.configurable) == null ? void 0 : _d.checkpoint_id)
    });
    return snapshot;
  }
  /**
   * Gets the history of graph states.
   * Requires a checkpointer to be configured.
   * Useful for:
   * - Debugging execution history
   * - Implementing time travel
   * - Analyzing graph behavior
   *
   * @param config - Configuration for retrieving the history
   * @param options - Options for filtering the history
   * @returns An async iterator of state snapshots
   * @throws {Error} If no checkpointer is configured
   */
  async *getStateHistory(config, options) {
    var _a2, _b, _c;
    const checkpointer = ((_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_CHECKPOINTER]) ?? this.checkpointer;
    if (!checkpointer) {
      throw new GraphValueError("No checkpointer set");
    }
    const checkpointNamespace = ((_b = config.configurable) == null ? void 0 : _b.checkpoint_ns) ?? "";
    if (checkpointNamespace !== "" && ((_c = config.configurable) == null ? void 0 : _c[CONFIG_KEY_CHECKPOINTER]) === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, pregel] of this.getSubgraphsAsync(recastNamespace, true)) {
        if (name === recastNamespace) {
          yield* pregel.getStateHistory(patchConfigurable(config, {
            [CONFIG_KEY_CHECKPOINTER]: checkpointer
          }), options);
          return;
        }
      }
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config, {
      configurable: { checkpoint_ns: checkpointNamespace }
    });
    for await (const checkpointTuple of checkpointer.list(mergedConfig, options)) {
      yield this._prepareStateSnapshot({
        config: checkpointTuple.config,
        saved: checkpointTuple
      });
    }
  }
  /**
   * Apply updates to the graph state in bulk.
   * Requires a checkpointer to be configured.
   *
   * This method is useful for recreating a thread
   * from a list of updates, especially if a checkpoint
   * is created as a result of multiple tasks.
   *
   * @internal The API might change in the future.
   *
   * @param startConfig - Configuration for the update
   * @param updates - The list of updates to apply to graph state
   * @returns Updated configuration
   * @throws {GraphValueError} If no checkpointer is configured
   * @throws {InvalidUpdateError} If the update cannot be attributed to a node or an update can be only applied in sequence.
   */
  async bulkUpdateState(startConfig, supersteps) {
    var _a2, _b, _c;
    const checkpointer = ((_a2 = startConfig.configurable) == null ? void 0 : _a2[CONFIG_KEY_CHECKPOINTER]) ?? this.checkpointer;
    if (!checkpointer) {
      throw new GraphValueError("No checkpointer set");
    }
    if (supersteps.length === 0) {
      throw new Error("No supersteps provided");
    }
    if (supersteps.some((s) => s.updates.length === 0)) {
      throw new Error("No updates provided");
    }
    const checkpointNamespace = ((_b = startConfig.configurable) == null ? void 0 : _b.checkpoint_ns) ?? "";
    if (checkpointNamespace !== "" && ((_c = startConfig.configurable) == null ? void 0 : _c[CONFIG_KEY_CHECKPOINTER]) === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [, pregel] of this.getSubgraphsAsync(recastNamespace, true)) {
        return await pregel.bulkUpdateState(patchConfigurable(startConfig, {
          [CONFIG_KEY_CHECKPOINTER]: checkpointer
        }), supersteps);
      }
      throw new Error(`Subgraph "${recastNamespace}" not found`);
    }
    const updateSuperStep = async (inputConfig, updates) => {
      var _a3, _b2, _c2, _d, _e, _f, _g, _h, _i, _j, _k;
      const config = this.config ? mergeConfigs(this.config, inputConfig) : inputConfig;
      const saved = await checkpointer.getTuple(config);
      const checkpoint = saved !== void 0 ? copyCheckpoint(saved.checkpoint) : emptyCheckpoint();
      const checkpointPreviousVersions = {
        ...saved == null ? void 0 : saved.checkpoint.channel_versions
      };
      const step = ((_a3 = saved == null ? void 0 : saved.metadata) == null ? void 0 : _a3.step) ?? -1;
      let checkpointConfig = patchConfigurable(config, {
        checkpoint_ns: ((_b2 = config.configurable) == null ? void 0 : _b2.checkpoint_ns) ?? ""
      });
      let checkpointMetadata = config.metadata ?? {};
      if (saved == null ? void 0 : saved.config.configurable) {
        checkpointConfig = patchConfigurable(config, saved.config.configurable);
        checkpointMetadata = {
          ...saved.metadata,
          ...checkpointMetadata
        };
      }
      const { values, asNode } = updates[0];
      if (values == null && asNode === void 0) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot create empty checkpoint with multiple updates`);
        }
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, void 0, step), {
          source: "update",
          step: step + 1,
          parents: ((_c2 = saved == null ? void 0 : saved.metadata) == null ? void 0 : _c2.parents) ?? {}
        }, {});
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      const channels = emptyChannels(this.channels, checkpoint);
      if (values === null && asNode === END) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot apply multiple updates when clearing state`);
        }
        if (saved) {
          const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites || [], this.nodes, channels, saved.config, true, {
            step: (((_d = saved.metadata) == null ? void 0 : _d.step) ?? -1) + 1,
            checkpointer,
            store: this.store
          });
          const nullWrites = (saved.pendingWrites || []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
          if (nullWrites.length > 0) {
            _applyWrites(checkpoint, channels, [
              {
                name: INPUT,
                writes: nullWrites,
                triggers: []
              }
            ], checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
          }
          for (const [taskId, k, v] of saved.pendingWrites || []) {
            if ([ERROR3, INTERRUPT2, SCHEDULED].includes(k)) {
              continue;
            }
            if (!(taskId in nextTasks)) {
              continue;
            }
            nextTasks[taskId].writes.push([k, v]);
          }
          _applyWrites(checkpoint, channels, Object.values(nextTasks), checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
        }
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step), {
          ...checkpointMetadata,
          source: "update",
          step: step + 1,
          parents: ((_e = saved == null ? void 0 : saved.metadata) == null ? void 0 : _e.parents) ?? {}
        }, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (asNode === COPY) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot copy checkpoint with multiple updates`);
        }
        if (saved == null) {
          throw new InvalidUpdateError(`Cannot copy a non-existent checkpoint`);
        }
        const isCopyWithUpdates = (values2) => {
          if (!Array.isArray(values2))
            return false;
          if (values2.length === 0)
            return false;
          return values2.every((v) => Array.isArray(v) && v.length === 2);
        };
        const nextCheckpoint = createCheckpoint(checkpoint, void 0, step);
        const nextConfig2 = await checkpointer.put(saved.parentConfig ?? patchConfigurable(saved.config, { checkpoint_id: void 0 }), nextCheckpoint, {
          source: "fork",
          step: step + 1,
          parents: ((_f = saved.metadata) == null ? void 0 : _f.parents) ?? {}
        }, {});
        if (isCopyWithUpdates(values)) {
          const nextTasks = _prepareNextTasks(nextCheckpoint, saved.pendingWrites, this.nodes, channels, nextConfig2, false, { step: step + 2 });
          const tasksGroupBy = Object.values(nextTasks).reduce((acc, { name, id }) => {
            acc[name] ?? (acc[name] = []);
            acc[name].push({ id });
            return acc;
          }, {});
          const userGroupBy = values.reduce((acc, item) => {
            var _a4, _b3;
            const [values2, asNode2] = item;
            acc[asNode2] ?? (acc[asNode2] = []);
            const targetIdx = acc[asNode2].length;
            const taskId = (_b3 = (_a4 = tasksGroupBy[asNode2]) == null ? void 0 : _a4[targetIdx]) == null ? void 0 : _b3.id;
            acc[asNode2].push({ values: values2, asNode: asNode2, taskId });
            return acc;
          }, {});
          return updateSuperStep(patchCheckpointMap(nextConfig2, saved.metadata), Object.values(userGroupBy).flat());
        }
        return patchCheckpointMap(nextConfig2, saved.metadata);
      }
      if (asNode === INPUT) {
        if (updates.length > 1) {
          throw new InvalidUpdateError(`Cannot apply multiple updates when updating as input`);
        }
        const inputWrites = await gatherIterator(mapInput(this.inputChannels, values));
        if (inputWrites.length === 0) {
          throw new InvalidUpdateError(`Received no input writes for ${JSON.stringify(this.inputChannels, null, 2)}`);
        }
        _applyWrites(checkpoint, channels, [
          {
            name: INPUT,
            writes: inputWrites,
            triggers: []
          }
        ], checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
        const nextStep = ((_g = saved == null ? void 0 : saved.metadata) == null ? void 0 : _g.step) != null ? saved.metadata.step + 1 : -1;
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, nextStep), {
          source: "input",
          step: nextStep,
          parents: ((_h = saved == null ? void 0 : saved.metadata) == null ? void 0 : _h.parents) ?? {}
        }, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));
        await checkpointer.putWrites(nextConfig2, inputWrites, uuid5(INPUT, checkpoint.id));
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (((_i = config.configurable) == null ? void 0 : _i.checkpoint_id) === void 0 && (saved == null ? void 0 : saved.pendingWrites) !== void 0 && saved.pendingWrites.length > 0) {
        const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {
          store: this.store,
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          checkpointer: this.checkpointer,
          step: (((_j = saved.metadata) == null ? void 0 : _j.step) ?? -1) + 1
        });
        const nullWrites = (saved.pendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
        if (nullWrites.length > 0) {
          _applyWrites(saved.checkpoint, channels, [{ name: INPUT, writes: nullWrites, triggers: [] }], void 0, this.triggerToNodes);
        }
        for (const [tid, k, v] of saved.pendingWrites) {
          if ([ERROR3, INTERRUPT2, SCHEDULED].includes(k) || nextTasks[tid] === void 0) {
            continue;
          }
          nextTasks[tid].writes.push([k, v]);
        }
        const tasks2 = Object.values(nextTasks).filter((task2) => {
          return task2.writes.length > 0;
        });
        if (tasks2.length > 0) {
          _applyWrites(checkpoint, channels, tasks2, void 0, this.triggerToNodes);
        }
      }
      const nonNullVersion = Object.values(checkpoint.versions_seen).map((seenVersions) => {
        return Object.values(seenVersions);
      }).flat().find((v) => !!v);
      const validUpdates = [];
      if (updates.length === 1) {
        let { values: values2, asNode: asNode2, taskId } = updates[0];
        if (asNode2 === void 0 && Object.keys(this.nodes).length === 1) {
          [asNode2] = Object.keys(this.nodes);
        } else if (asNode2 === void 0 && nonNullVersion === void 0) {
          if (typeof this.inputChannels === "string" && this.nodes[this.inputChannels] !== void 0) {
            asNode2 = this.inputChannels;
          }
        } else if (asNode2 === void 0) {
          const lastSeenByNode = Object.entries(checkpoint.versions_seen).map(([n2, seen]) => {
            return Object.values(seen).map((v) => {
              return [v, n2];
            });
          }).flat().filter(([_, v]) => v !== INTERRUPT2).sort(([aNumber], [bNumber]) => compareChannelVersions(aNumber, bNumber));
          if (lastSeenByNode) {
            if (lastSeenByNode.length === 1) {
              asNode2 = lastSeenByNode[0][1];
            } else if (lastSeenByNode[lastSeenByNode.length - 1][0] !== lastSeenByNode[lastSeenByNode.length - 2][0]) {
              asNode2 = lastSeenByNode[lastSeenByNode.length - 1][1];
            }
          }
        }
        if (asNode2 === void 0) {
          throw new InvalidUpdateError(`Ambiguous update, specify "asNode"`);
        }
        validUpdates.push({ values: values2, asNode: asNode2, taskId });
      } else {
        for (const { asNode: asNode2, values: values2, taskId } of updates) {
          if (asNode2 == null) {
            throw new InvalidUpdateError(`"asNode" is required when applying multiple updates`);
          }
          validUpdates.push({ values: values2, asNode: asNode2, taskId });
        }
      }
      const tasks = [];
      for (const { asNode: asNode2, values: values2, taskId } of validUpdates) {
        if (this.nodes[asNode2] === void 0) {
          throw new InvalidUpdateError(`Node "${asNode2.toString()}" does not exist`);
        }
        const writers = this.nodes[asNode2].getWriters();
        if (!writers.length) {
          throw new InvalidUpdateError(`No writers found for node "${asNode2.toString()}"`);
        }
        tasks.push({
          name: asNode2,
          input: values2,
          proc: writers.length > 1 ? (
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            RunnableSequence.from(writers, {
              omitSequenceTags: true
            })
          ) : writers[0],
          writes: [],
          triggers: [INTERRUPT2],
          id: taskId ?? uuid5(INTERRUPT2, checkpoint.id),
          writers: []
        });
      }
      for (const task2 of tasks) {
        await task2.proc.invoke(task2.input, patchConfig({
          ...config,
          store: (config == null ? void 0 : config.store) ?? this.store
        }, {
          runName: config.runName ?? `${this.getName()}UpdateState`,
          configurable: {
            [CONFIG_KEY_SEND]: (items) => task2.writes.push(...items),
            [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(
              checkpoint,
              channels,
              // TODO: Why does keyof StrRecord allow number and symbol?
              task2,
              select_,
              fresh_
            )
          }
        }));
      }
      for (const task2 of tasks) {
        const channelWrites = task2.writes.filter((w) => w[0] !== PUSH);
        if (saved !== void 0 && channelWrites.length > 0) {
          await checkpointer.putWrites(checkpointConfig, channelWrites, task2.id);
        }
      }
      _applyWrites(checkpoint, channels, tasks, checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
      const newVersions = getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions);
      const nextConfig = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step + 1), {
        source: "update",
        step: step + 1,
        parents: ((_k = saved == null ? void 0 : saved.metadata) == null ? void 0 : _k.parents) ?? {}
      }, newVersions);
      for (const task2 of tasks) {
        const pushWrites = task2.writes.filter((w) => w[0] === PUSH);
        if (pushWrites.length > 0) {
          await checkpointer.putWrites(nextConfig, pushWrites, task2.id);
        }
      }
      return patchCheckpointMap(nextConfig, saved ? saved.metadata : void 0);
    };
    let currentConfig = startConfig;
    for (const { updates } of supersteps) {
      currentConfig = await updateSuperStep(currentConfig, updates);
    }
    return currentConfig;
  }
  /**
   * Updates the state of the graph with new values.
   * Requires a checkpointer to be configured.
   *
   * This method can be used for:
   * - Implementing human-in-the-loop workflows
   * - Modifying graph state during breakpoints
   * - Integrating external inputs into the graph
   *
   * @param inputConfig - Configuration for the update
   * @param values - The values to update the state with
   * @param asNode - Optional node name to attribute the update to
   * @returns Updated configuration
   * @throws {GraphValueError} If no checkpointer is configured
   * @throws {InvalidUpdateError} If the update cannot be attributed to a node
   */
  async updateState(inputConfig, values, asNode) {
    return this.bulkUpdateState(inputConfig, [
      { updates: [{ values, asNode }] }
    ]);
  }
  /**
   * Gets the default values for various graph configuration options.
   * This is an internal method used to process and normalize configuration options.
   *
   * @param config - The input configuration options
   * @returns A tuple containing normalized values for:
   * - debug mode
   * - stream modes
   * - input keys
   * - output keys
   * - remaining config
   * - interrupt before nodes
   * - interrupt after nodes
   * - checkpointer
   * - store
   * - whether stream mode is single
   * - node cache
   * - whether checkpoint during is enabled
   * @internal
   */
  _defaults(config) {
    var _a2, _b, _c;
    const { debug, streamMode, inputKeys, outputKeys, interruptAfter, interruptBefore, ...rest } = config;
    let streamModeSingle = true;
    const defaultDebug = debug !== void 0 ? debug : this.debug;
    let defaultOutputKeys = outputKeys;
    if (defaultOutputKeys === void 0) {
      defaultOutputKeys = this.streamChannelsAsIs;
    } else {
      validateKeys(defaultOutputKeys, this.channels);
    }
    let defaultInputKeys = inputKeys;
    if (defaultInputKeys === void 0) {
      defaultInputKeys = this.inputChannels;
    } else {
      validateKeys(defaultInputKeys, this.channels);
    }
    const defaultInterruptBefore = interruptBefore ?? this.interruptBefore ?? [];
    const defaultInterruptAfter = interruptAfter ?? this.interruptAfter ?? [];
    let defaultStreamMode;
    if (streamMode !== void 0) {
      defaultStreamMode = Array.isArray(streamMode) ? streamMode : [streamMode];
      streamModeSingle = typeof streamMode === "string";
    } else {
      if (((_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_TASK_ID]) !== void 0) {
        defaultStreamMode = ["values"];
      } else {
        defaultStreamMode = this.streamMode;
      }
      streamModeSingle = true;
    }
    let defaultCheckpointer;
    if (this.checkpointer === false) {
      defaultCheckpointer = void 0;
    } else if (config !== void 0 && ((_b = config.configurable) == null ? void 0 : _b[CONFIG_KEY_CHECKPOINTER]) !== void 0) {
      defaultCheckpointer = config.configurable[CONFIG_KEY_CHECKPOINTER];
    } else if (this.checkpointer === true) {
      throw new Error("checkpointer: true cannot be used for root graphs.");
    } else {
      defaultCheckpointer = this.checkpointer;
    }
    const defaultStore = config.store ?? this.store;
    const defaultCache = config.cache ?? this.cache;
    if (config.durability != null && config.checkpointDuring != null) {
      throw new Error("Cannot use both `durability` and `checkpointDuring` at the same time.");
    }
    const checkpointDuringDurability = (() => {
      if (config.checkpointDuring == null)
        return void 0;
      if (config.checkpointDuring === false)
        return "exit";
      return "async";
    })();
    const defaultDurability = config.durability ?? checkpointDuringDurability ?? ((_c = config == null ? void 0 : config.configurable) == null ? void 0 : _c[CONFIG_KEY_DURABILITY]) ?? "async";
    return [
      defaultDebug,
      defaultStreamMode,
      defaultInputKeys,
      defaultOutputKeys,
      rest,
      defaultInterruptBefore,
      defaultInterruptAfter,
      defaultCheckpointer,
      defaultStore,
      streamModeSingle,
      defaultCache,
      defaultDurability
    ];
  }
  /**
   * Streams the execution of the graph, emitting state updates as they occur.
   * This is the primary method for observing graph execution in real-time.
   *
   * Stream modes:
   * - "values": Emits complete state after each step
   * - "updates": Emits only state changes after each step
   * - "debug": Emits detailed debug information
   * - "messages": Emits messages from within nodes
   *
   * For more details, see the [Streaming how-to guides](../../how-tos/#streaming_1).
   *
   * @param input - The input to start graph execution with
   * @param options - Configuration options for streaming
   * @returns An async iterable stream of graph state updates
   */
  async stream(input, options) {
    var _a2;
    const abortController = new AbortController();
    const config = {
      recursionLimit: (_a2 = this.config) == null ? void 0 : _a2.recursionLimit,
      ...options,
      signal: combineAbortSignals(options == null ? void 0 : options.signal, abortController.signal).signal
    };
    return new IterableReadableStreamWithAbortSignal(await super.stream(input, config), abortController);
  }
  streamEvents(input, options, streamOptions) {
    var _a2, _b;
    const abortController = new AbortController();
    const config = {
      recursionLimit: (_a2 = this.config) == null ? void 0 : _a2.recursionLimit,
      ...options,
      // Similar to `stream`, we need to pass the `config.callbacks` here,
      // otherwise the user-provided callback will get lost in `ensureLangGraphConfig`.
      // extend the callbacks with the ones from the config
      callbacks: combineCallbacks((_b = this.config) == null ? void 0 : _b.callbacks, options == null ? void 0 : options.callbacks),
      signal: combineAbortSignals(options == null ? void 0 : options.signal, abortController.signal).signal
    };
    return new IterableReadableStreamWithAbortSignal(super.streamEvents(input, config, streamOptions), abortController);
  }
  /**
   * Validates the input for the graph.
   * @param input - The input to validate
   * @returns The validated input
   * @internal
   */
  async _validateInput(input) {
    return input;
  }
  /**
   * Validates the context options for the graph.
   * @param context - The context options to validate
   * @returns The validated context options
   * @internal
   */
  async _validateContext(context) {
    return context;
  }
  /**
   * Internal iterator used by stream() to generate state updates.
   * This method handles the core logic of graph execution and streaming.
   *
   * @param input - The input to start graph execution with
   * @param options - Configuration options for streaming
   * @returns AsyncGenerator yielding state updates
   * @internal
   */
  async *_streamIterator(input, options) {
    const streamSubgraphs = options == null ? void 0 : options.subgraphs;
    const inputConfig = ensureLangGraphConfig(this.config, options);
    if (inputConfig.recursionLimit === void 0 || inputConfig.recursionLimit < 1) {
      throw new Error(`Passed "recursionLimit" must be at least 1.`);
    }
    if (this.checkpointer !== void 0 && this.checkpointer !== false && inputConfig.configurable === void 0) {
      throw new Error(`Checkpointer requires one or more of the following "configurable" keys: "thread_id", "checkpoint_ns", "checkpoint_id"`);
    }
    const validInput = await this._validateInput(input);
    const { runId, ...restConfig } = inputConfig;
    const [debug, streamMode, , outputKeys, config, interruptBefore, interruptAfter, checkpointer, store, streamModeSingle, cache2, durability] = this._defaults(restConfig);
    if (typeof config.context !== "undefined") {
      config.context = await this._validateContext(config.context);
    } else {
      config.configurable = await this._validateContext(config.configurable);
    }
    const stream = new IterableReadableWritableStream({
      modes: new Set(streamMode)
    });
    if (this.checkpointer === true) {
      config.configurable ?? (config.configurable = {});
      const ns = config.configurable[CONFIG_KEY_CHECKPOINT_NS] ?? "";
      config.configurable[CONFIG_KEY_CHECKPOINT_NS] = ns.split(CHECKPOINT_NAMESPACE_SEPARATOR).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);
    }
    if (streamMode.includes("messages")) {
      const messageStreamer = new StreamMessagesHandler((chunk) => stream.push(chunk));
      const { callbacks } = config;
      if (callbacks === void 0) {
        config.callbacks = [messageStreamer];
      } else if (Array.isArray(callbacks)) {
        config.callbacks = callbacks.concat(messageStreamer);
      } else {
        const copiedCallbacks = callbacks.copy();
        copiedCallbacks.addHandler(messageStreamer, true);
        config.callbacks = copiedCallbacks;
      }
    }
    if (streamMode.includes("custom")) {
      config.writer = (chunk) => {
        var _a2, _b, _c;
        const ns = (_c = (_b = (_a2 = getConfig()) == null ? void 0 : _a2.configurable) == null ? void 0 : _b[CONFIG_KEY_CHECKPOINT_NS]) == null ? void 0 : _c.split(CHECKPOINT_NAMESPACE_SEPARATOR).slice(0, -1);
        stream.push([ns ?? [], "custom", chunk]);
      };
    }
    const callbackManager = await getCallbackManagerForConfig(config);
    const runManager = await (callbackManager == null ? void 0 : callbackManager.handleChainStart(
      this.toJSON(),
      // chain
      _coerceToDict2(input, "input"),
      // inputs
      runId,
      // run_id
      void 0,
      // run_type
      void 0,
      // tags
      void 0,
      // metadata
      (config == null ? void 0 : config.runName) ?? this.getName()
    ));
    const channelSpecs = getOnlyChannels(this.channels);
    let loop;
    let loopError;
    const createAndRunLoop = async () => {
      var _a2, _b, _c;
      try {
        loop = await PregelLoop.initialize({
          input: validInput,
          config,
          checkpointer,
          nodes: this.nodes,
          channelSpecs,
          outputKeys,
          streamKeys: this.streamChannelsAsIs,
          store,
          cache: cache2,
          stream,
          interruptAfter,
          interruptBefore,
          manager: runManager,
          debug: this.debug,
          triggerToNodes: this.triggerToNodes,
          durability
        });
        const runner = new PregelRunner({
          loop,
          nodeFinished: (_a2 = config.configurable) == null ? void 0 : _a2[CONFIG_KEY_NODE_FINISHED]
        });
        if (options == null ? void 0 : options.subgraphs) {
          loop.config.configurable = {
            ...loop.config.configurable,
            [CONFIG_KEY_STREAM]: loop.stream
          };
        }
        await this._runLoop({ loop, runner, debug, config });
        if (durability === "sync") {
          await Promise.all((loop == null ? void 0 : loop.checkpointerPromises) ?? []);
        }
      } catch (e) {
        loopError = e;
      } finally {
        try {
          if (loop) {
            await ((_b = loop.store) == null ? void 0 : _b.stop());
            await ((_c = loop.cache) == null ? void 0 : _c.stop());
          }
          await Promise.all((loop == null ? void 0 : loop.checkpointerPromises) ?? []);
        } catch (e) {
          loopError = loopError ?? e;
        }
        if (loopError) {
          stream.error(loopError);
        } else {
          stream.close();
        }
      }
    };
    const runLoopPromise = createAndRunLoop();
    try {
      for await (const chunk of stream) {
        if (chunk === void 0) {
          throw new Error("Data structure error.");
        }
        const [namespace, mode, payload] = chunk;
        if (streamMode.includes(mode)) {
          if (streamSubgraphs && !streamModeSingle) {
            yield [namespace, mode, payload];
          } else if (!streamModeSingle) {
            yield [mode, payload];
          } else if (streamSubgraphs) {
            yield [namespace, payload];
          } else {
            yield payload;
          }
        }
      }
    } catch (e) {
      await (runManager == null ? void 0 : runManager.handleChainError(loopError));
      throw e;
    } finally {
      await runLoopPromise;
    }
    await (runManager == null ? void 0 : runManager.handleChainEnd(
      (loop == null ? void 0 : loop.output) ?? {},
      runId,
      // run_id
      void 0,
      // run_type
      void 0,
      // tags
      void 0
    ));
  }
  /**
   * Run the graph with a single input and config.
   * @param input The input to the graph.
   * @param options The configuration to use for the run.
   */
  async invoke(input, options) {
    const streamMode = (options == null ? void 0 : options.streamMode) ?? "values";
    const config = {
      ...options,
      outputKeys: (options == null ? void 0 : options.outputKeys) ?? this.outputChannels,
      streamMode
    };
    const chunks = [];
    const stream = await this.stream(input, config);
    const interruptChunks = [];
    let latest;
    for await (const chunk of stream) {
      if (streamMode === "values") {
        if (isInterrupted(chunk)) {
          interruptChunks.push(chunk[INTERRUPT2]);
        } else {
          latest = chunk;
        }
      } else {
        chunks.push(chunk);
      }
    }
    if (streamMode === "values") {
      if (interruptChunks.length > 0) {
        const interrupts = interruptChunks.flat(1);
        if (latest == null)
          return { [INTERRUPT2]: interrupts };
        if (typeof latest === "object") {
          return { ...latest, [INTERRUPT2]: interrupts };
        }
      }
      return latest;
    }
    return chunks;
  }
  async _runLoop(params) {
    const { loop, runner, debug, config } = params;
    let tickError;
    try {
      while (await loop.tick({ inputKeys: this.inputChannels })) {
        for (const { task: task2 } of await loop._matchCachedWrites()) {
          loop._outputWrites(task2.id, task2.writes, true);
        }
        if (debug) {
          printStepCheckpoint(loop.checkpointMetadata.step, loop.channels, this.streamChannelsList);
        }
        if (debug) {
          printStepTasks(loop.step, Object.values(loop.tasks));
        }
        await runner.tick({
          timeout: this.stepTimeout,
          retryPolicy: this.retryPolicy,
          onStepWrite: (step, writes) => {
            if (debug) {
              printStepWrites(step, writes, this.streamChannelsList);
            }
          },
          maxConcurrency: config.maxConcurrency,
          signal: config.signal
        });
      }
      if (loop.status === "out_of_steps") {
        throw new GraphRecursionError([
          `Recursion limit of ${config.recursionLimit} reached`,
          "without hitting a stop condition. You can increase the",
          `limit by setting the "recursionLimit" config key.`
        ].join(" "), {
          lc_error_code: "GRAPH_RECURSION_LIMIT"
        });
      }
    } catch (e) {
      tickError = e;
      const suppress = await loop.finishAndHandleError(tickError);
      if (!suppress) {
        throw e;
      }
    } finally {
      if (tickError === void 0) {
        await loop.finishAndHandleError();
      }
    }
  }
  async clearCache() {
    var _a2;
    await ((_a2 = this.cache) == null ? void 0 : _a2.clear([]));
  }
};

// node_modules/@langchain/langgraph/dist/channels/ephemeral_value.js
var EphemeralValue = class _EphemeralValue extends BaseChannel {
  constructor(guard = true) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "EphemeralValue"
    });
    Object.defineProperty(this, "guard", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "value", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: []
    });
    this.guard = guard;
  }
  fromCheckpoint(checkpoint) {
    const empty = new _EphemeralValue(this.guard);
    if (typeof checkpoint !== "undefined") {
      empty.value = [checkpoint];
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      const updated = this.value.length > 0;
      this.value = [];
      return updated;
    }
    if (values.length !== 1 && this.guard) {
      throw new InvalidUpdateError("EphemeralValue can only receive one value per step.");
    }
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) {
      throw new EmptyChannelError();
    }
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};

// node_modules/@langchain/langgraph/dist/graph/graph.js
var Branch = class {
  constructor(options) {
    Object.defineProperty(this, "path", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "ends", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (Runnable.isRunnable(options.path)) {
      this.path = options.path;
    } else {
      this.path = _coerceToRunnable(options.path).withConfig({ runName: `Branch` });
    }
    this.ends = Array.isArray(options.pathMap) ? options.pathMap.reduce((acc, n2) => {
      acc[n2] = n2;
      return acc;
    }, {}) : options.pathMap;
  }
  run(writer, reader) {
    return ChannelWrite.registerWriter(new RunnableCallable({
      name: "<branch_run>",
      trace: false,
      func: async (input, config) => {
        try {
          return await this._route(input, config, writer, reader);
        } catch (e) {
          if (e.name === NodeInterrupt.unminifiable_name) {
            console.warn("[WARN]: 'NodeInterrupt' thrown in conditional edge. This is likely a bug in your graph implementation.\nNodeInterrupt should only be thrown inside a node, not in edge conditions.");
          }
          throw e;
        }
      }
    }));
  }
  async _route(input, config, writer, reader) {
    let result = await this.path.invoke(reader ? reader(config) : input, config);
    if (!Array.isArray(result)) {
      result = [result];
    }
    let destinations;
    if (this.ends) {
      destinations = result.map((r) => _isSend(r) ? r : this.ends[r]);
    } else {
      destinations = result;
    }
    if (destinations.some((dest) => !dest)) {
      throw new Error("Branch condition returned unknown or null destination");
    }
    if (destinations.filter(_isSend).some((packet) => packet.node === END)) {
      throw new InvalidUpdateError("Cannot send a packet to the END node");
    }
    const writeResult = await writer(destinations, config);
    return writeResult ?? input;
  }
};
var Graph2 = class {
  constructor() {
    Object.defineProperty(this, "nodes", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "edges", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "branches", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "entryPoint", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "compiled", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    this.nodes = {};
    this.edges = /* @__PURE__ */ new Set();
    this.branches = {};
  }
  warnIfCompiled(message) {
    if (this.compiled) {
      console.warn(message);
    }
  }
  get allEdges() {
    return this.edges;
  }
  addNode(...args) {
    function isMutlipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMutlipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]) : [[args[0], args[1], args[2]]];
    if (nodes.length === 0) {
      throw new Error("No nodes provided in `addNode`");
    }
    for (const [key, action, options] of nodes) {
      for (const reservedChar of [
        CHECKPOINT_NAMESPACE_SEPARATOR,
        CHECKPOINT_NAMESPACE_END
      ]) {
        if (key.includes(reservedChar)) {
          throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
        }
      }
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) {
        throw new Error(`Node \`${key}\` already present.`);
      }
      if (key === END) {
        throw new Error(`Node \`${key}\` is reserved.`);
      }
      const runnable = _coerceToRunnable(
        // Account for arbitrary state due to Send API
        action
      );
      this.nodes[key] = {
        runnable,
        metadata: options == null ? void 0 : options.metadata,
        subgraphs: isPregelLike(runnable) ? [runnable] : options == null ? void 0 : options.subgraphs,
        ends: options == null ? void 0 : options.ends
      };
    }
    return this;
  }
  addEdge(startKey, endKey) {
    this.warnIfCompiled(`Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
    if (startKey === END) {
      throw new Error("END cannot be a start node");
    }
    if (endKey === START) {
      throw new Error("START cannot be an end node");
    }
    if (Array.from(this.edges).some(([start]) => start === startKey) && !("channels" in this)) {
      throw new Error(`Already found path for ${startKey}. For multiple edges, use StateGraph.`);
    }
    this.edges.add([startKey, endKey]);
    return this;
  }
  addConditionalEdges(source, path, pathMap) {
    var _a2, _b;
    const options = typeof source === "object" ? source : { source, path, pathMap };
    this.warnIfCompiled("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    if (!Runnable.isRunnable(options.path)) {
      const pathDisplayValues = Array.isArray(options.pathMap) ? options.pathMap.join(",") : Object.keys(options.pathMap ?? {}).join(",");
      options.path = _coerceToRunnable(options.path).withConfig({
        runName: `Branch<${options.source}${pathDisplayValues !== "" ? `,${pathDisplayValues}` : ""}>`.slice(0, 63)
      });
    }
    const name = options.path.getName() === "RunnableLambda" ? "condition" : options.path.getName();
    if (this.branches[options.source] && this.branches[options.source][name]) {
      throw new Error(`Condition \`${name}\` already present for node \`${source}\``);
    }
    (_a2 = this.branches)[_b = options.source] ?? (_a2[_b] = {});
    this.branches[options.source][name] = new Branch(options);
    return this;
  }
  /**
   * @deprecated use `addEdge(START, key)` instead
   */
  setEntryPoint(key) {
    this.warnIfCompiled("Setting the entry point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(START, key);
  }
  /**
   * @deprecated use `addEdge(key, END)` instead
   */
  setFinishPoint(key) {
    this.warnIfCompiled("Setting a finish point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(key, END);
  }
  compile({ checkpointer, interruptBefore, interruptAfter, name } = {}) {
    this.validate([
      ...Array.isArray(interruptBefore) ? interruptBefore : [],
      ...Array.isArray(interruptAfter) ? interruptAfter : []
    ]);
    const compiled = new CompiledGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        [START]: new EphemeralValue(),
        [END]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels: END,
      streamChannels: [],
      streamMode: "values",
      name
    });
    for (const [key, node] of Object.entries(this.nodes)) {
      compiled.attachNode(key, node);
    }
    for (const [start, end] of this.edges) {
      compiled.attachEdge(start, end);
    }
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const [name2, branch] of Object.entries(branches)) {
        compiled.attachBranch(start, name2, branch);
      }
    }
    return compiled.validate();
  }
  validate(interrupt) {
    const allSources = new Set([...this.allEdges].map(([src, _]) => src));
    for (const [start] of Object.entries(this.branches)) {
      allSources.add(start);
    }
    for (const source of allSources) {
      if (source !== START && !(source in this.nodes)) {
        throw new Error(`Found edge starting at unknown node \`${source}\``);
      }
    }
    const allTargets = new Set([...this.allEdges].map(([_, target]) => target));
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const branch of Object.values(branches)) {
        if (branch.ends != null) {
          for (const end of Object.values(branch.ends)) {
            allTargets.add(end);
          }
        } else {
          allTargets.add(END);
          for (const node of Object.keys(this.nodes)) {
            if (node !== start) {
              allTargets.add(node);
            }
          }
        }
      }
    }
    for (const node of Object.values(this.nodes)) {
      for (const target of node.ends ?? []) {
        allTargets.add(target);
      }
    }
    for (const node of Object.keys(this.nodes)) {
      if (!allTargets.has(node)) {
        throw new UnreachableNodeError([
          `Node \`${node}\` is not reachable.`,
          "",
          "If you are returning Command objects from your node,",
          'make sure you are passing names of potential destination nodes as an "ends" array',
          'into ".addNode(..., { ends: ["node1", "node2"] })".'
        ].join("\n"), {
          lc_error_code: "UNREACHABLE_NODE"
        });
      }
    }
    for (const target of allTargets) {
      if (target !== END && !(target in this.nodes)) {
        throw new Error(`Found edge ending at unknown node \`${target}\``);
      }
    }
    if (interrupt) {
      for (const node of interrupt) {
        if (!(node in this.nodes)) {
          throw new Error(`Interrupt node \`${node}\` is not present`);
        }
      }
    }
    this.compiled = true;
  }
};
var CompiledGraph = class extends Pregel {
  constructor({ builder, ...rest }) {
    super(rest);
    Object.defineProperty(this, "builder", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.builder = builder;
  }
  attachNode(key, node) {
    this.channels[key] = new EphemeralValue();
    this.nodes[key] = new PregelNode({
      channels: [],
      triggers: [],
      metadata: node.metadata,
      subgraphs: node.subgraphs,
      ends: node.ends
    }).pipe(node.runnable).pipe(new ChannelWrite([{ channel: key, value: PASSTHROUGH }], [TAG_HIDDEN]));
    this.streamChannels.push(key);
  }
  attachEdge(start, end) {
    if (end === END) {
      if (start === START) {
        throw new Error("Cannot have an edge from START to END");
      }
      this.nodes[start].writers.push(new ChannelWrite([{ channel: END, value: PASSTHROUGH }], [TAG_HIDDEN]));
    } else {
      this.nodes[end].triggers.push(start);
      this.nodes[end].channels.push(start);
    }
  }
  attachBranch(start, name, branch) {
    if (start === START && !this.nodes[START]) {
      this.nodes[START] = Channel.subscribeTo(START, { tags: [TAG_HIDDEN] });
    }
    this.nodes[start].pipe(branch.run((dests) => {
      const writes = dests.map((dest) => {
        if (_isSend(dest)) {
          return dest;
        }
        return {
          channel: dest === END ? END : `branch:${start}:${name}:${dest}`,
          value: PASSTHROUGH
        };
      });
      return new ChannelWrite(writes, [TAG_HIDDEN]);
    }));
    const ends = branch.ends ? Object.values(branch.ends) : Object.keys(this.nodes);
    for (const end of ends) {
      if (end !== END) {
        const channelName = `branch:${start}:${name}:${end}`;
        this.channels[channelName] = new EphemeralValue();
        this.nodes[end].triggers.push(channelName);
        this.nodes[end].channels.push(channelName);
      }
    }
  }
  /**
   * Returns a drawable representation of the computation graph.
   */
  async getGraphAsync(config) {
    var _a2, _b, _c, _d;
    const xray = config == null ? void 0 : config.xray;
    const graph = new Graph();
    const startNodes = {
      [START]: graph.addNode({
        schema: external_exports.any()
      }, START)
    };
    const endNodes = {};
    let subgraphs = {};
    if (xray) {
      subgraphs = Object.fromEntries((await gatherIterator(this.getSubgraphsAsync())).filter(
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        (x) => isCompiledGraph(x[1])
      ));
    }
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) {
        endNodes[END] = graph.addNode({ schema: external_exports.any() }, END);
      }
      if (startNodes[start] === void 0) {
        return;
      }
      if (endNodes[end] === void 0) {
        throw new Error(`End node ${end} not found!`);
      }
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (((_a2 = this.interruptBefore) == null ? void 0 : _a2.includes(key)) && ((_b = this.interruptAfter) == null ? void 0 : _b.includes(key))) {
        metadata.__interrupt = "before,after";
      } else if ((_c = this.interruptBefore) == null ? void 0 : _c.includes(key)) {
        metadata.__interrupt = "before";
      } else if ((_d = this.interruptAfter) == null ? void 0 : _d.includes(key)) {
        metadata.__interrupt = "after";
      }
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? await subgraphs[key].getGraphAsync({
          ...config,
          xray: newXrayValue
        }) : node.getGraph(config);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !validate_default2(id)) {
              return id;
            } else if (_isRunnableInterface(data)) {
              try {
                let dataStr = data.getName();
                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                return dataStr;
              } catch (error) {
                return data.getName();
              }
            } else {
              return data.name ?? "UnknownSchema";
            }
          };
          const [e, s] = graph.extend(drawableSubgraph, displayKey);
          if (e === void 0) {
            throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          }
          if (s !== void 0) {
            startNodes[displayKey] = {
              name: _nodeDataStr(s.id, s.data),
              ...s
            };
          }
          endNodes[displayKey] = {
            name: _nodeDataStr(e.id, e.data),
            ...e
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {
      if (a < b) {
        return -1;
      } else if (b > a) {
        return 1;
      } else {
        return 0;
      }
    });
    for (const [start, end] of sortedEdges) {
      addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    }
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) {
          ends = branch.ends;
        } else {
          ends = defaultEnds;
        }
        for (const [label, end] of Object.entries(ends)) {
          addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
        }
      }
    }
    for (const [key, node] of Object.entries(this.builder.nodes)) {
      if (node.ends !== void 0) {
        for (const end of node.ends) {
          addEdge(_escapeMermaidKeywords(key), _escapeMermaidKeywords(end), void 0, true);
        }
      }
    }
    return graph;
  }
  /**
   * Returns a drawable representation of the computation graph.
   *
   * @deprecated Use getGraphAsync instead. The async method will be the default in the next minor core release.
   */
  getGraph(config) {
    var _a2, _b, _c, _d;
    const xray = config == null ? void 0 : config.xray;
    const graph = new Graph();
    const startNodes = {
      [START]: graph.addNode({
        schema: external_exports.any()
      }, START)
    };
    const endNodes = {};
    let subgraphs = {};
    if (xray) {
      subgraphs = Object.fromEntries(gatherIteratorSync(this.getSubgraphs()).filter(
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        (x) => isCompiledGraph(x[1])
      ));
    }
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) {
        endNodes[END] = graph.addNode({ schema: external_exports.any() }, END);
      }
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (((_a2 = this.interruptBefore) == null ? void 0 : _a2.includes(key)) && ((_b = this.interruptAfter) == null ? void 0 : _b.includes(key))) {
        metadata.__interrupt = "before,after";
      } else if ((_c = this.interruptBefore) == null ? void 0 : _c.includes(key)) {
        metadata.__interrupt = "before";
      } else if ((_d = this.interruptAfter) == null ? void 0 : _d.includes(key)) {
        metadata.__interrupt = "after";
      }
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? subgraphs[key].getGraph({
          ...config,
          xray: newXrayValue
        }) : node.getGraph(config);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !validate_default2(id)) {
              return id;
            } else if (_isRunnableInterface(data)) {
              try {
                let dataStr = data.getName();
                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                return dataStr;
              } catch (error) {
                return data.getName();
              }
            } else {
              return data.name ?? "UnknownSchema";
            }
          };
          const [e, s] = graph.extend(drawableSubgraph, displayKey);
          if (e === void 0) {
            throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          }
          if (s !== void 0) {
            startNodes[displayKey] = {
              name: _nodeDataStr(s.id, s.data),
              ...s
            };
          }
          endNodes[displayKey] = {
            name: _nodeDataStr(e.id, e.data),
            ...e
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {
      if (a < b) {
        return -1;
      } else if (b > a) {
        return 1;
      } else {
        return 0;
      }
    });
    for (const [start, end] of sortedEdges) {
      addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    }
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) {
          ends = branch.ends;
        } else {
          ends = defaultEnds;
        }
        for (const [label, end] of Object.entries(ends)) {
          addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
        }
      }
    }
    return graph;
  }
};
function isCompiledGraph(x) {
  return (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x.attachNode === "function" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x.attachEdge === "function"
  );
}
function _escapeMermaidKeywords(key) {
  if (key === "subgraph") {
    return `"${key}"`;
  }
  return key;
}

// node_modules/@langchain/langgraph/dist/channels/named_barrier_value.js
var areSetsEqual = (a, b) => a.size === b.size && [...a].every((value) => b.has(value));
var NamedBarrierValue = class _NamedBarrierValue extends BaseChannel {
  constructor(names) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "NamedBarrierValue"
    });
    Object.defineProperty(this, "names", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
  }
  fromCheckpoint(checkpoint) {
    const empty = new _NamedBarrierValue(this.names);
    if (typeof checkpoint !== "undefined") {
      empty.seen = new Set(checkpoint);
    }
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) {
      if (this.names.has(nodeName)) {
        if (!this.seen.has(nodeName)) {
          this.seen.add(nodeName);
          updated = true;
        }
      } else {
        throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
      }
    }
    return updated;
  }
  // If we have not yet seen all the node names we want to wait for,
  // throw an error to prevent continuing.
  get() {
    if (!areSetsEqual(this.names, this.seen)) {
      throw new EmptyChannelError();
    }
    return void 0;
  }
  checkpoint() {
    return [...this.seen];
  }
  consume() {
    if (this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      return true;
    }
    return false;
  }
  isAvailable() {
    return !!this.names && areSetsEqual(this.names, this.seen);
  }
};
var NamedBarrierValueAfterFinish = class _NamedBarrierValueAfterFinish extends BaseChannel {
  constructor(names) {
    super();
    Object.defineProperty(this, "lc_graph_name", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "NamedBarrierValueAfterFinish"
    });
    Object.defineProperty(this, "names", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "seen", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "finished", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
    this.finished = false;
  }
  fromCheckpoint(checkpoint) {
    const empty = new _NamedBarrierValueAfterFinish(this.names);
    if (typeof checkpoint !== "undefined") {
      const [seen, finished] = checkpoint;
      empty.seen = new Set(seen);
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) {
      if (this.names.has(nodeName) && !this.seen.has(nodeName)) {
        this.seen.add(nodeName);
        updated = true;
      } else if (!this.names.has(nodeName)) {
        throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
      }
    }
    return updated;
  }
  get() {
    if (!this.finished || !areSetsEqual(this.names, this.seen)) {
      throw new EmptyChannelError();
    }
    return void 0;
  }
  checkpoint() {
    return [[...this.seen], this.finished];
  }
  consume() {
    if (this.finished && this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      this.finished = false;
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && !!this.names && areSetsEqual(this.names, this.seen)) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.finished && !!this.names && areSetsEqual(this.names, this.seen);
  }
};

// node_modules/@langchain/langgraph/dist/graph/zod/meta.js
var META_EXTRAS_DESCRIPTION_PREFIX = "lg:";
var SchemaMetaRegistry = class {
  constructor() {
    Object.defineProperty(this, "_map", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new WeakMap()
    });
    Object.defineProperty(this, "_extensionCache", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
  }
  /**
   * Retrieves the metadata associated with a given schema.
   * @template TValue The value type of the schema.
   * @template TUpdate The update type of the schema (defaults to TValue).
   * @param schema The schema to retrieve metadata for.
   * @returns The associated SchemaMeta, or undefined if not present.
   */
  get(schema) {
    return this._map.get(schema);
  }
  /**
   * Extends or sets the metadata for a given schema.
   * @template TValue The value type of the schema.
   * @template TUpdate The update type of the schema (defaults to TValue).
   * @param schema The schema to extend metadata for.
   * @param predicate A function that receives the existing metadata (or undefined) and returns the new metadata.
   */
  extend(schema, predicate) {
    const existingMeta = this.get(schema);
    this._map.set(schema, predicate(existingMeta));
  }
  /**
   * Removes the metadata associated with a given schema.
   * @param schema The schema to remove metadata for.
   * @returns The SchemaMetaRegistry instance (for chaining).
   */
  remove(schema) {
    this._map.delete(schema);
    return this;
  }
  /**
   * Checks if metadata exists for a given schema.
   * @param schema The schema to check.
   * @returns True if metadata exists, false otherwise.
   */
  has(schema) {
    return this._map.has(schema);
  }
  /**
   * Returns a mapping of channel instances for each property in the schema
   * using the associated metadata in the registry.
   *
   * This is used to create the `channels` object that's passed to the `Graph` constructor.
   *
   * @template T The shape of the schema.
   * @param schema The schema to extract channels from.
   * @returns A mapping from property names to channel instances.
   */
  getChannelsForSchema(schema) {
    const channels = {};
    const shape = getInteropZodObjectShape(schema);
    for (const [key, channelSchema] of Object.entries(shape)) {
      const meta = this.get(channelSchema);
      if (meta == null ? void 0 : meta.reducer) {
        channels[key] = new BinaryOperatorAggregate(meta.reducer.fn, meta.default);
      } else {
        channels[key] = new LastValue();
      }
    }
    return channels;
  }
  /**
   * Returns a modified schema that introspectively looks at all keys of the provided
   * object schema, and applies the augmentations based on meta provided with those keys
   * in the registry and the selectors provided in the `effects` parameter.
   *
   * This assumes that the passed in schema is the "root" schema object for a graph where
   * the keys of the schema are the channels of the graph. Because we need to represent
   * the input of a graph in a couple of different ways, the `effects` parameter allows
   * us to apply those augmentations based on pre determined conditions.
   *
   * @param schema The root schema object to extend.
   * @param effects The effects that are being applied.
   * @returns The extended schema.
   */
  getExtendedChannelSchemas(schema, effects) {
    if (Object.keys(effects).length === 0) {
      return schema;
    }
    const cacheKey = Object.entries(effects).filter(([, v]) => v === true).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}:${v}`).join("|");
    const cache2 = this._extensionCache.get(cacheKey) ?? /* @__PURE__ */ new WeakMap();
    if (cache2.has(schema))
      return cache2.get(schema);
    let modifiedSchema = schema;
    if (effects.withReducerSchema || effects.withJsonSchemaExtrasAsDescription) {
      const newShapeEntries = Object.entries(getInteropZodObjectShape(schema)).map(([key, schema2]) => {
        var _a2;
        const meta = this.get(schema2);
        let outputSchema = effects.withReducerSchema ? ((_a2 = meta == null ? void 0 : meta.reducer) == null ? void 0 : _a2.schema) ?? schema2 : schema2;
        if (effects.withJsonSchemaExtrasAsDescription && (meta == null ? void 0 : meta.jsonSchemaExtra)) {
          const description = getSchemaDescription(outputSchema) ?? getSchemaDescription(schema2);
          const strExtras = JSON.stringify({
            ...meta.jsonSchemaExtra,
            description
          });
          outputSchema = outputSchema.describe(`${META_EXTRAS_DESCRIPTION_PREFIX}${strExtras}`);
        }
        return [key, outputSchema];
      });
      modifiedSchema = extendInteropZodObject(schema, Object.fromEntries(newShapeEntries));
      if (isZodSchemaV3(modifiedSchema)) {
        modifiedSchema._def.unknownKeys = "strip";
      }
    }
    if (effects.asPartial) {
      modifiedSchema = interopZodObjectPartial(modifiedSchema);
    }
    cache2.set(schema, modifiedSchema);
    this._extensionCache.set(cacheKey, cache2);
    return modifiedSchema;
  }
};
var schemaMetaRegistry = new SchemaMetaRegistry();
function withLangGraph(schema, meta) {
  var _a2;
  if (meta.reducer && !meta.default) {
    const defaultValueGetter = getInteropZodDefaultGetter(schema);
    if (defaultValueGetter != null) {
      meta.default = defaultValueGetter;
    }
  }
  if (meta.reducer) {
    const schemaWithReducer = Object.assign(schema, {
      lg_reducer_schema: ((_a2 = meta.reducer) == null ? void 0 : _a2.schema) ?? schema
    });
    schemaMetaRegistry.extend(schemaWithReducer, () => meta);
    return schemaWithReducer;
  } else {
    schemaMetaRegistry.extend(schema, () => meta);
    return schema;
  }
}

// node_modules/@langchain/langgraph/dist/graph/state.js
var ROOT = "__root__";
var PartialStateSchema = Symbol.for("langgraph.state.partial");
var StateGraph = class extends Graph2 {
  constructor(fields, contextSchema) {
    var _a2, _b;
    super();
    Object.defineProperty(this, "channels", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: {}
    });
    Object.defineProperty(this, "waitingEdges", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Set()
    });
    Object.defineProperty(this, "_schemaDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_schemaRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_inputDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_inputRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_outputDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_outputRuntimeDefinition", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_schemaDefinitions", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: /* @__PURE__ */ new Map()
    });
    Object.defineProperty(this, "_metaRegistry", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: schemaMetaRegistry
    });
    Object.defineProperty(this, "_configSchema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_configRuntimeSchema", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    if (isZodStateGraphArgsWithStateSchema(fields)) {
      const stateDef = this._metaRegistry.getChannelsForSchema(fields.state);
      const inputDef = fields.input != null ? this._metaRegistry.getChannelsForSchema(fields.input) : stateDef;
      const outputDef = fields.output != null ? this._metaRegistry.getChannelsForSchema(fields.output) : stateDef;
      this._schemaDefinition = stateDef;
      this._schemaRuntimeDefinition = fields.state;
      this._inputDefinition = inputDef;
      this._inputRuntimeDefinition = fields.input ?? PartialStateSchema;
      this._outputDefinition = outputDef;
      this._outputRuntimeDefinition = fields.output ?? fields.state;
    } else if (isInteropZodObject(fields)) {
      const stateDef = this._metaRegistry.getChannelsForSchema(fields);
      this._schemaDefinition = stateDef;
      this._schemaRuntimeDefinition = fields;
      this._inputDefinition = stateDef;
      this._inputRuntimeDefinition = PartialStateSchema;
      this._outputDefinition = stateDef;
      this._outputRuntimeDefinition = fields;
    } else if (isStateGraphArgsWithInputOutputSchemas(fields)) {
      this._schemaDefinition = fields.input.spec;
      this._inputDefinition = fields.input.spec;
      this._outputDefinition = fields.output.spec;
    } else if (isStateGraphArgsWithStateSchema(fields)) {
      this._schemaDefinition = fields.stateSchema.spec;
      this._inputDefinition = ((_a2 = fields.input) == null ? void 0 : _a2.spec) ?? this._schemaDefinition;
      this._outputDefinition = ((_b = fields.output) == null ? void 0 : _b.spec) ?? this._schemaDefinition;
    } else if (isStateDefinition(fields) || isAnnotationRoot(fields)) {
      const spec = isAnnotationRoot(fields) ? fields.spec : fields;
      this._schemaDefinition = spec;
    } else if (isStateGraphArgs(fields)) {
      const spec = _getChannels(fields.channels);
      this._schemaDefinition = spec;
    } else {
      throw new Error("Invalid StateGraph input. Make sure to pass a valid Annotation.Root or Zod schema.");
    }
    this._inputDefinition ?? (this._inputDefinition = this._schemaDefinition);
    this._outputDefinition ?? (this._outputDefinition = this._schemaDefinition);
    this._addSchema(this._schemaDefinition);
    this._addSchema(this._inputDefinition);
    this._addSchema(this._outputDefinition);
    if (isInteropZodObject(contextSchema)) {
      this._configRuntimeSchema = contextSchema;
    }
  }
  get allEdges() {
    return /* @__PURE__ */ new Set([
      ...this.edges,
      ...Array.from(this.waitingEdges).flatMap(([starts, end]) => starts.map((start) => [start, end]))
    ]);
  }
  _addSchema(stateDefinition) {
    if (this._schemaDefinitions.has(stateDefinition)) {
      return;
    }
    this._schemaDefinitions.set(stateDefinition, stateDefinition);
    for (const [key, val] of Object.entries(stateDefinition)) {
      let channel;
      if (typeof val === "function") {
        channel = val();
      } else {
        channel = val;
      }
      if (this.channels[key] !== void 0) {
        if (this.channels[key] !== channel) {
          if (channel.lc_graph_name !== "LastValue") {
            throw new Error(`Channel "${key}" already exists with a different type.`);
          }
        }
      } else {
        this.channels[key] = channel;
      }
    }
  }
  addNode(...args) {
    function isMultipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMultipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]).map(([key, action]) => [
      key,
      action,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      action[Symbol.for("langgraph.state.node")] ?? void 0
    ]) : [[args[0], args[1], args[2]]];
    if (nodes.length === 0) {
      throw new Error("No nodes provided in `addNode`");
    }
    for (const [key, action, options] of nodes) {
      if (key in this.channels) {
        throw new Error(`${key} is already being used as a state attribute (a.k.a. a channel), cannot also be used as a node name.`);
      }
      for (const reservedChar of [
        CHECKPOINT_NAMESPACE_SEPARATOR,
        CHECKPOINT_NAMESPACE_END
      ]) {
        if (key.includes(reservedChar)) {
          throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
        }
      }
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) {
        throw new Error(`Node \`${key}\` already present.`);
      }
      if (key === END || key === START) {
        throw new Error(`Node \`${key}\` is reserved.`);
      }
      let inputSpec = this._schemaDefinition;
      if ((options == null ? void 0 : options.input) !== void 0) {
        if (isInteropZodObject(options.input)) {
          inputSpec = this._metaRegistry.getChannelsForSchema(options.input);
        } else if (options.input.spec !== void 0) {
          inputSpec = options.input.spec;
        }
      }
      if (inputSpec !== void 0) {
        this._addSchema(inputSpec);
      }
      let runnable;
      if (Runnable.isRunnable(action)) {
        runnable = action;
      } else if (typeof action === "function") {
        runnable = new RunnableCallable({
          func: action,
          name: key,
          trace: false
        });
      } else {
        runnable = _coerceToRunnable(action);
      }
      let cachePolicy = options == null ? void 0 : options.cachePolicy;
      if (typeof cachePolicy === "boolean") {
        cachePolicy = cachePolicy ? {} : void 0;
      }
      const nodeSpec = {
        runnable,
        retryPolicy: options == null ? void 0 : options.retryPolicy,
        cachePolicy,
        metadata: options == null ? void 0 : options.metadata,
        input: inputSpec ?? this._schemaDefinition,
        subgraphs: isPregelLike(runnable) ? (
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          [runnable]
        ) : options == null ? void 0 : options.subgraphs,
        ends: options == null ? void 0 : options.ends,
        defer: options == null ? void 0 : options.defer
      };
      this.nodes[key] = nodeSpec;
    }
    return this;
  }
  addEdge(startKey, endKey) {
    if (typeof startKey === "string") {
      return super.addEdge(startKey, endKey);
    }
    if (this.compiled) {
      console.warn("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    }
    for (const start of startKey) {
      if (start === END) {
        throw new Error("END cannot be a start node");
      }
      if (!Object.keys(this.nodes).some((node) => node === start)) {
        throw new Error(`Need to add a node named "${start}" first`);
      }
    }
    if (endKey === END) {
      throw new Error("END cannot be an end node");
    }
    if (!Object.keys(this.nodes).some((node) => node === endKey)) {
      throw new Error(`Need to add a node named "${endKey}" first`);
    }
    this.waitingEdges.add([startKey, endKey]);
    return this;
  }
  addSequence(nodes) {
    const parsedNodes = Array.isArray(nodes) ? nodes : Object.entries(nodes).map(([key, action]) => [
      key,
      action,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      action[Symbol.for("langgraph.state.node")] ?? void 0
    ]);
    if (parsedNodes.length === 0) {
      throw new Error("Sequence requires at least one node.");
    }
    let previousNode;
    for (const [key, action, options] of parsedNodes) {
      if (key in this.nodes) {
        throw new Error(`Node names must be unique: node with the name "${key}" already exists.`);
      }
      const validKey = key;
      this.addNode(validKey, action, options);
      if (previousNode != null) {
        this.addEdge(previousNode, validKey);
      }
      previousNode = validKey;
    }
    return this;
  }
  compile({ checkpointer, store, cache: cache2, interruptBefore, interruptAfter, name, description } = {}) {
    this.validate([
      ...Array.isArray(interruptBefore) ? interruptBefore : [],
      ...Array.isArray(interruptAfter) ? interruptAfter : []
    ]);
    const outputKeys = Object.keys(this._schemaDefinitions.get(this._outputDefinition));
    const outputChannels = outputKeys.length === 1 && outputKeys[0] === ROOT ? ROOT : outputKeys;
    const streamKeys = Object.keys(this.channels);
    const streamChannels = streamKeys.length === 1 && streamKeys[0] === ROOT ? ROOT : streamKeys;
    const compiled = new CompiledStateGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        ...this.channels,
        [START]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels,
      streamChannels,
      streamMode: "updates",
      store,
      cache: cache2,
      name,
      description
    });
    compiled.attachNode(START);
    for (const [key, node] of Object.entries(this.nodes)) {
      compiled.attachNode(key, node);
    }
    compiled.attachBranch(START, SELF, _getControlBranch(), {
      withReader: false
    });
    for (const [key] of Object.entries(this.nodes)) {
      compiled.attachBranch(key, SELF, _getControlBranch(), {
        withReader: false
      });
    }
    for (const [start, end] of this.edges) {
      compiled.attachEdge(start, end);
    }
    for (const [starts, end] of this.waitingEdges) {
      compiled.attachEdge(starts, end);
    }
    for (const [start, branches] of Object.entries(this.branches)) {
      for (const [name2, branch] of Object.entries(branches)) {
        compiled.attachBranch(start, name2, branch);
      }
    }
    return compiled.validate();
  }
};
function _getChannels(schema) {
  const channels = {};
  for (const [name, val] of Object.entries(schema)) {
    if (name === ROOT) {
      channels[name] = getChannel(val);
    } else {
      const key = name;
      channels[name] = getChannel(val);
    }
  }
  return channels;
}
var CompiledStateGraph = class extends CompiledGraph {
  constructor({ description, ...rest }) {
    super(rest);
    Object.defineProperty(this, "description", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "_metaRegistry", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: schemaMetaRegistry
    });
    this.description = description;
  }
  attachNode(key, node) {
    let outputKeys;
    if (key === START) {
      outputKeys = Object.entries(this.builder._schemaDefinitions.get(this.builder._inputDefinition)).map(([k]) => k);
    } else {
      outputKeys = Object.keys(this.builder.channels);
    }
    function _getRoot(input) {
      if (isCommand(input)) {
        if (input.graph === Command.PARENT) {
          return null;
        }
        return input._updateAsTuples();
      } else if (Array.isArray(input) && input.length > 0 && input.some((i) => isCommand(i))) {
        const updates = [];
        for (const i of input) {
          if (isCommand(i)) {
            if (i.graph === Command.PARENT) {
              continue;
            }
            updates.push(...i._updateAsTuples());
          } else {
            updates.push([ROOT, i]);
          }
        }
        return updates;
      } else if (input != null) {
        return [[ROOT, input]];
      }
      return null;
    }
    const nodeKey = key;
    function _getUpdates(input) {
      if (!input) {
        return null;
      } else if (isCommand(input)) {
        if (input.graph === Command.PARENT) {
          return null;
        }
        return input._updateAsTuples().filter(([k]) => outputKeys.includes(k));
      } else if (Array.isArray(input) && input.length > 0 && input.some(isCommand)) {
        const updates = [];
        for (const item of input) {
          if (isCommand(item)) {
            if (item.graph === Command.PARENT) {
              continue;
            }
            updates.push(...item._updateAsTuples().filter(([k]) => outputKeys.includes(k)));
          } else {
            const itemUpdates = _getUpdates(item);
            if (itemUpdates) {
              updates.push(...itemUpdates ?? []);
            }
          }
        }
        return updates;
      } else if (typeof input === "object" && !Array.isArray(input)) {
        return Object.entries(input).filter(([k]) => outputKeys.includes(k));
      } else {
        const typeofInput = Array.isArray(input) ? "array" : typeof input;
        throw new InvalidUpdateError(`Expected node "${nodeKey.toString()}" to return an object or an array containing at least one Command object, received ${typeofInput}`, {
          lc_error_code: "INVALID_GRAPH_NODE_RETURN_VALUE"
        });
      }
    }
    const stateWriteEntries = [
      {
        value: PASSTHROUGH,
        mapper: new RunnableCallable({
          func: outputKeys.length && outputKeys[0] === ROOT ? _getRoot : _getUpdates,
          trace: false,
          recurse: false
        })
      }
    ];
    if (key === START) {
      this.nodes[key] = new PregelNode({
        tags: [TAG_HIDDEN],
        triggers: [START],
        channels: [START],
        writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])]
      });
    } else {
      const inputDefinition = (node == null ? void 0 : node.input) ?? this.builder._schemaDefinition;
      const inputValues = Object.fromEntries(Object.keys(this.builder._schemaDefinitions.get(inputDefinition)).map((k) => [k, k]));
      const isSingleInput = Object.keys(inputValues).length === 1 && ROOT in inputValues;
      const branchChannel = `branch:to:${key}`;
      this.channels[branchChannel] = (node == null ? void 0 : node.defer) ? new LastValueAfterFinish() : new EphemeralValue(false);
      this.nodes[key] = new PregelNode({
        triggers: [branchChannel],
        // read state keys
        channels: isSingleInput ? Object.keys(inputValues) : inputValues,
        // publish to state keys
        writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])],
        mapper: isSingleInput ? void 0 : (
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          (input) => {
            return Object.fromEntries(Object.entries(input).filter(([k]) => k in inputValues));
          }
        ),
        bound: node == null ? void 0 : node.runnable,
        metadata: node == null ? void 0 : node.metadata,
        retryPolicy: node == null ? void 0 : node.retryPolicy,
        cachePolicy: node == null ? void 0 : node.cachePolicy,
        subgraphs: node == null ? void 0 : node.subgraphs,
        ends: node == null ? void 0 : node.ends
      });
    }
  }
  attachEdge(starts, end) {
    if (end === END)
      return;
    if (typeof starts === "string") {
      this.nodes[starts].writers.push(new ChannelWrite([{ channel: `branch:to:${end}`, value: null }], [TAG_HIDDEN]));
    } else if (Array.isArray(starts)) {
      const channelName = `join:${starts.join("+")}:${end}`;
      this.channels[channelName] = this.builder.nodes[end].defer ? new NamedBarrierValueAfterFinish(new Set(starts)) : new NamedBarrierValue(new Set(starts));
      this.nodes[end].triggers.push(channelName);
      for (const start of starts) {
        this.nodes[start].writers.push(new ChannelWrite([{ channel: channelName, value: start }], [TAG_HIDDEN]));
      }
    }
  }
  attachBranch(start, _, branch, options = { withReader: true }) {
    const branchWriter = async (packets, config) => {
      const filteredPackets = packets.filter((p) => p !== END);
      if (!filteredPackets.length)
        return;
      const writes = filteredPackets.map((p) => {
        if (_isSend(p))
          return p;
        return { channel: p === END ? p : `branch:to:${p}`, value: start };
      });
      await ChannelWrite.doWrite({ ...config, tags: (config.tags ?? []).concat([TAG_HIDDEN]) }, writes);
    };
    this.nodes[start].writers.push(branch.run(
      branchWriter,
      // reader
      options.withReader ? (config) => ChannelRead.doRead(config, this.streamChannels ?? this.outputChannels, true) : void 0
    ));
  }
  async _validateInput(input) {
    if (input == null)
      return input;
    const schema = (() => {
      const input2 = this.builder._inputRuntimeDefinition;
      const schema2 = this.builder._schemaRuntimeDefinition;
      const apply = (schema3) => {
        if (schema3 == null)
          return void 0;
        return this._metaRegistry.getExtendedChannelSchemas(schema3, {
          withReducerSchema: true
        });
      };
      if (isInteropZodObject(input2))
        return apply(input2);
      if (input2 === PartialStateSchema) {
        return interopZodObjectPartial(apply(schema2));
      }
      return void 0;
    })();
    if (isCommand(input)) {
      const parsedInput = input;
      if (input.update && schema != null)
        parsedInput.update = interopParse(schema, input.update);
      return parsedInput;
    }
    if (schema != null)
      return interopParse(schema, input);
    return input;
  }
  async _validateContext(config) {
    const configSchema = this.builder._configRuntimeSchema;
    if (isInteropZodObject(configSchema))
      interopParse(configSchema, config);
    return config;
  }
};
function isStateDefinition(obj) {
  return typeof obj === "object" && obj !== null && !Array.isArray(obj) && Object.keys(obj).length > 0 && Object.values(obj).every((v) => typeof v === "function" || isBaseChannel(v));
}
function isAnnotationRoot(obj) {
  return typeof obj === "object" && obj !== null && "lc_graph_name" in obj && obj.lc_graph_name === "AnnotationRoot";
}
function isStateGraphArgs(obj) {
  return typeof obj === "object" && obj !== null && obj.channels !== void 0;
}
function isStateGraphArgsWithStateSchema(obj) {
  return typeof obj === "object" && obj !== null && obj.stateSchema !== void 0;
}
function isStateGraphArgsWithInputOutputSchemas(obj) {
  return typeof obj === "object" && obj !== null && // eslint-disable-next-line @typescript-eslint/no-explicit-any
  obj.stateSchema === void 0 && obj.input !== void 0 && obj.output !== void 0;
}
function isZodStateGraphArgsWithStateSchema(value) {
  if (typeof value !== "object" || value == null) {
    return false;
  }
  if (!("state" in value) || !isInteropZodObject(value.state)) {
    return false;
  }
  if ("input" in value && !isInteropZodObject(value.input)) {
    return false;
  }
  if ("output" in value && !isInteropZodObject(value.output)) {
    return false;
  }
  return true;
}
function _controlBranch(value) {
  if (_isSend(value)) {
    return [value];
  }
  const commands = [];
  if (isCommand(value)) {
    commands.push(value);
  } else if (Array.isArray(value)) {
    commands.push(...value.filter(isCommand));
  }
  const destinations = [];
  for (const command of commands) {
    if (command.graph === Command.PARENT) {
      throw new ParentCommand(command);
    }
    if (_isSend(command.goto)) {
      destinations.push(command.goto);
    } else if (typeof command.goto === "string") {
      destinations.push(command.goto);
    } else {
      if (Array.isArray(command.goto)) {
        destinations.push(...command.goto);
      }
    }
  }
  return destinations;
}
function _getControlBranch() {
  const CONTROL_BRANCH_PATH = new RunnableCallable({
    func: _controlBranch,
    tags: [TAG_HIDDEN],
    trace: false,
    recurse: false,
    name: "<control_branch>"
  });
  return new Branch({
    path: CONTROL_BRANCH_PATH
  });
}
function typedNode(_state, _options) {
  return (func, options) => {
    Object.assign(func, { [Symbol.for("langgraph.state.node")]: options });
    return func;
  };
}

// node_modules/@langchain/langgraph/dist/graph/message.js
var REMOVE_ALL_MESSAGES = "__remove_all__";
function messagesStateReducer(left, right) {
  const leftArray = Array.isArray(left) ? left : [left];
  const rightArray = Array.isArray(right) ? right : [right];
  const leftMessages = leftArray.map(coerceMessageLikeToMessage);
  const rightMessages = rightArray.map(coerceMessageLikeToMessage);
  for (const m of leftMessages) {
    if (m.id === null || m.id === void 0) {
      m.id = v4_default2();
      m.lc_kwargs.id = m.id;
    }
  }
  let removeAllIdx;
  for (let i = 0; i < rightMessages.length; i += 1) {
    const m = rightMessages[i];
    if (m.id === null || m.id === void 0) {
      m.id = v4_default2();
      m.lc_kwargs.id = m.id;
    }
    if (m.getType() === "remove" && m.id === REMOVE_ALL_MESSAGES) {
      removeAllIdx = i;
    }
  }
  if (removeAllIdx != null)
    return rightMessages.slice(removeAllIdx + 1);
  const merged = [...leftMessages];
  const mergedById = new Map(merged.map((m, i) => [m.id, i]));
  const idsToRemove = /* @__PURE__ */ new Set();
  for (const m of rightMessages) {
    const existingIdx = mergedById.get(m.id);
    if (existingIdx !== void 0) {
      if (m.getType() === "remove") {
        idsToRemove.add(m.id);
      } else {
        idsToRemove.delete(m.id);
        merged[existingIdx] = m;
      }
    } else {
      if (m.getType() === "remove") {
        throw new Error(`Attempting to delete a message with an ID that doesn't exist ('${m.id}')`);
      }
      mergedById.set(m.id, merged.length);
      merged.push(m);
    }
  }
  return merged.filter((m) => !idsToRemove.has(m.id));
}
var MessageGraph = class extends StateGraph {
  constructor() {
    super({
      channels: {
        __root__: {
          reducer: messagesStateReducer,
          default: () => []
        }
      }
    });
  }
};

// node_modules/@langchain/langgraph/dist/func/index.js
function task(optionsOrName, func) {
  const options = typeof optionsOrName === "string" ? { name: optionsOrName, retry: void 0, cachePolicy: void 0 } : optionsOrName;
  const { name, retry } = options;
  if (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) {
    throw new Error("Generators are disallowed as tasks. For streaming responses, use config.write.");
  }
  const cachePolicy = options.cachePolicy ?? // `cache` was mistakingly used as an alias for `cachePolicy` in v0.3.x,
  // TODO: remove in 1.x
  ("cache" in options ? options.cache : void 0);
  let cache2;
  if (typeof cachePolicy === "boolean") {
    cache2 = cachePolicy ? {} : void 0;
  } else {
    cache2 = cachePolicy;
  }
  return (...args) => {
    return call({ func, name, retry, cache: cache2 }, ...args);
  };
}
var entrypoint = function entrypoint2(optionsOrName, func) {
  const { name, checkpointer, store, cache: cache2 } = typeof optionsOrName === "string" ? { name: optionsOrName, checkpointer: void 0, store: void 0 } : optionsOrName;
  if (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) {
    throw new Error("Generators are disallowed as entrypoints. For streaming responses, use config.write.");
  }
  const streamMode = "updates";
  const bound = getRunnableForEntrypoint(name, func);
  function isEntrypointFinal(value) {
    return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "__pregel_final";
  }
  const pluckReturnValue = new RunnableCallable({
    name: "pluckReturnValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.value : value;
    }
  });
  const pluckSaveValue = new RunnableCallable({
    name: "pluckSaveValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.save : value;
    }
  });
  const entrypointNode = new PregelNode({
    bound,
    triggers: [START],
    channels: [START],
    writers: [
      new ChannelWrite([
        { channel: END, value: PASSTHROUGH, mapper: pluckReturnValue },
        { channel: PREVIOUS, value: PASSTHROUGH, mapper: pluckSaveValue }
      ], [TAG_HIDDEN])
    ]
  });
  return new Pregel({
    name,
    checkpointer,
    nodes: {
      [name]: entrypointNode
    },
    channels: {
      [START]: new EphemeralValue(),
      [END]: new LastValue(),
      [PREVIOUS]: new LastValue()
    },
    inputChannels: START,
    outputChannels: END,
    streamChannels: END,
    streamMode,
    store,
    cache: cache2
  });
};
entrypoint.final = function final({ value, save }) {
  return { value, save, __lg_type: "__pregel_final" };
};

// node_modules/@langchain/langgraph/dist/graph/messages_annotation.js
var MessagesAnnotation = Annotation.Root({
  messages: Annotation({
    reducer: messagesStateReducer,
    default: () => []
  })
});
var MessagesZodMeta = {
  reducer: { fn: messagesStateReducer },
  jsonSchemaExtra: { langgraph_type: "messages" },
  default: () => []
};
var MessagesZodState = external_exports.object({
  messages: withLangGraph(external_exports.custom(), MessagesZodMeta)
});
export {
  Annotation,
  AsyncBatchedStore,
  BaseChannel,
  BaseCheckpointSaver,
  BaseLangGraphError,
  BaseStore2 as BaseStore,
  BinaryOperatorAggregate,
  Command,
  CompiledStateGraph,
  END,
  EmptyChannelError,
  EmptyInputError,
  Graph2 as Graph,
  GraphBubbleUp,
  GraphInterrupt,
  GraphRecursionError,
  GraphValueError,
  INTERRUPT2 as INTERRUPT,
  InMemoryStore2 as InMemoryStore,
  InvalidUpdateError,
  MemorySaver,
  MessageGraph,
  MessagesAnnotation,
  MessagesZodMeta,
  MessagesZodState,
  MultipleSubgraphsError,
  NodeInterrupt,
  ParentCommand,
  REMOVE_ALL_MESSAGES,
  RemoteException,
  START,
  Send,
  StateGraph,
  UnreachableNodeError,
  messagesStateReducer as addMessages,
  copyCheckpoint,
  emptyCheckpoint,
  entrypoint,
  getSubgraphsSeenSet,
  isCommand,
  isGraphBubbleUp,
  isGraphInterrupt,
  isInterrupted,
  isParentCommand,
  messagesStateReducer,
  task,
  typedNode
};
/*! Bundled license information:

@langchain/core/dist/utils/js-sha1/hash.js:
  (*
   * [js-sha1]{@link https://github.com/emn178/js-sha1}
   *
   * @version 0.6.0
   * @author Chen, Yi-Cyuan [emn178@gmail.com]
   * @copyright Chen, Yi-Cyuan 2014-2017
   * @license MIT
   *)

@langchain/core/dist/utils/js-sha256/hash.js:
  (**
   * [js-sha256]{@link https://github.com/emn178/js-sha256}
   *
   * @version 0.11.1
   * @author Chen, Yi-Cyuan [emn178@gmail.com]
   * @copyright Chen, Yi-Cyuan 2014-2025
   * @license MIT
   *)

@langchain/core/dist/utils/sax-js/sax.js:
  (*! http://mths.be/fromcodepoint v0.1.0 by @mathias *)
*/
//# sourceMappingURL=@langchain_langgraph_web.js.map
